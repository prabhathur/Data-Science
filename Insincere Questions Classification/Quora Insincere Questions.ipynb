{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Splitting-to-test-and-train\" data-toc-modified-id=\"Splitting-to-test-and-train-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Splitting to test and train</a></span></li><li><span><a href=\"#Feature-Engineering\" data-toc-modified-id=\"Feature-Engineering-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Feature Engineering</a></span><ul class=\"toc-item\"><li><span><a href=\"#Training-file\" data-toc-modified-id=\"Training-file-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Training file</a></span></li><li><span><a href=\"#Test-file-WOE\" data-toc-modified-id=\"Test-file-WOE-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Test file WOE</a></span></li></ul></li><li><span><a href=\"#Preprocessing\" data-toc-modified-id=\"Preprocessing-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Preprocessing</a></span></li><li><span><a href=\"#Loading-WOE-Files\" data-toc-modified-id=\"Loading-WOE-Files-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Loading WOE Files</a></span></li><li><span><a href=\"#TFIDF\" data-toc-modified-id=\"TFIDF-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>TFIDF</a></span><ul class=\"toc-item\"><li><span><a href=\"#Logistic-Regression\" data-toc-modified-id=\"Logistic-Regression-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Logistic Regression</a></span></li><li><span><a href=\"#Light-GBM\" data-toc-modified-id=\"Light-GBM-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Light GBM</a></span></li></ul></li><li><span><a href=\"#Count-Vectorizer\" data-toc-modified-id=\"Count-Vectorizer-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Count Vectorizer</a></span><ul class=\"toc-item\"><li><span><a href=\"#Logistic-Regression\" data-toc-modified-id=\"Logistic-Regression-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Logistic Regression</a></span></li><li><span><a href=\"#Light-GBM\" data-toc-modified-id=\"Light-GBM-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Light GBM</a></span></li></ul></li><li><span><a href=\"#Loading-embeddings-&amp;-processing-text-to-suit-embeddings\" data-toc-modified-id=\"Loading-embeddings-&amp;-processing-text-to-suit-embeddings-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Loading embeddings &amp; processing text to suit embeddings</a></span></li><li><span><a href=\"#Loading-processed-file\" data-toc-modified-id=\"Loading-processed-file-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Loading processed file</a></span></li><li><span><a href=\"#BiLSTM\" data-toc-modified-id=\"BiLSTM-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>BiLSTM</a></span></li><li><span><a href=\"#Combined-Model\" data-toc-modified-id=\"Combined-Model-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Combined Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Logistic-Regression\" data-toc-modified-id=\"Logistic-Regression-10.1\"><span class=\"toc-item-num\">10.1&nbsp;&nbsp;</span>Logistic Regression</a></span></li><li><span><a href=\"#Logistic-regression-with-non-deep-learning-models\" data-toc-modified-id=\"Logistic-regression-with-non-deep-learning-models-10.2\"><span class=\"toc-item-num\">10.2&nbsp;&nbsp;</span>Logistic regression with non deep learning models</a></span></li><li><span><a href=\"#Light-GBM\" data-toc-modified-id=\"Light-GBM-10.3\"><span class=\"toc-item-num\">10.3&nbsp;&nbsp;</span>Light GBM</a></span></li><li><span><a href=\"#Concatenating-woe-scores-to-training-file\" data-toc-modified-id=\"Concatenating-woe-scores-to-training-file-10.4\"><span class=\"toc-item-num\">10.4&nbsp;&nbsp;</span>Concatenating woe scores to training file</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T15:16:52.443573Z",
     "start_time": "2020-04-12T15:16:48.155012Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import scipy as sp\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T15:16:52.449577Z",
     "start_time": "2020-04-12T15:16:52.444541Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to select threshold value to get optimum f1 score \n",
    "def threshold_search(y_true,y_proba):\n",
    "    best_threshold=0\n",
    "    best_score=0\n",
    "    for threshold in [i*0.01 for i in range(100)]:\n",
    "        score=metrics.f1_score(y_true=y_true, y_pred=y_proba>threshold)\n",
    "        if score>best_score:\n",
    "            best_threshold=threshold\n",
    "            best_score=score\n",
    "    search_result={'threshold':best_threshold,'f1':best_score}\n",
    "    return search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T15:16:52.469474Z",
     "start_time": "2020-04-12T15:16:52.451522Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function for generating WOE values for given dataframe and column\n",
    "def woe(df,targ,col):\n",
    "    if((df[col].dtype!=object) and (df[col].nunique()>10)):\n",
    "        df1=df[[col,targ]].sort_values(col)\n",
    "        totalgood=sum(df[targ]==0)\n",
    "        totalbad=sum(df[targ]==1)\n",
    "        df1['bin']=pd.qcut(df1[col],20,duplicates='drop',precision=20,)\n",
    "        df2=df1.drop(col,axis=1)\n",
    "        ct=pd.crosstab(df2['bin'],df2[targ],colnames=[None])\n",
    "        ct.reset_index(0,inplace=True)\n",
    "        for i in range(len(ct)):\n",
    "            if ct[1][i]==0:\n",
    "                ct[1][i]=1\n",
    "        for i in range(len(ct)):\n",
    "            if ct[0][i]==0:\n",
    "                ct[0][i]=1\n",
    "        ct['% Good']=ct[0]/totalgood\n",
    "        ct['% Bad']=ct[1]/totalbad\n",
    "        ct['WOE']=np.log(ct['% Good']/ct['% Bad'])\n",
    "        ct['IV']=(ct['% Good']-ct['% Bad'])*ct['WOE']\n",
    "        if sum(df[col].isna())>1:\n",
    "            missing=df.loc[df[col].isna(),]\n",
    "            ones=sum(missing['TARGET']==1)\n",
    "            zeroes=sum(missing['TARGET']==0)\n",
    "            good=(zeroes/totalgood)\n",
    "            if ones==0:\n",
    "                bad=(ones+1/totalbad)\n",
    "            else:\n",
    "                bad=(ones/totalbad)\n",
    "            woev=np.log(good/bad)\n",
    "            iv=(good-bad)*woev\n",
    "            ct.loc[max(ct.index)+1]=['Missing Values',zeroes,ones,good,bad,woev,iv]\n",
    "        return(ct)\n",
    "    else:\n",
    "        ct=pd.crosstab(df[col],df[targ],colnames=[None])\n",
    "        totalgood=sum(df[targ]==0)\n",
    "        totalbad=sum(df[targ]==1)\n",
    "        ct.reset_index(0,inplace=True)\n",
    "        for i in range(len(ct)):\n",
    "            if ct[1][i]==0:\n",
    "                ct[1][i]=1\n",
    "        for i in range(len(ct)):\n",
    "            if ct[0][i]==0:\n",
    "                ct[0][i]=1\n",
    "        ct['% Good']=ct[0]/totalgood\n",
    "        ct['% Bad']=ct[1]/totalbad\n",
    "        ct['WOE']=np.log(ct['% Good']/ct['% Bad'])\n",
    "        ct['IV']=(ct['% Good']-ct['% Bad'])*ct['WOE']\n",
    "        if sum(df[col].isna())>1:\n",
    "            missing=df.loc[df[col].isna(),]\n",
    "            ones=sum(missing['TARGET']==1)\n",
    "            zeroes=sum(missing['TARGET']==0)\n",
    "            if ones==0:\n",
    "                bad=(ones+1/totalbad)\n",
    "            else:\n",
    "                bad=(ones/totalbad)\n",
    "            good=zeroes/totalgood\n",
    "            woev=np.log(good/bad)\n",
    "            iv=(good-bad)*woev\n",
    "            ct.loc[max(ct.index)+1]=['Missing Values',zeroes,ones,good,bad,woev,iv]\n",
    "        return(ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T16:59:40.525897Z",
     "start_time": "2020-04-09T16:59:40.510304Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T15:16:54.701504Z",
     "start_time": "2020-04-12T15:16:52.470506Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Main train file\n",
    "insin=pd.read_csv(r'D:\\DS\\NLP\\quora-insincere-questions-classification\\train.csv')\n",
    "insin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T17:45:01.333859Z",
     "start_time": "2020-04-02T17:45:01.330060Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1306122, 3)\n"
     ]
    }
   ],
   "source": [
    "print(insin.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T17:45:01.643677Z",
     "start_time": "2020-04-02T17:45:01.334829Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 2 artists>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Class distribution\n",
    "plt.bar(x=[0,1],height=insin['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T17:45:01.733423Z",
     "start_time": "2020-04-02T17:45:01.648607Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Class distribution\n",
    "plt.pie(insin['target'].value_counts(),labels=['Sincere','Insincere'],autopct='%1.2f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T17:45:01.847083Z",
     "start_time": "2020-04-02T17:45:01.735376Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "qid              0\n",
       "question_text    0\n",
       "target           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing value check\n",
    "insin.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T17:45:02.645947Z",
     "start_time": "2020-04-02T17:45:01.849076Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1306122\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplication\n",
    "insin.duplicated(subset=[\"question_text\",\"qid\",\"target\"]).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting to test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T17:00:02.645749Z",
     "start_time": "2020-04-09T17:00:02.005270Z"
    }
   },
   "outputs": [],
   "source": [
    "# Splitting to train and test\n",
    "train=insin.sample(frac=0.8,random_state=49) #random state is a seed value\n",
    "test=insin.drop(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T17:00:02.755084Z",
     "start_time": "2020-04-09T17:00:02.645749Z"
    }
   },
   "outputs": [],
   "source": [
    "test.drop('qid',inplace=True,axis=1)\n",
    "train.drop('qid',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T04:49:45.626051Z",
     "start_time": "2020-04-03T04:49:38.404381Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sentence length\n",
    "leng=[len(train.loc[i,'question_text']) for i in train.index]\n",
    "train['Length']=leng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T17:45:18.626398Z",
     "start_time": "2020-04-02T17:45:10.720358Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "      <th>Length</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>172360</th>\n",
       "      <td>Is there any beach available in Delhi for night out?</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188522</th>\n",
       "      <td>What is the unit of vector parallel to each of vector?</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235537</th>\n",
       "      <td>How change LTE to VOlTE?</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345543</th>\n",
       "      <td>What percentage of US Democrat politicians are lawyers?</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566414</th>\n",
       "      <td>How did Cabela's Inc. manages to establish such large stores?</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180555</th>\n",
       "      <td>Where can I buy tamper proof courier bags online?</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155574</th>\n",
       "      <td>What are some reasons to trust a Jew?</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130815</th>\n",
       "      <td>What are the considerations in using a static class vs. a singleton? I need a class to handle functions with no relevance to specific instances.</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107187</th>\n",
       "      <td>What is the purpose of the bit in a horse harness?</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856532</th>\n",
       "      <td>What is Annie Dillard known for?</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1044898 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                            question_text  \\\n",
       "172360                                                                                               Is there any beach available in Delhi for night out?   \n",
       "188522                                                                                             What is the unit of vector parallel to each of vector?   \n",
       "1235537                                                                                                                          How change LTE to VOlTE?   \n",
       "345543                                                                                            What percentage of US Democrat politicians are lawyers?   \n",
       "566414                                                                                      How did Cabela's Inc. manages to establish such large stores?   \n",
       "...                                                                                                                                                   ...   \n",
       "1180555                                                                                                 Where can I buy tamper proof courier bags online?   \n",
       "155574                                                                                                              What are some reasons to trust a Jew?   \n",
       "1130815  What are the considerations in using a static class vs. a singleton? I need a class to handle functions with no relevance to specific instances.   \n",
       "107187                                                                                                 What is the purpose of the bit in a horse harness?   \n",
       "856532                                                                                                                   What is Annie Dillard known for?   \n",
       "\n",
       "         target  Length  Words  \n",
       "172360        0      52     10  \n",
       "188522        0      54     11  \n",
       "1235537       0      24      5  \n",
       "345543        0      55      8  \n",
       "566414        0      61     10  \n",
       "...         ...     ...    ...  \n",
       "1180555       0      49      9  \n",
       "155574        1      37      8  \n",
       "1130815       0     144     25  \n",
       "107187        0      50     11  \n",
       "856532        0      32      6  \n",
       "\n",
       "[1044898 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting number of words in sentence\n",
    "words=[len(train.loc[i,'question_text'].split()) for i in train.index]\n",
    "train['Words']=words\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T17:45:28.366365Z",
     "start_time": "2020-04-02T17:45:18.627397Z"
    }
   },
   "outputs": [],
   "source": [
    "# Getting number of special characters in sentence\n",
    "spchar = [len(re.sub('[A-Za-z0-9\\s]+', '', train.loc[i,'question_text'])) for i in train.index] \n",
    "train['Special Characters']=spchar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T17:45:38.598838Z",
     "start_time": "2020-04-02T17:45:28.367395Z"
    }
   },
   "outputs": [],
   "source": [
    "# Getting number of capital words used in sentence\n",
    "capwrd=[len(re.findall('([A-Z][a-z]+)', train.loc[i,'question_text'])) for i in train.index]\n",
    "train['Capital Words']=capwrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T17:49:54.482329Z",
     "start_time": "2020-04-02T17:45:38.599919Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "      <th>Length</th>\n",
       "      <th>Words</th>\n",
       "      <th>Special Characters</th>\n",
       "      <th>Capital Words</th>\n",
       "      <th>Positive words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>172360</th>\n",
       "      <td>Is there any beach available in Delhi for night out?</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188522</th>\n",
       "      <td>What is the unit of vector parallel to each of vector?</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235537</th>\n",
       "      <td>How change LTE to VOlTE?</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345543</th>\n",
       "      <td>What percentage of US Democrat politicians are lawyers?</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566414</th>\n",
       "      <td>How did Cabela's Inc. manages to establish such large stores?</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180555</th>\n",
       "      <td>Where can I buy tamper proof courier bags online?</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155574</th>\n",
       "      <td>What are some reasons to trust a Jew?</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130815</th>\n",
       "      <td>What are the considerations in using a static class vs. a singleton? I need a class to handle functions with no relevance to specific instances.</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107187</th>\n",
       "      <td>What is the purpose of the bit in a horse harness?</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856532</th>\n",
       "      <td>What is Annie Dillard known for?</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1044898 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                            question_text  \\\n",
       "172360                                                                                               Is there any beach available in Delhi for night out?   \n",
       "188522                                                                                             What is the unit of vector parallel to each of vector?   \n",
       "1235537                                                                                                                          How change LTE to VOlTE?   \n",
       "345543                                                                                            What percentage of US Democrat politicians are lawyers?   \n",
       "566414                                                                                      How did Cabela's Inc. manages to establish such large stores?   \n",
       "...                                                                                                                                                   ...   \n",
       "1180555                                                                                                 Where can I buy tamper proof courier bags online?   \n",
       "155574                                                                                                              What are some reasons to trust a Jew?   \n",
       "1130815  What are the considerations in using a static class vs. a singleton? I need a class to handle functions with no relevance to specific instances.   \n",
       "107187                                                                                                 What is the purpose of the bit in a horse harness?   \n",
       "856532                                                                                                                   What is Annie Dillard known for?   \n",
       "\n",
       "         target  Length  Words  Special Characters  Capital Words  \\\n",
       "172360        0      52     10                   1              2   \n",
       "188522        0      54     11                   1              1   \n",
       "1235537       0      24      5                   1              2   \n",
       "345543        0      55      8                   1              2   \n",
       "566414        0      61     10                   3              3   \n",
       "...         ...     ...    ...                 ...            ...   \n",
       "1180555       0      49      9                   1              1   \n",
       "155574        1      37      8                   1              2   \n",
       "1130815       0     144     25                   3              1   \n",
       "107187        0      50     11                   1              1   \n",
       "856532        0      32      6                   1              3   \n",
       "\n",
       "         Positive words  \n",
       "172360                0  \n",
       "188522                0  \n",
       "1235537               0  \n",
       "345543                0  \n",
       "566414                0  \n",
       "...                 ...  \n",
       "1180555               0  \n",
       "155574                1  \n",
       "1130815               0  \n",
       "107187                0  \n",
       "856532                0  \n",
       "\n",
       "[1044898 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting number of positive words used in sentence\n",
    "senti=SentimentIntensityAnalyzer()\n",
    "poslen=[]\n",
    "for i in train.index:\n",
    "    j=train.loc[i,'question_text']\n",
    "    pos=[]\n",
    "    for p in j.split():\n",
    "        if (senti.polarity_scores(p)['compound']) >= 0.5:\n",
    "            pos.append(p)\n",
    "    poslen.append(len(pos))\n",
    "train['Positive words']=poslen\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T17:54:15.620025Z",
     "start_time": "2020-04-02T17:49:54.483509Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "      <th>Length</th>\n",
       "      <th>Words</th>\n",
       "      <th>Special Characters</th>\n",
       "      <th>Capital Words</th>\n",
       "      <th>Positive words</th>\n",
       "      <th>Negative words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>172360</th>\n",
       "      <td>Is there any beach available in Delhi for night out?</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188522</th>\n",
       "      <td>What is the unit of vector parallel to each of vector?</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235537</th>\n",
       "      <td>How change LTE to VOlTE?</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345543</th>\n",
       "      <td>What percentage of US Democrat politicians are lawyers?</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566414</th>\n",
       "      <td>How did Cabela's Inc. manages to establish such large stores?</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180555</th>\n",
       "      <td>Where can I buy tamper proof courier bags online?</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155574</th>\n",
       "      <td>What are some reasons to trust a Jew?</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130815</th>\n",
       "      <td>What are the considerations in using a static class vs. a singleton? I need a class to handle functions with no relevance to specific instances.</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107187</th>\n",
       "      <td>What is the purpose of the bit in a horse harness?</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856532</th>\n",
       "      <td>What is Annie Dillard known for?</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1044898 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                            question_text  \\\n",
       "172360                                                                                               Is there any beach available in Delhi for night out?   \n",
       "188522                                                                                             What is the unit of vector parallel to each of vector?   \n",
       "1235537                                                                                                                          How change LTE to VOlTE?   \n",
       "345543                                                                                            What percentage of US Democrat politicians are lawyers?   \n",
       "566414                                                                                      How did Cabela's Inc. manages to establish such large stores?   \n",
       "...                                                                                                                                                   ...   \n",
       "1180555                                                                                                 Where can I buy tamper proof courier bags online?   \n",
       "155574                                                                                                              What are some reasons to trust a Jew?   \n",
       "1130815  What are the considerations in using a static class vs. a singleton? I need a class to handle functions with no relevance to specific instances.   \n",
       "107187                                                                                                 What is the purpose of the bit in a horse harness?   \n",
       "856532                                                                                                                   What is Annie Dillard known for?   \n",
       "\n",
       "         target  Length  Words  Special Characters  Capital Words  \\\n",
       "172360        0      52     10                   1              2   \n",
       "188522        0      54     11                   1              1   \n",
       "1235537       0      24      5                   1              2   \n",
       "345543        0      55      8                   1              2   \n",
       "566414        0      61     10                   3              3   \n",
       "...         ...     ...    ...                 ...            ...   \n",
       "1180555       0      49      9                   1              1   \n",
       "155574        1      37      8                   1              2   \n",
       "1130815       0     144     25                   3              1   \n",
       "107187        0      50     11                   1              1   \n",
       "856532        0      32      6                   1              3   \n",
       "\n",
       "         Positive words  Negative words  \n",
       "172360                0               0  \n",
       "188522                0               0  \n",
       "1235537               0               0  \n",
       "345543                0               0  \n",
       "566414                0               0  \n",
       "...                 ...             ...  \n",
       "1180555               0               0  \n",
       "155574                1               0  \n",
       "1130815               0               0  \n",
       "107187                0               0  \n",
       "856532                0               0  \n",
       "\n",
       "[1044898 rows x 8 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of negative words used in sentence\n",
    "neglen=[]\n",
    "for i in train.index:\n",
    "    j=train.loc[i,'question_text']\n",
    "    neg=[]\n",
    "    for p in j.split():\n",
    "        if (senti.polarity_scores(p)['compound']) <= -0.5:\n",
    "            neg.append(p)\n",
    "    neglen.append(len(neg))\n",
    "train['Negative words']=neglen\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T17:54:42.397102Z",
     "start_time": "2020-04-02T17:54:15.621023Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "      <th>Length</th>\n",
       "      <th>Words</th>\n",
       "      <th>Special Characters</th>\n",
       "      <th>Capital Words</th>\n",
       "      <th>Positive words</th>\n",
       "      <th>Negative words</th>\n",
       "      <th>Stop words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>172360</th>\n",
       "      <td>Is there any beach available in Delhi for night out?</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188522</th>\n",
       "      <td>What is the unit of vector parallel to each of vector?</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235537</th>\n",
       "      <td>How change LTE to VOlTE?</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345543</th>\n",
       "      <td>What percentage of US Democrat politicians are lawyers?</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566414</th>\n",
       "      <td>How did Cabela's Inc. manages to establish such large stores?</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180555</th>\n",
       "      <td>Where can I buy tamper proof courier bags online?</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155574</th>\n",
       "      <td>What are some reasons to trust a Jew?</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130815</th>\n",
       "      <td>What are the considerations in using a static class vs. a singleton? I need a class to handle functions with no relevance to specific instances.</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107187</th>\n",
       "      <td>What is the purpose of the bit in a horse harness?</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856532</th>\n",
       "      <td>What is Annie Dillard known for?</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1044898 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                            question_text  \\\n",
       "172360                                                                                               Is there any beach available in Delhi for night out?   \n",
       "188522                                                                                             What is the unit of vector parallel to each of vector?   \n",
       "1235537                                                                                                                          How change LTE to VOlTE?   \n",
       "345543                                                                                            What percentage of US Democrat politicians are lawyers?   \n",
       "566414                                                                                      How did Cabela's Inc. manages to establish such large stores?   \n",
       "...                                                                                                                                                   ...   \n",
       "1180555                                                                                                 Where can I buy tamper proof courier bags online?   \n",
       "155574                                                                                                              What are some reasons to trust a Jew?   \n",
       "1130815  What are the considerations in using a static class vs. a singleton? I need a class to handle functions with no relevance to specific instances.   \n",
       "107187                                                                                                 What is the purpose of the bit in a horse harness?   \n",
       "856532                                                                                                                   What is Annie Dillard known for?   \n",
       "\n",
       "         target  Length  Words  Special Characters  Capital Words  \\\n",
       "172360        0      52     10                   1              2   \n",
       "188522        0      54     11                   1              1   \n",
       "1235537       0      24      5                   1              2   \n",
       "345543        0      55      8                   1              2   \n",
       "566414        0      61     10                   3              3   \n",
       "...         ...     ...    ...                 ...            ...   \n",
       "1180555       0      49      9                   1              1   \n",
       "155574        1      37      8                   1              2   \n",
       "1130815       0     144     25                   3              1   \n",
       "107187        0      50     11                   1              1   \n",
       "856532        0      32      6                   1              3   \n",
       "\n",
       "         Positive words  Negative words  Stop words  \n",
       "172360                0               0           4  \n",
       "188522                0               0           6  \n",
       "1235537               0               0           1  \n",
       "345543                0               0           2  \n",
       "566414                0               0           3  \n",
       "...                 ...             ...         ...  \n",
       "1180555               0               0           1  \n",
       "155574                1               0           4  \n",
       "1130815               0               0          10  \n",
       "107187                0               0           6  \n",
       "856532                0               0           1  \n",
       "\n",
       "[1044898 rows x 9 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of stop words used in sentence\n",
    "stp=nltk.corpus.stopwords.words('english')\n",
    "nostp=[]\n",
    "for i in train.index:\n",
    "    j=train.loc[i,'question_text']\n",
    "    stpwrds=[]\n",
    "    for p in j.split():\n",
    "        if p in stp:\n",
    "            stpwrds.append(p)\n",
    "    nostp.append(len(stpwrds))\n",
    "train['Stop words']=nostp\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T17:54:52.283274Z",
     "start_time": "2020-04-02T17:54:42.398351Z"
    }
   },
   "outputs": [],
   "source": [
    "# Number of exclamation marks used in sentence\n",
    "exc=[]\n",
    "for i in train.index:\n",
    "    c=0\n",
    "    j=train.loc[i,'question_text']\n",
    "    for k in j.split():\n",
    "        if k.endswith('!'):\n",
    "            c+=1\n",
    "    exc.append(c)\n",
    "train['Exclamation']=exc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T17:55:02.077909Z",
     "start_time": "2020-04-02T17:54:52.284272Z"
    }
   },
   "outputs": [],
   "source": [
    "# Number of question marks used in sentence\n",
    "ques=[]\n",
    "for i in train.index:\n",
    "    c=0\n",
    "    j=train.loc[i,'question_text']\n",
    "    for k in j.split():\n",
    "        if k.endswith('?'):\n",
    "            c+=1\n",
    "    ques.append(c)\n",
    "train[\"Question\"]=ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T18:08:16.753059Z",
     "start_time": "2020-04-02T17:55:02.078916Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 200 300 400 500 600 700 800 900 1000 1100 1200 1300 1400 1500 1600 1700 1800 1900 2000 2100 2200 2300 2400 2500 2600 2700 2800 2900 3000 3100 3200 3300 3400 3500 3600 3700 3800 3900 4000 4100 4200 4300 4400 4500 4600 4700 4800 4900 5000 5100 5200 5300 5400 5500 5600 5700 5800 5900 6000 6100 6200 6300 6400 6500 6600 6700 6800 6900 7000 7100 7200 7300 7400 7500 7600 7700 7800 7900 8000 8100 8200 8300 8400 8500 8600 8700 8800 8900 9000 9100 9200 9300 9400 9500 9600 9700 9800 9900 10000 10100 10200 10300 10400 10500 10600 10700 10800 10900 11000 11100 11200 11300 11400 11500 11600 11700 11800 11900 12000 12100 12200 12300 12400 12500 12600 12700 12800 12900 13000 13100 13200 13300 13400 13500 13600 13700 13800 13900 14000 14100 14200 14300 14400 14500 14600 14700 14800 14900 15000 15100 15200 15300 15400 15500 15600 15700 15800 15900 16000 16100 16200 16300 16400 16500 16600 16700 16800 16900 17000 17100 17200 17300 17400 17500 17600 17700 17800 17900 18000 18100 18200 18300 18400 18500 18600 18700 18800 18900 19000 19100 19200 19300 19400 19500 19600 19700 19800 19900 20000 20100 20200 20300 20400 20500 20600 20700 20800 20900 21000 21100 21200 21300 21400 21500 21600 21700 21800 21900 22000 22100 22200 22300 22400 22500 22600 22700 22800 22900 23000 23100 23200 23300 23400 23500 23600 23700 23800 23900 24000 24100 24200 24300 24400 24500 24600 24700 24800 24900 25000 25100 25200 25300 25400 25500 25600 25700 25800 25900 26000 26100 26200 26300 26400 26500 26600 26700 26800 26900 27000 27100 27200 27300 27400 27500 27600 27700 27800 27900 28000 28100 28200 28300 28400 28500 28600 28700 28800 28900 29000 29100 29200 29300 29400 29500 29600 29700 29800 29900 30000 30100 30200 30300 30400 30500 30600 30700 30800 30900 31000 31100 31200 31300 31400 31500 31600 31700 31800 31900 32000 32100 32200 32300 32400 32500 32600 32700 32800 32900 33000 33100 33200 33300 33400 33500 33600 33700 33800 33900 34000 34100 34200 34300 34400 34500 34600 34700 34800 34900 35000 35100 35200 35300 35400 35500 35600 35700 35800 35900 36000 36100 36200 36300 36400 36500 36600 36700 36800 36900 37000 37100 37200 37300 37400 37500 37600 37700 37800 37900 38000 38100 38200 38300 38400 38500 38600 38700 38800 38900 39000 39100 39200 39300 39400 39500 39600 39700 39800 39900 40000 40100 40200 40300 40400 40500 40600 40700 40800 40900 41000 41100 41200 41300 41400 41500 41600 41700 41800 41900 42000 42100 42200 42300 42400 42500 42600 42700 42800 42900 43000 43100 43200 43300 43400 43500 43600 43700 43800 43900 44000 44100 44200 44300 44400 44500 44600 44700 44800 44900 45000 45100 45200 45300 45400 45500 45600 45700 45800 45900 46000 46100 46200 46300 46400 46500 46600 46700 46800 46900 47000 47100 47200 47300 47400 47500 47600 47700 47800 47900 48000 48100 48200 48300 48400 48500 48600 48700 48800 48900 49000 49100 49200 49300 49400 49500 49600 49700 49800 49900 50000 50100 50200 50300 50400 50500 50600 50700 50800 50900 51000 51100 51200 51300 51400 51500 51600 51700 51800 51900 52000 52100 52200 52300 52400 52500 52600 52700 52800 52900 53000 53100 53200 53300 53400 53500 53600 53700 53800 53900 54000 54100 54200 54300 54400 54500 54600 54700 54800 54900 55000 55100 55200 55300 55400 55500 55600 55700 55800 55900 56000 56100 56200 56300 56400 56500 56600 56700 56800 56900 57000 57100 57200 57300 57400 57500 57600 57700 57800 57900 58000 58100 58200 58300 58400 58500 58600 58700 58800 58900 59000 59100 59200 59300 59400 59500 59600 59700 59800 59900 60000 60100 60200 60300 60400 60500 60600 60700 60800 60900 61000 61100 61200 61300 61400 61500 61600 61700 61800 61900 62000 62100 62200 62300 62400 62500 62600 62700 62800 62900 63000 63100 63200 63300 63400 63500 63600 63700 63800 63900 64000 64100 64200 64300 64400 64500 64600 64700 64800 64900 65000 65100 65200 65300 65400 65500 65600 65700 65800 65900 66000 66100 66200 66300 66400 66500 66600 66700 66800 66900 67000 67100 67200 67300 67400 67500 67600 67700 67800 67900 68000 68100 68200 68300 68400 68500 68600 68700 68800 68900 69000 69100 69200 69300 69400 69500 69600 69700 69800 69900 70000 70100 70200 70300 70400 70500 70600 70700 70800 70900 71000 71100 71200 71300 71400 71500 71600 71700 71800 71900 72000 72100 72200 72300 72400 72500 72600 72700 72800 72900 73000 73100 73200 73300 73400 73500 73600 73700 73800 73900 74000 74100 74200 74300 74400 74500 74600 74700 74800 74900 75000 75100 75200 75300 75400 75500 75600 75700 75800 75900 76000 76100 76200 76300 76400 76500 76600 76700 76800 76900 77000 77100 77200 77300 77400 77500 77600 77700 77800 77900 78000 78100 78200 78300 78400 78500 78600 78700 78800 78900 79000 79100 79200 79300 79400 79500 79600 79700 79800 79900 80000 80100 80200 80300 80400 80500 80600 80700 80800 80900 81000 81100 81200 81300 81400 81500 81600 81700 81800 81900 82000 82100 82200 82300 82400 82500 82600 82700 82800 82900 83000 83100 83200 83300 83400 83500 83600 83700 83800 83900 84000 84100 84200 84300 84400 84500 84600 84700 84800 84900 85000 85100 85200 85300 85400 85500 85600 85700 85800 85900 86000 86100 86200 86300 86400 86500 86600 86700 86800 86900 87000 87100 87200 87300 87400 87500 87600 87700 87800 87900 88000 88100 88200 88300 88400 88500 88600 88700 88800 88900 89000 89100 89200 89300 89400 89500 89600 89700 89800 89900 90000 90100 90200 90300 90400 90500 90600 90700 90800 90900 91000 91100 91200 91300 91400 91500 91600 91700 91800 91900 92000 92100 92200 92300 92400 92500 92600 92700 92800 92900 93000 93100 93200 93300 93400 93500 93600 93700 93800 93900 94000 94100 94200 94300 94400 94500 94600 94700 94800 94900 95000 95100 95200 95300 95400 95500 95600 95700 95800 95900 96000 96100 96200 96300 96400 96500 96600 96700 96800 96900 97000 97100 97200 97300 97400 97500 97600 97700 97800 97900 98000 98100 98200 98300 98400 98500 98600 98700 98800 98900 99000 99100 99200 99300 99400 99500 99600 99700 99800 99900 100000 100100 100200 100300 100400 100500 100600 100700 100800 100900 101000 101100 101200 101300 101400 101500 101600 101700 101800 101900 102000 102100 102200 102300 102400 102500 102600 102700 102800 102900 103000 103100 103200 103300 103400 103500 103600 103700 103800 103900 104000 104100 104200 104300 104400 104500 104600 104700 104800 104900 105000 105100 105200 105300 105400 105500 105600 105700 105800 105900 106000 106100 106200 106300 106400 106500 106600 106700 106800 106900 107000 107100 107200 107300 107400 107500 107600 107700 107800 107900 108000 108100 108200 108300 108400 108500 108600 108700 108800 108900 109000 109100 109200 109300 109400 109500 109600 109700 109800 109900 110000 110100 110200 110300 110400 110500 110600 110700 110800 110900 111000 111100 111200 111300 111400 111500 111600 111700 111800 111900 112000 112100 112200 112300 112400 112500 112600 112700 112800 112900 113000 113100 113200 113300 113400 113500 113600 113700 113800 113900 114000 114100 114200 114300 114400 114500 114600 114700 114800 114900 115000 115100 115200 115300 115400 115500 115600 115700 115800 115900 116000 116100 116200 116300 116400 116500 116600 116700 116800 116900 117000 117100 117200 117300 117400 117500 117600 117700 117800 117900 118000 118100 118200 118300 118400 118500 118600 118700 118800 118900 119000 119100 119200 119300 119400 119500 119600 119700 119800 119900 120000 120100 120200 120300 120400 120500 120600 120700 120800 120900 121000 121100 121200 121300 121400 121500 121600 121700 121800 121900 122000 122100 122200 122300 122400 122500 122600 122700 122800 122900 123000 123100 123200 123300 123400 123500 123600 123700 123800 123900 124000 124100 124200 124300 124400 124500 124600 124700 124800 124900 125000 125100 125200 125300 125400 125500 125600 125700 125800 125900 126000 126100 126200 126300 126400 126500 126600 126700 126800 126900 127000 127100 127200 127300 127400 127500 127600 127700 127800 127900 128000 128100 128200 128300 128400 128500 128600 128700 128800 128900 129000 129100 129200 129300 129400 129500 129600 129700 129800 129900 130000 130100 130200 130300 130400 130500 130600 130700 130800 130900 131000 131100 131200 131300 131400 131500 131600 131700 131800 131900 132000 132100 132200 132300 132400 132500 132600 132700 132800 132900 133000 133100 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133200 133300 133400 133500 133600 133700 133800 133900 134000 134100 134200 134300 134400 134500 134600 134700 134800 134900 135000 135100 135200 135300 135400 135500 135600 135700 135800 135900 136000 136100 136200 136300 136400 136500 136600 136700 136800 136900 137000 137100 137200 137300 137400 137500 137600 137700 137800 137900 138000 138100 138200 138300 138400 138500 138600 138700 138800 138900 139000 139100 139200 139300 139400 139500 139600 139700 139800 139900 140000 140100 140200 140300 140400 140500 140600 140700 140800 140900 141000 141100 141200 141300 141400 141500 141600 141700 141800 141900 142000 142100 142200 142300 142400 142500 142600 142700 142800 142900 143000 143100 143200 143300 143400 143500 143600 143700 143800 143900 144000 144100 144200 144300 144400 144500 144600 144700 144800 144900 145000 145100 145200 145300 145400 145500 145600 145700 145800 145900 146000 146100 146200 146300 146400 146500 146600 146700 146800 146900 147000 147100 147200 147300 147400 147500 147600 147700 147800 147900 148000 148100 148200 148300 148400 148500 148600 148700 148800 148900 149000 149100 149200 149300 149400 149500 149600 149700 149800 149900 150000 150100 150200 150300 150400 150500 150600 150700 150800 150900 151000 151100 151200 151300 151400 151500 151600 151700 151800 151900 152000 152100 152200 152300 152400 152500 152600 152700 152800 152900 153000 153100 153200 153300 153400 153500 153600 153700 153800 153900 154000 154100 154200 154300 154400 154500 154600 154700 154800 154900 155000 155100 155200 155300 155400 155500 155600 155700 155800 155900 156000 156100 156200 156300 156400 156500 156600 156700 156800 156900 157000 157100 157200 157300 157400 157500 157600 157700 157800 157900 158000 158100 158200 158300 158400 158500 158600 158700 158800 158900 159000 159100 159200 159300 159400 159500 159600 159700 159800 159900 160000 160100 160200 160300 160400 160500 160600 160700 160800 160900 161000 161100 161200 161300 161400 161500 161600 161700 161800 161900 162000 162100 162200 162300 162400 162500 162600 162700 162800 162900 163000 163100 163200 163300 163400 163500 163600 163700 163800 163900 164000 164100 164200 164300 164400 164500 164600 164700 164800 164900 165000 165100 165200 165300 165400 165500 165600 165700 165800 165900 166000 166100 166200 166300 166400 166500 166600 166700 166800 166900 167000 167100 167200 167300 167400 167500 167600 167700 167800 167900 168000 168100 168200 168300 168400 168500 168600 168700 168800 168900 169000 169100 169200 169300 169400 169500 169600 169700 169800 169900 170000 170100 170200 170300 170400 170500 170600 170700 170800 170900 171000 171100 171200 171300 171400 171500 171600 171700 171800 171900 172000 172100 172200 172300 172400 172500 172600 172700 172800 172900 173000 173100 173200 173300 173400 173500 173600 173700 173800 173900 174000 174100 174200 174300 174400 174500 174600 174700 174800 174900 175000 175100 175200 175300 175400 175500 175600 175700 175800 175900 176000 176100 176200 176300 176400 176500 176600 176700 176800 176900 177000 177100 177200 177300 177400 177500 177600 177700 177800 177900 178000 178100 178200 178300 178400 178500 178600 178700 178800 178900 179000 179100 179200 179300 179400 179500 179600 179700 179800 179900 180000 180100 180200 180300 180400 180500 180600 180700 180800 180900 181000 181100 181200 181300 181400 181500 181600 181700 181800 181900 182000 182100 182200 182300 182400 182500 182600 182700 182800 182900 183000 183100 183200 183300 183400 183500 183600 183700 183800 183900 184000 184100 184200 184300 184400 184500 184600 184700 184800 184900 185000 185100 185200 185300 185400 185500 185600 185700 185800 185900 186000 186100 186200 186300 186400 186500 186600 186700 186800 186900 187000 187100 187200 187300 187400 187500 187600 187700 187800 187900 188000 188100 188200 188300 188400 188500 188600 188700 188800 188900 189000 189100 189200 189300 189400 189500 189600 189700 189800 189900 190000 190100 190200 190300 190400 190500 190600 190700 190800 190900 191000 191100 191200 191300 191400 191500 191600 191700 191800 191900 192000 192100 192200 192300 192400 192500 192600 192700 192800 192900 193000 193100 193200 193300 193400 193500 193600 193700 193800 193900 194000 194100 194200 194300 194400 194500 194600 194700 194800 194900 195000 195100 195200 195300 195400 195500 195600 195700 195800 195900 196000 196100 196200 196300 196400 196500 196600 196700 196800 196900 197000 197100 197200 197300 197400 197500 197600 197700 197800 197900 198000 198100 198200 198300 198400 198500 198600 198700 198800 198900 199000 199100 199200 199300 199400 199500 199600 199700 199800 199900 200000 200100 200200 200300 200400 200500 200600 200700 200800 200900 201000 201100 201200 201300 201400 201500 201600 201700 201800 201900 202000 202100 202200 202300 202400 202500 202600 202700 202800 202900 203000 203100 203200 203300 203400 203500 203600 203700 203800 203900 204000 204100 204200 204300 204400 204500 204600 204700 204800 204900 205000 205100 205200 205300 205400 205500 205600 205700 205800 205900 206000 206100 206200 206300 206400 206500 206600 206700 206800 206900 207000 207100 207200 207300 207400 207500 207600 207700 207800 207900 208000 208100 208200 208300 208400 208500 208600 208700 208800 208900 209000 209100 209200 209300 209400 209500 209600 209700 209800 209900 210000 210100 210200 210300 210400 210500 210600 210700 210800 210900 211000 211100 211200 211300 211400 211500 211600 211700 211800 211900 212000 212100 212200 212300 212400 212500 212600 212700 212800 212900 213000 213100 213200 213300 213400 213500 213600 213700 213800 213900 214000 214100 214200 214300 214400 214500 214600 214700 214800 214900 215000 215100 215200 215300 215400 215500 215600 215700 215800 215900 216000 216100 216200 216300 216400 216500 216600 216700 216800 216900 217000 217100 217200 217300 217400 217500 217600 217700 217800 217900 218000 218100 218200 218300 218400 218500 218600 218700 218800 218900 219000 219100 219200 219300 219400 219500 219600 219700 219800 219900 220000 220100 220200 220300 220400 220500 220600 220700 220800 220900 221000 221100 221200 221300 221400 221500 221600 221700 221800 221900 222000 222100 222200 222300 222400 222500 222600 222700 222800 222900 223000 223100 223200 223300 223400 223500 223600 223700 223800 223900 224000 224100 224200 224300 224400 224500 224600 224700 224800 224900 225000 225100 225200 225300 225400 225500 225600 225700 225800 225900 226000 226100 226200 226300 226400 226500 226600 226700 226800 226900 227000 227100 227200 227300 227400 227500 227600 227700 227800 227900 228000 228100 228200 228300 228400 228500 228600 228700 228800 228900 229000 229100 229200 229300 229400 229500 229600 229700 229800 229900 230000 230100 230200 230300 230400 230500 230600 230700 230800 230900 231000 231100 231200 231300 231400 231500 231600 231700 231800 231900 232000 232100 232200 232300 232400 232500 232600 232700 232800 232900 233000 233100 233200 233300 233400 233500 233600 233700 233800 233900 234000 234100 234200 234300 234400 234500 234600 234700 234800 234900 235000 235100 235200 235300 235400 235500 235600 235700 235800 235900 236000 236100 236200 236300 236400 236500 236600 236700 236800 236900 237000 237100 237200 237300 237400 237500 237600 237700 237800 237900 238000 238100 238200 238300 238400 238500 238600 238700 238800 238900 239000 239100 239200 239300 239400 239500 239600 239700 239800 239900 240000 240100 240200 240300 240400 240500 240600 240700 240800 240900 241000 241100 241200 241300 241400 241500 241600 241700 241800 241900 242000 242100 242200 242300 242400 242500 242600 242700 242800 242900 243000 243100 243200 243300 243400 243500 243600 243700 243800 243900 244000 244100 244200 244300 244400 244500 244600 244700 244800 244900 245000 245100 245200 245300 245400 245500 245600 245700 245800 245900 246000 246100 246200 246300 246400 246500 246600 246700 246800 246900 247000 247100 247200 247300 247400 247500 247600 247700 247800 247900 248000 248100 248200 248300 248400 248500 248600 248700 248800 248900 249000 249100 249200 249300 249400 249500 249600 249700 249800 249900 250000 250100 250200 250300 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250400 250500 250600 250700 250800 250900 251000 251100 251200 251300 251400 251500 251600 251700 251800 251900 252000 252100 252200 252300 252400 252500 252600 252700 252800 252900 253000 253100 253200 253300 253400 253500 253600 253700 253800 253900 254000 254100 254200 254300 254400 254500 254600 254700 254800 254900 255000 255100 255200 255300 255400 255500 255600 255700 255800 255900 256000 256100 256200 256300 256400 256500 256600 256700 256800 256900 257000 257100 257200 257300 257400 257500 257600 257700 257800 257900 258000 258100 258200 258300 258400 258500 258600 258700 258800 258900 259000 259100 259200 259300 259400 259500 259600 259700 259800 259900 260000 260100 260200 260300 260400 260500 260600 260700 260800 260900 261000 261100 261200 261300 261400 261500 261600 261700 261800 261900 262000 262100 262200 262300 262400 262500 262600 262700 262800 262900 263000 263100 263200 263300 263400 263500 263600 263700 263800 263900 264000 264100 264200 264300 264400 264500 264600 264700 264800 264900 265000 265100 265200 265300 265400 265500 265600 265700 265800 265900 266000 266100 266200 266300 266400 266500 266600 266700 266800 266900 267000 267100 267200 267300 267400 267500 267600 267700 267800 267900 268000 268100 268200 268300 268400 268500 268600 268700 268800 268900 269000 269100 269200 269300 269400 269500 269600 269700 269800 269900 270000 270100 270200 270300 270400 270500 270600 270700 270800 270900 271000 271100 271200 271300 271400 271500 271600 271700 271800 271900 272000 272100 272200 272300 272400 272500 272600 272700 272800 272900 273000 273100 273200 273300 273400 273500 273600 273700 273800 273900 274000 274100 274200 274300 274400 274500 274600 274700 274800 274900 275000 275100 275200 275300 275400 275500 275600 275700 275800 275900 276000 276100 276200 276300 276400 276500 276600 276700 276800 276900 277000 277100 277200 277300 277400 277500 277600 277700 277800 277900 278000 278100 278200 278300 278400 278500 278600 278700 278800 278900 279000 279100 279200 279300 279400 279500 279600 279700 279800 279900 280000 280100 280200 280300 280400 280500 280600 280700 280800 280900 281000 281100 281200 281300 281400 281500 281600 281700 281800 281900 282000 282100 282200 282300 282400 282500 282600 282700 282800 282900 283000 283100 283200 283300 283400 283500 283600 283700 283800 283900 284000 284100 284200 284300 284400 284500 284600 284700 284800 284900 285000 285100 285200 285300 285400 285500 285600 285700 285800 285900 286000 286100 286200 286300 286400 286500 286600 286700 286800 286900 287000 287100 287200 287300 287400 287500 287600 287700 287800 287900 288000 288100 288200 288300 288400 288500 288600 288700 288800 288900 289000 289100 289200 289300 289400 289500 289600 289700 289800 289900 290000 290100 290200 290300 290400 290500 290600 290700 290800 290900 291000 291100 291200 291300 291400 291500 291600 291700 291800 291900 292000 292100 292200 292300 292400 292500 292600 292700 292800 292900 293000 293100 293200 293300 293400 293500 293600 293700 293800 293900 294000 294100 294200 294300 294400 294500 294600 294700 294800 294900 295000 295100 295200 295300 295400 295500 295600 295700 295800 295900 296000 296100 296200 296300 296400 296500 296600 296700 296800 296900 297000 297100 297200 297300 297400 297500 297600 297700 297800 297900 298000 298100 298200 298300 298400 298500 298600 298700 298800 298900 299000 299100 299200 299300 299400 299500 299600 299700 299800 299900 300000 300100 300200 300300 300400 300500 300600 300700 300800 300900 301000 301100 301200 301300 301400 301500 301600 301700 301800 301900 302000 302100 302200 302300 302400 302500 302600 302700 302800 302900 303000 303100 303200 303300 303400 303500 303600 303700 303800 303900 304000 304100 304200 304300 304400 304500 304600 304700 304800 304900 305000 305100 305200 305300 305400 305500 305600 305700 305800 305900 306000 306100 306200 306300 306400 306500 306600 306700 306800 306900 307000 307100 307200 307300 307400 307500 307600 307700 307800 307900 308000 308100 308200 308300 308400 308500 308600 308700 308800 308900 309000 309100 309200 309300 309400 309500 309600 309700 309800 309900 310000 310100 310200 310300 310400 310500 310600 310700 310800 310900 311000 311100 311200 311300 311400 311500 311600 311700 311800 311900 312000 312100 312200 312300 312400 312500 312600 312700 312800 312900 313000 313100 313200 313300 313400 313500 313600 313700 313800 313900 314000 314100 314200 314300 314400 314500 314600 314700 314800 314900 315000 315100 315200 315300 315400 315500 315600 315700 315800 315900 316000 316100 316200 316300 316400 316500 316600 316700 316800 316900 317000 317100 317200 317300 317400 317500 317600 317700 317800 317900 318000 318100 318200 318300 318400 318500 318600 318700 318800 318900 319000 319100 319200 319300 319400 319500 319600 319700 319800 319900 320000 320100 320200 320300 320400 320500 320600 320700 320800 320900 321000 321100 321200 321300 321400 321500 321600 321700 321800 321900 322000 322100 322200 322300 322400 322500 322600 322700 322800 322900 323000 323100 323200 323300 323400 323500 323600 323700 323800 323900 324000 324100 324200 324300 324400 324500 324600 324700 324800 324900 325000 325100 325200 325300 325400 325500 325600 325700 325800 325900 326000 326100 326200 326300 326400 326500 326600 326700 326800 326900 327000 327100 327200 327300 327400 327500 327600 327700 327800 327900 328000 328100 328200 328300 328400 328500 328600 328700 328800 328900 329000 329100 329200 329300 329400 329500 329600 329700 329800 329900 330000 330100 330200 330300 330400 330500 330600 330700 330800 330900 331000 331100 331200 331300 331400 331500 331600 331700 331800 331900 332000 332100 332200 332300 332400 332500 332600 332700 332800 332900 333000 333100 333200 333300 333400 333500 333600 333700 333800 333900 334000 334100 334200 334300 334400 334500 334600 334700 334800 334900 335000 335100 335200 335300 335400 335500 335600 335700 335800 335900 336000 336100 336200 336300 336400 336500 336600 336700 336800 336900 337000 337100 337200 337300 337400 337500 337600 337700 337800 337900 338000 338100 338200 338300 338400 338500 338600 338700 338800 338900 339000 339100 339200 339300 339400 339500 339600 339700 339800 339900 340000 340100 340200 340300 340400 340500 340600 340700 340800 340900 341000 341100 341200 341300 341400 341500 341600 341700 341800 341900 342000 342100 342200 342300 342400 342500 342600 342700 342800 342900 343000 343100 343200 343300 343400 343500 343600 343700 343800 343900 344000 344100 344200 344300 344400 344500 344600 344700 344800 344900 345000 345100 345200 345300 345400 345500 345600 345700 345800 345900 346000 346100 346200 346300 346400 346500 346600 346700 346800 346900 347000 347100 347200 347300 347400 347500 347600 347700 347800 347900 348000 348100 348200 348300 348400 348500 348600 348700 348800 348900 349000 349100 349200 349300 349400 349500 349600 349700 349800 349900 350000 350100 350200 350300 350400 350500 350600 350700 350800 350900 351000 351100 351200 351300 351400 351500 351600 351700 351800 351900 352000 352100 352200 352300 352400 352500 352600 352700 352800 352900 353000 353100 353200 353300 353400 353500 353600 353700 353800 353900 354000 354100 354200 354300 354400 354500 354600 354700 354800 354900 355000 355100 355200 355300 355400 355500 355600 355700 355800 355900 356000 356100 356200 356300 356400 356500 356600 356700 356800 356900 357000 357100 357200 357300 357400 357500 357600 357700 357800 357900 358000 358100 358200 358300 358400 358500 358600 358700 358800 358900 359000 359100 359200 359300 359400 359500 359600 359700 359800 359900 360000 360100 360200 360300 360400 360500 360600 360700 360800 360900 361000 361100 361200 361300 361400 361500 361600 361700 361800 361900 362000 362100 362200 362300 362400 362500 362600 362700 362800 362900 363000 363100 363200 363300 363400 363500 363600 363700 363800 363900 364000 364100 364200 364300 364400 364500 364600 364700 364800 364900 365000 365100 365200 365300 365400 365500 365600 365700 365800 365900 366000 366100 366200 366300 366400 366500 366600 366700 366800 366900 367000 367100 367200 367300 367400 367500 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367600 367700 367800 367900 368000 368100 368200 368300 368400 368500 368600 368700 368800 368900 369000 369100 369200 369300 369400 369500 369600 369700 369800 369900 370000 370100 370200 370300 370400 370500 370600 370700 370800 370900 371000 371100 371200 371300 371400 371500 371600 371700 371800 371900 372000 372100 372200 372300 372400 372500 372600 372700 372800 372900 373000 373100 373200 373300 373400 373500 373600 373700 373800 373900 374000 374100 374200 374300 374400 374500 374600 374700 374800 374900 375000 375100 375200 375300 375400 375500 375600 375700 375800 375900 376000 376100 376200 376300 376400 376500 376600 376700 376800 376900 377000 377100 377200 377300 377400 377500 377600 377700 377800 377900 378000 378100 378200 378300 378400 378500 378600 378700 378800 378900 379000 379100 379200 379300 379400 379500 379600 379700 379800 379900 380000 380100 380200 380300 380400 380500 380600 380700 380800 380900 381000 381100 381200 381300 381400 381500 381600 381700 381800 381900 382000 382100 382200 382300 382400 382500 382600 382700 382800 382900 383000 383100 383200 383300 383400 383500 383600 383700 383800 383900 384000 384100 384200 384300 384400 384500 384600 384700 384800 384900 385000 385100 385200 385300 385400 385500 385600 385700 385800 385900 386000 386100 386200 386300 386400 386500 386600 386700 386800 386900 387000 387100 387200 387300 387400 387500 387600 387700 387800 387900 388000 388100 388200 388300 388400 388500 388600 388700 388800 388900 389000 389100 389200 389300 389400 389500 389600 389700 389800 389900 390000 390100 390200 390300 390400 390500 390600 390700 390800 390900 391000 391100 391200 391300 391400 391500 391600 391700 391800 391900 392000 392100 392200 392300 392400 392500 392600 392700 392800 392900 393000 393100 393200 393300 393400 393500 393600 393700 393800 393900 394000 394100 394200 394300 394400 394500 394600 394700 394800 394900 395000 395100 395200 395300 395400 395500 395600 395700 395800 395900 396000 396100 396200 396300 396400 396500 396600 396700 396800 396900 397000 397100 397200 397300 397400 397500 397600 397700 397800 397900 398000 398100 398200 398300 398400 398500 398600 398700 398800 398900 399000 399100 399200 399300 399400 399500 399600 399700 399800 399900 400000 400100 400200 400300 400400 400500 400600 400700 400800 400900 401000 401100 401200 401300 401400 401500 401600 401700 401800 401900 402000 402100 402200 402300 402400 402500 402600 402700 402800 402900 403000 403100 403200 403300 403400 403500 403600 403700 403800 403900 404000 404100 404200 404300 404400 404500 404600 404700 404800 404900 405000 405100 405200 405300 405400 405500 405600 405700 405800 405900 406000 406100 406200 406300 406400 406500 406600 406700 406800 406900 407000 407100 407200 407300 407400 407500 407600 407700 407800 407900 408000 408100 408200 408300 408400 408500 408600 408700 408800 408900 409000 409100 409200 409300 409400 409500 409600 409700 409800 409900 410000 410100 410200 410300 410400 410500 410600 410700 410800 410900 411000 411100 411200 411300 411400 411500 411600 411700 411800 411900 412000 412100 412200 412300 412400 412500 412600 412700 412800 412900 413000 413100 413200 413300 413400 413500 413600 413700 413800 413900 414000 414100 414200 414300 414400 414500 414600 414700 414800 414900 415000 415100 415200 415300 415400 415500 415600 415700 415800 415900 416000 416100 416200 416300 416400 416500 416600 416700 416800 416900 417000 417100 417200 417300 417400 417500 417600 417700 417800 417900 418000 418100 418200 418300 418400 418500 418600 418700 418800 418900 419000 419100 419200 419300 419400 419500 419600 419700 419800 419900 420000 420100 420200 420300 420400 420500 420600 420700 420800 420900 421000 421100 421200 421300 421400 421500 421600 421700 421800 421900 422000 422100 422200 422300 422400 422500 422600 422700 422800 422900 423000 423100 423200 423300 423400 423500 423600 423700 423800 423900 424000 424100 424200 424300 424400 424500 424600 424700 424800 424900 425000 425100 425200 425300 425400 425500 425600 425700 425800 425900 426000 426100 426200 426300 426400 426500 426600 426700 426800 426900 427000 427100 427200 427300 427400 427500 427600 427700 427800 427900 428000 428100 428200 428300 428400 428500 428600 428700 428800 428900 429000 429100 429200 429300 429400 429500 429600 429700 429800 429900 430000 430100 430200 430300 430400 430500 430600 430700 430800 430900 431000 431100 431200 431300 431400 431500 431600 431700 431800 431900 432000 432100 432200 432300 432400 432500 432600 432700 432800 432900 433000 433100 433200 433300 433400 433500 433600 433700 433800 433900 434000 434100 434200 434300 434400 434500 434600 434700 434800 434900 435000 435100 435200 435300 435400 435500 435600 435700 435800 435900 436000 436100 436200 436300 436400 436500 436600 436700 436800 436900 437000 437100 437200 437300 437400 437500 437600 437700 437800 437900 438000 438100 438200 438300 438400 438500 438600 438700 438800 438900 439000 439100 439200 439300 439400 439500 439600 439700 439800 439900 440000 440100 440200 440300 440400 440500 440600 440700 440800 440900 441000 441100 441200 441300 441400 441500 441600 441700 441800 441900 442000 442100 442200 442300 442400 442500 442600 442700 442800 442900 443000 443100 443200 443300 443400 443500 443600 443700 443800 443900 444000 444100 444200 444300 444400 444500 444600 444700 444800 444900 445000 445100 445200 445300 445400 445500 445600 445700 445800 445900 446000 446100 446200 446300 446400 446500 446600 446700 446800 446900 447000 447100 447200 447300 447400 447500 447600 447700 447800 447900 448000 448100 448200 448300 448400 448500 448600 448700 448800 448900 449000 449100 449200 449300 449400 449500 449600 449700 449800 449900 450000 450100 450200 450300 450400 450500 450600 450700 450800 450900 451000 451100 451200 451300 451400 451500 451600 451700 451800 451900 452000 452100 452200 452300 452400 452500 452600 452700 452800 452900 453000 453100 453200 453300 453400 453500 453600 453700 453800 453900 454000 454100 454200 454300 454400 454500 454600 454700 454800 454900 455000 455100 455200 455300 455400 455500 455600 455700 455800 455900 456000 456100 456200 456300 456400 456500 456600 456700 456800 456900 457000 457100 457200 457300 457400 457500 457600 457700 457800 457900 458000 458100 458200 458300 458400 458500 458600 458700 458800 458900 459000 459100 459200 459300 459400 459500 459600 459700 459800 459900 460000 460100 460200 460300 460400 460500 460600 460700 460800 460900 461000 461100 461200 461300 461400 461500 461600 461700 461800 461900 462000 462100 462200 462300 462400 462500 462600 462700 462800 462900 463000 463100 463200 463300 463400 463500 463600 463700 463800 463900 464000 464100 464200 464300 464400 464500 464600 464700 464800 464900 465000 465100 465200 465300 465400 465500 465600 465700 465800 465900 466000 466100 466200 466300 466400 466500 466600 466700 466800 466900 467000 467100 467200 467300 467400 467500 467600 467700 467800 467900 468000 468100 468200 468300 468400 468500 468600 468700 468800 468900 469000 469100 469200 469300 469400 469500 469600 469700 469800 469900 470000 470100 470200 470300 470400 470500 470600 470700 470800 470900 471000 471100 471200 471300 471400 471500 471600 471700 471800 471900 472000 472100 472200 472300 472400 472500 472600 472700 472800 472900 473000 473100 473200 473300 473400 473500 473600 473700 473800 473900 474000 474100 474200 474300 474400 474500 474600 474700 474800 474900 475000 475100 475200 475300 475400 475500 475600 475700 475800 475900 476000 476100 476200 476300 476400 476500 476600 476700 476800 476900 477000 477100 477200 477300 477400 477500 477600 477700 477800 477900 478000 478100 478200 478300 478400 478500 478600 478700 478800 478900 479000 479100 479200 479300 479400 479500 479600 479700 479800 479900 480000 480100 480200 480300 480400 480500 480600 480700 480800 480900 481000 481100 481200 481300 481400 481500 481600 481700 481800 481900 482000 482100 482200 482300 482400 482500 482600 482700 482800 482900 483000 483100 483200 483300 483400 483500 483600 483700 483800 483900 484000 484100 484200 484300 484400 484500 484600 484700 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484800 484900 485000 485100 485200 485300 485400 485500 485600 485700 485800 485900 486000 486100 486200 486300 486400 486500 486600 486700 486800 486900 487000 487100 487200 487300 487400 487500 487600 487700 487800 487900 488000 488100 488200 488300 488400 488500 488600 488700 488800 488900 489000 489100 489200 489300 489400 489500 489600 489700 489800 489900 490000 490100 490200 490300 490400 490500 490600 490700 490800 490900 491000 491100 491200 491300 491400 491500 491600 491700 491800 491900 492000 492100 492200 492300 492400 492500 492600 492700 492800 492900 493000 493100 493200 493300 493400 493500 493600 493700 493800 493900 494000 494100 494200 494300 494400 494500 494600 494700 494800 494900 495000 495100 495200 495300 495400 495500 495600 495700 495800 495900 496000 496100 496200 496300 496400 496500 496600 496700 496800 496900 497000 497100 497200 497300 497400 497500 497600 497700 497800 497900 498000 498100 498200 498300 498400 498500 498600 498700 498800 498900 499000 499100 499200 499300 499400 499500 499600 499700 499800 499900 500000 500100 500200 500300 500400 500500 500600 500700 500800 500900 501000 501100 501200 501300 501400 501500 501600 501700 501800 501900 502000 502100 502200 502300 502400 502500 502600 502700 502800 502900 503000 503100 503200 503300 503400 503500 503600 503700 503800 503900 504000 504100 504200 504300 504400 504500 504600 504700 504800 504900 505000 505100 505200 505300 505400 505500 505600 505700 505800 505900 506000 506100 506200 506300 506400 506500 506600 506700 506800 506900 507000 507100 507200 507300 507400 507500 507600 507700 507800 507900 508000 508100 508200 508300 508400 508500 508600 508700 508800 508900 509000 509100 509200 509300 509400 509500 509600 509700 509800 509900 510000 510100 510200 510300 510400 510500 510600 510700 510800 510900 511000 511100 511200 511300 511400 511500 511600 511700 511800 511900 512000 512100 512200 512300 512400 512500 512600 512700 512800 512900 513000 513100 513200 513300 513400 513500 513600 513700 513800 513900 514000 514100 514200 514300 514400 514500 514600 514700 514800 514900 515000 515100 515200 515300 515400 515500 515600 515700 515800 515900 516000 516100 516200 516300 516400 516500 516600 516700 516800 516900 517000 517100 517200 517300 517400 517500 517600 517700 517800 517900 518000 518100 518200 518300 518400 518500 518600 518700 518800 518900 519000 519100 519200 519300 519400 519500 519600 519700 519800 519900 520000 520100 520200 520300 520400 520500 520600 520700 520800 520900 521000 521100 521200 521300 521400 521500 521600 521700 521800 521900 522000 522100 522200 522300 522400 522500 522600 522700 522800 522900 523000 523100 523200 523300 523400 523500 523600 523700 523800 523900 524000 524100 524200 524300 524400 524500 524600 524700 524800 524900 525000 525100 525200 525300 525400 525500 525600 525700 525800 525900 526000 526100 526200 526300 526400 526500 526600 526700 526800 526900 527000 527100 527200 527300 527400 527500 527600 527700 527800 527900 528000 528100 528200 528300 528400 528500 528600 528700 528800 528900 529000 529100 529200 529300 529400 529500 529600 529700 529800 529900 530000 530100 530200 530300 530400 530500 530600 530700 530800 530900 531000 531100 531200 531300 531400 531500 531600 531700 531800 531900 532000 532100 532200 532300 532400 532500 532600 532700 532800 532900 533000 533100 533200 533300 533400 533500 533600 533700 533800 533900 534000 534100 534200 534300 534400 534500 534600 534700 534800 534900 535000 535100 535200 535300 535400 535500 535600 535700 535800 535900 536000 536100 536200 536300 536400 536500 536600 536700 536800 536900 537000 537100 537200 537300 537400 537500 537600 537700 537800 537900 538000 538100 538200 538300 538400 538500 538600 538700 538800 538900 539000 539100 539200 539300 539400 539500 539600 539700 539800 539900 540000 540100 540200 540300 540400 540500 540600 540700 540800 540900 541000 541100 541200 541300 541400 541500 541600 541700 541800 541900 542000 542100 542200 542300 542400 542500 542600 542700 542800 542900 543000 543100 543200 543300 543400 543500 543600 543700 543800 543900 544000 544100 544200 544300 544400 544500 544600 544700 544800 544900 545000 545100 545200 545300 545400 545500 545600 545700 545800 545900 546000 546100 546200 546300 546400 546500 546600 546700 546800 546900 547000 547100 547200 547300 547400 547500 547600 547700 547800 547900 548000 548100 548200 548300 548400 548500 548600 548700 548800 548900 549000 549100 549200 549300 549400 549500 549600 549700 549800 549900 550000 550100 550200 550300 550400 550500 550600 550700 550800 550900 551000 551100 551200 551300 551400 551500 551600 551700 551800 551900 552000 552100 552200 552300 552400 552500 552600 552700 552800 552900 553000 553100 553200 553300 553400 553500 553600 553700 553800 553900 554000 554100 554200 554300 554400 554500 554600 554700 554800 554900 555000 555100 555200 555300 555400 555500 555600 555700 555800 555900 556000 556100 556200 556300 556400 556500 556600 556700 556800 556900 557000 557100 557200 557300 557400 557500 557600 557700 557800 557900 558000 558100 558200 558300 558400 558500 558600 558700 558800 558900 559000 559100 559200 559300 559400 559500 559600 559700 559800 559900 560000 560100 560200 560300 560400 560500 560600 560700 560800 560900 561000 561100 561200 561300 561400 561500 561600 561700 561800 561900 562000 562100 562200 562300 562400 562500 562600 562700 562800 562900 563000 563100 563200 563300 563400 563500 563600 563700 563800 563900 564000 564100 564200 564300 564400 564500 564600 564700 564800 564900 565000 565100 565200 565300 565400 565500 565600 565700 565800 565900 566000 566100 566200 566300 566400 566500 566600 566700 566800 566900 567000 567100 567200 567300 567400 567500 567600 567700 567800 567900 568000 568100 568200 568300 568400 568500 568600 568700 568800 568900 569000 569100 569200 569300 569400 569500 569600 569700 569800 569900 570000 570100 570200 570300 570400 570500 570600 570700 570800 570900 571000 571100 571200 571300 571400 571500 571600 571700 571800 571900 572000 572100 572200 572300 572400 572500 572600 572700 572800 572900 573000 573100 573200 573300 573400 573500 573600 573700 573800 573900 574000 574100 574200 574300 574400 574500 574600 574700 574800 574900 575000 575100 575200 575300 575400 575500 575600 575700 575800 575900 576000 576100 576200 576300 576400 576500 576600 576700 576800 576900 577000 577100 577200 577300 577400 577500 577600 577700 577800 577900 578000 578100 578200 578300 578400 578500 578600 578700 578800 578900 579000 579100 579200 579300 579400 579500 579600 579700 579800 579900 580000 580100 580200 580300 580400 580500 580600 580700 580800 580900 581000 581100 581200 581300 581400 581500 581600 581700 581800 581900 582000 582100 582200 582300 582400 582500 582600 582700 582800 582900 583000 583100 583200 583300 583400 583500 583600 583700 583800 583900 584000 584100 584200 584300 584400 584500 584600 584700 584800 584900 585000 585100 585200 585300 585400 585500 585600 585700 585800 585900 586000 586100 586200 586300 586400 586500 586600 586700 586800 586900 587000 587100 587200 587300 587400 587500 587600 587700 587800 587900 588000 588100 588200 588300 588400 588500 588600 588700 588800 588900 589000 589100 589200 589300 589400 589500 589600 589700 589800 589900 590000 590100 590200 590300 590400 590500 590600 590700 590800 590900 591000 591100 591200 591300 591400 591500 591600 591700 591800 591900 592000 592100 592200 592300 592400 592500 592600 592700 592800 592900 593000 593100 593200 593300 593400 593500 593600 593700 593800 593900 594000 594100 594200 594300 594400 594500 594600 594700 594800 594900 595000 595100 595200 595300 595400 595500 595600 595700 595800 595900 596000 596100 596200 596300 596400 596500 596600 596700 596800 596900 597000 597100 597200 597300 597400 597500 597600 597700 597800 597900 598000 598100 598200 598300 598400 598500 598600 598700 598800 598900 599000 599100 599200 599300 599400 599500 599600 599700 599800 599900 600000 600100 600200 600300 600400 600500 600600 600700 600800 600900 601000 601100 601200 601300 601400 601500 601600 601700 601800 601900 602000 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602100 602200 602300 602400 602500 602600 602700 602800 602900 603000 603100 603200 603300 603400 603500 603600 603700 603800 603900 604000 604100 604200 604300 604400 604500 604600 604700 604800 604900 605000 605100 605200 605300 605400 605500 605600 605700 605800 605900 606000 606100 606200 606300 606400 606500 606600 606700 606800 606900 607000 607100 607200 607300 607400 607500 607600 607700 607800 607900 608000 608100 608200 608300 608400 608500 608600 608700 608800 608900 609000 609100 609200 609300 609400 609500 609600 609700 609800 609900 610000 610100 610200 610300 610400 610500 610600 610700 610800 610900 611000 611100 611200 611300 611400 611500 611600 611700 611800 611900 612000 612100 612200 612300 612400 612500 612600 612700 612800 612900 613000 613100 613200 613300 613400 613500 613600 613700 613800 613900 614000 614100 614200 614300 614400 614500 614600 614700 614800 614900 615000 615100 615200 615300 615400 615500 615600 615700 615800 615900 616000 616100 616200 616300 616400 616500 616600 616700 616800 616900 617000 617100 617200 617300 617400 617500 617600 617700 617800 617900 618000 618100 618200 618300 618400 618500 618600 618700 618800 618900 619000 619100 619200 619300 619400 619500 619600 619700 619800 619900 620000 620100 620200 620300 620400 620500 620600 620700 620800 620900 621000 621100 621200 621300 621400 621500 621600 621700 621800 621900 622000 622100 622200 622300 622400 622500 622600 622700 622800 622900 623000 623100 623200 623300 623400 623500 623600 623700 623800 623900 624000 624100 624200 624300 624400 624500 624600 624700 624800 624900 625000 625100 625200 625300 625400 625500 625600 625700 625800 625900 626000 626100 626200 626300 626400 626500 626600 626700 626800 626900 627000 627100 627200 627300 627400 627500 627600 627700 627800 627900 628000 628100 628200 628300 628400 628500 628600 628700 628800 628900 629000 629100 629200 629300 629400 629500 629600 629700 629800 629900 630000 630100 630200 630300 630400 630500 630600 630700 630800 630900 631000 631100 631200 631300 631400 631500 631600 631700 631800 631900 632000 632100 632200 632300 632400 632500 632600 632700 632800 632900 633000 633100 633200 633300 633400 633500 633600 633700 633800 633900 634000 634100 634200 634300 634400 634500 634600 634700 634800 634900 635000 635100 635200 635300 635400 635500 635600 635700 635800 635900 636000 636100 636200 636300 636400 636500 636600 636700 636800 636900 637000 637100 637200 637300 637400 637500 637600 637700 637800 637900 638000 638100 638200 638300 638400 638500 638600 638700 638800 638900 639000 639100 639200 639300 639400 639500 639600 639700 639800 639900 640000 640100 640200 640300 640400 640500 640600 640700 640800 640900 641000 641100 641200 641300 641400 641500 641600 641700 641800 641900 642000 642100 642200 642300 642400 642500 642600 642700 642800 642900 643000 643100 643200 643300 643400 643500 643600 643700 643800 643900 644000 644100 644200 644300 644400 644500 644600 644700 644800 644900 645000 645100 645200 645300 645400 645500 645600 645700 645800 645900 646000 646100 646200 646300 646400 646500 646600 646700 646800 646900 647000 647100 647200 647300 647400 647500 647600 647700 647800 647900 648000 648100 648200 648300 648400 648500 648600 648700 648800 648900 649000 649100 649200 649300 649400 649500 649600 649700 649800 649900 650000 650100 650200 650300 650400 650500 650600 650700 650800 650900 651000 651100 651200 651300 651400 651500 651600 651700 651800 651900 652000 652100 652200 652300 652400 652500 652600 652700 652800 652900 653000 653100 653200 653300 653400 653500 653600 653700 653800 653900 654000 654100 654200 654300 654400 654500 654600 654700 654800 654900 655000 655100 655200 655300 655400 655500 655600 655700 655800 655900 656000 656100 656200 656300 656400 656500 656600 656700 656800 656900 657000 657100 657200 657300 657400 657500 657600 657700 657800 657900 658000 658100 658200 658300 658400 658500 658600 658700 658800 658900 659000 659100 659200 659300 659400 659500 659600 659700 659800 659900 660000 660100 660200 660300 660400 660500 660600 660700 660800 660900 661000 661100 661200 661300 661400 661500 661600 661700 661800 661900 662000 662100 662200 662300 662400 662500 662600 662700 662800 662900 663000 663100 663200 663300 663400 663500 663600 663700 663800 663900 664000 664100 664200 664300 664400 664500 664600 664700 664800 664900 665000 665100 665200 665300 665400 665500 665600 665700 665800 665900 666000 666100 666200 666300 666400 666500 666600 666700 666800 666900 667000 667100 667200 667300 667400 667500 667600 667700 667800 667900 668000 668100 668200 668300 668400 668500 668600 668700 668800 668900 669000 669100 669200 669300 669400 669500 669600 669700 669800 669900 670000 670100 670200 670300 670400 670500 670600 670700 670800 670900 671000 671100 671200 671300 671400 671500 671600 671700 671800 671900 672000 672100 672200 672300 672400 672500 672600 672700 672800 672900 673000 673100 673200 673300 673400 673500 673600 673700 673800 673900 674000 674100 674200 674300 674400 674500 674600 674700 674800 674900 675000 675100 675200 675300 675400 675500 675600 675700 675800 675900 676000 676100 676200 676300 676400 676500 676600 676700 676800 676900 677000 677100 677200 677300 677400 677500 677600 677700 677800 677900 678000 678100 678200 678300 678400 678500 678600 678700 678800 678900 679000 679100 679200 679300 679400 679500 679600 679700 679800 679900 680000 680100 680200 680300 680400 680500 680600 680700 680800 680900 681000 681100 681200 681300 681400 681500 681600 681700 681800 681900 682000 682100 682200 682300 682400 682500 682600 682700 682800 682900 683000 683100 683200 683300 683400 683500 683600 683700 683800 683900 684000 684100 684200 684300 684400 684500 684600 684700 684800 684900 685000 685100 685200 685300 685400 685500 685600 685700 685800 685900 686000 686100 686200 686300 686400 686500 686600 686700 686800 686900 687000 687100 687200 687300 687400 687500 687600 687700 687800 687900 688000 688100 688200 688300 688400 688500 688600 688700 688800 688900 689000 689100 689200 689300 689400 689500 689600 689700 689800 689900 690000 690100 690200 690300 690400 690500 690600 690700 690800 690900 691000 691100 691200 691300 691400 691500 691600 691700 691800 691900 692000 692100 692200 692300 692400 692500 692600 692700 692800 692900 693000 693100 693200 693300 693400 693500 693600 693700 693800 693900 694000 694100 694200 694300 694400 694500 694600 694700 694800 694900 695000 695100 695200 695300 695400 695500 695600 695700 695800 695900 696000 696100 696200 696300 696400 696500 696600 696700 696800 696900 697000 697100 697200 697300 697400 697500 697600 697700 697800 697900 698000 698100 698200 698300 698400 698500 698600 698700 698800 698900 699000 699100 699200 699300 699400 699500 699600 699700 699800 699900 700000 700100 700200 700300 700400 700500 700600 700700 700800 700900 701000 701100 701200 701300 701400 701500 701600 701700 701800 701900 702000 702100 702200 702300 702400 702500 702600 702700 702800 702900 703000 703100 703200 703300 703400 703500 703600 703700 703800 703900 704000 704100 704200 704300 704400 704500 704600 704700 704800 704900 705000 705100 705200 705300 705400 705500 705600 705700 705800 705900 706000 706100 706200 706300 706400 706500 706600 706700 706800 706900 707000 707100 707200 707300 707400 707500 707600 707700 707800 707900 708000 708100 708200 708300 708400 708500 708600 708700 708800 708900 709000 709100 709200 709300 709400 709500 709600 709700 709800 709900 710000 710100 710200 710300 710400 710500 710600 710700 710800 710900 711000 711100 711200 711300 711400 711500 711600 711700 711800 711900 712000 712100 712200 712300 712400 712500 712600 712700 712800 712900 713000 713100 713200 713300 713400 713500 713600 713700 713800 713900 714000 714100 714200 714300 714400 714500 714600 714700 714800 714900 715000 715100 715200 715300 715400 715500 715600 715700 715800 715900 716000 716100 716200 716300 716400 716500 716600 716700 716800 716900 717000 717100 717200 717300 717400 717500 717600 717700 717800 717900 718000 718100 718200 718300 718400 718500 718600 718700 718800 718900 719000 719100 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "719200 719300 719400 719500 719600 719700 719800 719900 720000 720100 720200 720300 720400 720500 720600 720700 720800 720900 721000 721100 721200 721300 721400 721500 721600 721700 721800 721900 722000 722100 722200 722300 722400 722500 722600 722700 722800 722900 723000 723100 723200 723300 723400 723500 723600 723700 723800 723900 724000 724100 724200 724300 724400 724500 724600 724700 724800 724900 725000 725100 725200 725300 725400 725500 725600 725700 725800 725900 726000 726100 726200 726300 726400 726500 726600 726700 726800 726900 727000 727100 727200 727300 727400 727500 727600 727700 727800 727900 728000 728100 728200 728300 728400 728500 728600 728700 728800 728900 729000 729100 729200 729300 729400 729500 729600 729700 729800 729900 730000 730100 730200 730300 730400 730500 730600 730700 730800 730900 731000 731100 731200 731300 731400 731500 731600 731700 731800 731900 732000 732100 732200 732300 732400 732500 732600 732700 732800 732900 733000 733100 733200 733300 733400 733500 733600 733700 733800 733900 734000 734100 734200 734300 734400 734500 734600 734700 734800 734900 735000 735100 735200 735300 735400 735500 735600 735700 735800 735900 736000 736100 736200 736300 736400 736500 736600 736700 736800 736900 737000 737100 737200 737300 737400 737500 737600 737700 737800 737900 738000 738100 738200 738300 738400 738500 738600 738700 738800 738900 739000 739100 739200 739300 739400 739500 739600 739700 739800 739900 740000 740100 740200 740300 740400 740500 740600 740700 740800 740900 741000 741100 741200 741300 741400 741500 741600 741700 741800 741900 742000 742100 742200 742300 742400 742500 742600 742700 742800 742900 743000 743100 743200 743300 743400 743500 743600 743700 743800 743900 744000 744100 744200 744300 744400 744500 744600 744700 744800 744900 745000 745100 745200 745300 745400 745500 745600 745700 745800 745900 746000 746100 746200 746300 746400 746500 746600 746700 746800 746900 747000 747100 747200 747300 747400 747500 747600 747700 747800 747900 748000 748100 748200 748300 748400 748500 748600 748700 748800 748900 749000 749100 749200 749300 749400 749500 749600 749700 749800 749900 750000 750100 750200 750300 750400 750500 750600 750700 750800 750900 751000 751100 751200 751300 751400 751500 751600 751700 751800 751900 752000 752100 752200 752300 752400 752500 752600 752700 752800 752900 753000 753100 753200 753300 753400 753500 753600 753700 753800 753900 754000 754100 754200 754300 754400 754500 754600 754700 754800 754900 755000 755100 755200 755300 755400 755500 755600 755700 755800 755900 756000 756100 756200 756300 756400 756500 756600 756700 756800 756900 757000 757100 757200 757300 757400 757500 757600 757700 757800 757900 758000 758100 758200 758300 758400 758500 758600 758700 758800 758900 759000 759100 759200 759300 759400 759500 759600 759700 759800 759900 760000 760100 760200 760300 760400 760500 760600 760700 760800 760900 761000 761100 761200 761300 761400 761500 761600 761700 761800 761900 762000 762100 762200 762300 762400 762500 762600 762700 762800 762900 763000 763100 763200 763300 763400 763500 763600 763700 763800 763900 764000 764100 764200 764300 764400 764500 764600 764700 764800 764900 765000 765100 765200 765300 765400 765500 765600 765700 765800 765900 766000 766100 766200 766300 766400 766500 766600 766700 766800 766900 767000 767100 767200 767300 767400 767500 767600 767700 767800 767900 768000 768100 768200 768300 768400 768500 768600 768700 768800 768900 769000 769100 769200 769300 769400 769500 769600 769700 769800 769900 770000 770100 770200 770300 770400 770500 770600 770700 770800 770900 771000 771100 771200 771300 771400 771500 771600 771700 771800 771900 772000 772100 772200 772300 772400 772500 772600 772700 772800 772900 773000 773100 773200 773300 773400 773500 773600 773700 773800 773900 774000 774100 774200 774300 774400 774500 774600 774700 774800 774900 775000 775100 775200 775300 775400 775500 775600 775700 775800 775900 776000 776100 776200 776300 776400 776500 776600 776700 776800 776900 777000 777100 777200 777300 777400 777500 777600 777700 777800 777900 778000 778100 778200 778300 778400 778500 778600 778700 778800 778900 779000 779100 779200 779300 779400 779500 779600 779700 779800 779900 780000 780100 780200 780300 780400 780500 780600 780700 780800 780900 781000 781100 781200 781300 781400 781500 781600 781700 781800 781900 782000 782100 782200 782300 782400 782500 782600 782700 782800 782900 783000 783100 783200 783300 783400 783500 783600 783700 783800 783900 784000 784100 784200 784300 784400 784500 784600 784700 784800 784900 785000 785100 785200 785300 785400 785500 785600 785700 785800 785900 786000 786100 786200 786300 786400 786500 786600 786700 786800 786900 787000 787100 787200 787300 787400 787500 787600 787700 787800 787900 788000 788100 788200 788300 788400 788500 788600 788700 788800 788900 789000 789100 789200 789300 789400 789500 789600 789700 789800 789900 790000 790100 790200 790300 790400 790500 790600 790700 790800 790900 791000 791100 791200 791300 791400 791500 791600 791700 791800 791900 792000 792100 792200 792300 792400 792500 792600 792700 792800 792900 793000 793100 793200 793300 793400 793500 793600 793700 793800 793900 794000 794100 794200 794300 794400 794500 794600 794700 794800 794900 795000 795100 795200 795300 795400 795500 795600 795700 795800 795900 796000 796100 796200 796300 796400 796500 796600 796700 796800 796900 797000 797100 797200 797300 797400 797500 797600 797700 797800 797900 798000 798100 798200 798300 798400 798500 798600 798700 798800 798900 799000 799100 799200 799300 799400 799500 799600 799700 799800 799900 800000 800100 800200 800300 800400 800500 800600 800700 800800 800900 801000 801100 801200 801300 801400 801500 801600 801700 801800 801900 802000 802100 802200 802300 802400 802500 802600 802700 802800 802900 803000 803100 803200 803300 803400 803500 803600 803700 803800 803900 804000 804100 804200 804300 804400 804500 804600 804700 804800 804900 805000 805100 805200 805300 805400 805500 805600 805700 805800 805900 806000 806100 806200 806300 806400 806500 806600 806700 806800 806900 807000 807100 807200 807300 807400 807500 807600 807700 807800 807900 808000 808100 808200 808300 808400 808500 808600 808700 808800 808900 809000 809100 809200 809300 809400 809500 809600 809700 809800 809900 810000 810100 810200 810300 810400 810500 810600 810700 810800 810900 811000 811100 811200 811300 811400 811500 811600 811700 811800 811900 812000 812100 812200 812300 812400 812500 812600 812700 812800 812900 813000 813100 813200 813300 813400 813500 813600 813700 813800 813900 814000 814100 814200 814300 814400 814500 814600 814700 814800 814900 815000 815100 815200 815300 815400 815500 815600 815700 815800 815900 816000 816100 816200 816300 816400 816500 816600 816700 816800 816900 817000 817100 817200 817300 817400 817500 817600 817700 817800 817900 818000 818100 818200 818300 818400 818500 818600 818700 818800 818900 819000 819100 819200 819300 819400 819500 819600 819700 819800 819900 820000 820100 820200 820300 820400 820500 820600 820700 820800 820900 821000 821100 821200 821300 821400 821500 821600 821700 821800 821900 822000 822100 822200 822300 822400 822500 822600 822700 822800 822900 823000 823100 823200 823300 823400 823500 823600 823700 823800 823900 824000 824100 824200 824300 824400 824500 824600 824700 824800 824900 825000 825100 825200 825300 825400 825500 825600 825700 825800 825900 826000 826100 826200 826300 826400 826500 826600 826700 826800 826900 827000 827100 827200 827300 827400 827500 827600 827700 827800 827900 828000 828100 828200 828300 828400 828500 828600 828700 828800 828900 829000 829100 829200 829300 829400 829500 829600 829700 829800 829900 830000 830100 830200 830300 830400 830500 830600 830700 830800 830900 831000 831100 831200 831300 831400 831500 831600 831700 831800 831900 832000 832100 832200 832300 832400 832500 832600 832700 832800 832900 833000 833100 833200 833300 833400 833500 833600 833700 833800 833900 834000 834100 834200 834300 834400 834500 834600 834700 834800 834900 835000 835100 835200 835300 835400 835500 835600 835700 835800 835900 836000 836100 836200 836300 836400 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "836500 836600 836700 836800 836900 837000 837100 837200 837300 837400 837500 837600 837700 837800 837900 838000 838100 838200 838300 838400 838500 838600 838700 838800 838900 839000 839100 839200 839300 839400 839500 839600 839700 839800 839900 840000 840100 840200 840300 840400 840500 840600 840700 840800 840900 841000 841100 841200 841300 841400 841500 841600 841700 841800 841900 842000 842100 842200 842300 842400 842500 842600 842700 842800 842900 843000 843100 843200 843300 843400 843500 843600 843700 843800 843900 844000 844100 844200 844300 844400 844500 844600 844700 844800 844900 845000 845100 845200 845300 845400 845500 845600 845700 845800 845900 846000 846100 846200 846300 846400 846500 846600 846700 846800 846900 847000 847100 847200 847300 847400 847500 847600 847700 847800 847900 848000 848100 848200 848300 848400 848500 848600 848700 848800 848900 849000 849100 849200 849300 849400 849500 849600 849700 849800 849900 850000 850100 850200 850300 850400 850500 850600 850700 850800 850900 851000 851100 851200 851300 851400 851500 851600 851700 851800 851900 852000 852100 852200 852300 852400 852500 852600 852700 852800 852900 853000 853100 853200 853300 853400 853500 853600 853700 853800 853900 854000 854100 854200 854300 854400 854500 854600 854700 854800 854900 855000 855100 855200 855300 855400 855500 855600 855700 855800 855900 856000 856100 856200 856300 856400 856500 856600 856700 856800 856900 857000 857100 857200 857300 857400 857500 857600 857700 857800 857900 858000 858100 858200 858300 858400 858500 858600 858700 858800 858900 859000 859100 859200 859300 859400 859500 859600 859700 859800 859900 860000 860100 860200 860300 860400 860500 860600 860700 860800 860900 861000 861100 861200 861300 861400 861500 861600 861700 861800 861900 862000 862100 862200 862300 862400 862500 862600 862700 862800 862900 863000 863100 863200 863300 863400 863500 863600 863700 863800 863900 864000 864100 864200 864300 864400 864500 864600 864700 864800 864900 865000 865100 865200 865300 865400 865500 865600 865700 865800 865900 866000 866100 866200 866300 866400 866500 866600 866700 866800 866900 867000 867100 867200 867300 867400 867500 867600 867700 867800 867900 868000 868100 868200 868300 868400 868500 868600 868700 868800 868900 869000 869100 869200 869300 869400 869500 869600 869700 869800 869900 870000 870100 870200 870300 870400 870500 870600 870700 870800 870900 871000 871100 871200 871300 871400 871500 871600 871700 871800 871900 872000 872100 872200 872300 872400 872500 872600 872700 872800 872900 873000 873100 873200 873300 873400 873500 873600 873700 873800 873900 874000 874100 874200 874300 874400 874500 874600 874700 874800 874900 875000 875100 875200 875300 875400 875500 875600 875700 875800 875900 876000 876100 876200 876300 876400 876500 876600 876700 876800 876900 877000 877100 877200 877300 877400 877500 877600 877700 877800 877900 878000 878100 878200 878300 878400 878500 878600 878700 878800 878900 879000 879100 879200 879300 879400 879500 879600 879700 879800 879900 880000 880100 880200 880300 880400 880500 880600 880700 880800 880900 881000 881100 881200 881300 881400 881500 881600 881700 881800 881900 882000 882100 882200 882300 882400 882500 882600 882700 882800 882900 883000 883100 883200 883300 883400 883500 883600 883700 883800 883900 884000 884100 884200 884300 884400 884500 884600 884700 884800 884900 885000 885100 885200 885300 885400 885500 885600 885700 885800 885900 886000 886100 886200 886300 886400 886500 886600 886700 886800 886900 887000 887100 887200 887300 887400 887500 887600 887700 887800 887900 888000 888100 888200 888300 888400 888500 888600 888700 888800 888900 889000 889100 889200 889300 889400 889500 889600 889700 889800 889900 890000 890100 890200 890300 890400 890500 890600 890700 890800 890900 891000 891100 891200 891300 891400 891500 891600 891700 891800 891900 892000 892100 892200 892300 892400 892500 892600 892700 892800 892900 893000 893100 893200 893300 893400 893500 893600 893700 893800 893900 894000 894100 894200 894300 894400 894500 894600 894700 894800 894900 895000 895100 895200 895300 895400 895500 895600 895700 895800 895900 896000 896100 896200 896300 896400 896500 896600 896700 896800 896900 897000 897100 897200 897300 897400 897500 897600 897700 897800 897900 898000 898100 898200 898300 898400 898500 898600 898700 898800 898900 899000 899100 899200 899300 899400 899500 899600 899700 899800 899900 900000 900100 900200 900300 900400 900500 900600 900700 900800 900900 901000 901100 901200 901300 901400 901500 901600 901700 901800 901900 902000 902100 902200 902300 902400 902500 902600 902700 902800 902900 903000 903100 903200 903300 903400 903500 903600 903700 903800 903900 904000 904100 904200 904300 904400 904500 904600 904700 904800 904900 905000 905100 905200 905300 905400 905500 905600 905700 905800 905900 906000 906100 906200 906300 906400 906500 906600 906700 906800 906900 907000 907100 907200 907300 907400 907500 907600 907700 907800 907900 908000 908100 908200 908300 908400 908500 908600 908700 908800 908900 909000 909100 909200 909300 909400 909500 909600 909700 909800 909900 910000 910100 910200 910300 910400 910500 910600 910700 910800 910900 911000 911100 911200 911300 911400 911500 911600 911700 911800 911900 912000 912100 912200 912300 912400 912500 912600 912700 912800 912900 913000 913100 913200 913300 913400 913500 913600 913700 913800 913900 914000 914100 914200 914300 914400 914500 914600 914700 914800 914900 915000 915100 915200 915300 915400 915500 915600 915700 915800 915900 916000 916100 916200 916300 916400 916500 916600 916700 916800 916900 917000 917100 917200 917300 917400 917500 917600 917700 917800 917900 918000 918100 918200 918300 918400 918500 918600 918700 918800 918900 919000 919100 919200 919300 919400 919500 919600 919700 919800 919900 920000 920100 920200 920300 920400 920500 920600 920700 920800 920900 921000 921100 921200 921300 921400 921500 921600 921700 921800 921900 922000 922100 922200 922300 922400 922500 922600 922700 922800 922900 923000 923100 923200 923300 923400 923500 923600 923700 923800 923900 924000 924100 924200 924300 924400 924500 924600 924700 924800 924900 925000 925100 925200 925300 925400 925500 925600 925700 925800 925900 926000 926100 926200 926300 926400 926500 926600 926700 926800 926900 927000 927100 927200 927300 927400 927500 927600 927700 927800 927900 928000 928100 928200 928300 928400 928500 928600 928700 928800 928900 929000 929100 929200 929300 929400 929500 929600 929700 929800 929900 930000 930100 930200 930300 930400 930500 930600 930700 930800 930900 931000 931100 931200 931300 931400 931500 931600 931700 931800 931900 932000 932100 932200 932300 932400 932500 932600 932700 932800 932900 933000 933100 933200 933300 933400 933500 933600 933700 933800 933900 934000 934100 934200 934300 934400 934500 934600 934700 934800 934900 935000 935100 935200 935300 935400 935500 935600 935700 935800 935900 936000 936100 936200 936300 936400 936500 936600 936700 936800 936900 937000 937100 937200 937300 937400 937500 937600 937700 937800 937900 938000 938100 938200 938300 938400 938500 938600 938700 938800 938900 939000 939100 939200 939300 939400 939500 939600 939700 939800 939900 940000 940100 940200 940300 940400 940500 940600 940700 940800 940900 941000 941100 941200 941300 941400 941500 941600 941700 941800 941900 942000 942100 942200 942300 942400 942500 942600 942700 942800 942900 943000 943100 943200 943300 943400 943500 943600 943700 943800 943900 944000 944100 944200 944300 944400 944500 944600 944700 944800 944900 945000 945100 945200 945300 945400 945500 945600 945700 945800 945900 946000 946100 946200 946300 946400 946500 946600 946700 946800 946900 947000 947100 947200 947300 947400 947500 947600 947700 947800 947900 948000 948100 948200 948300 948400 948500 948600 948700 948800 948900 949000 949100 949200 949300 949400 949500 949600 949700 949800 949900 950000 950100 950200 950300 950400 950500 950600 950700 950800 950900 951000 951100 951200 951300 951400 951500 951600 951700 951800 951900 952000 952100 952200 952300 952400 952500 952600 952700 952800 952900 953000 953100 953200 953300 953400 953500 953600 953700 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "953800 953900 954000 954100 954200 954300 954400 954500 954600 954700 954800 954900 955000 955100 955200 955300 955400 955500 955600 955700 955800 955900 956000 956100 956200 956300 956400 956500 956600 956700 956800 956900 957000 957100 957200 957300 957400 957500 957600 957700 957800 957900 958000 958100 958200 958300 958400 958500 958600 958700 958800 958900 959000 959100 959200 959300 959400 959500 959600 959700 959800 959900 960000 960100 960200 960300 960400 960500 960600 960700 960800 960900 961000 961100 961200 961300 961400 961500 961600 961700 961800 961900 962000 962100 962200 962300 962400 962500 962600 962700 962800 962900 963000 963100 963200 963300 963400 963500 963600 963700 963800 963900 964000 964100 964200 964300 964400 964500 964600 964700 964800 964900 965000 965100 965200 965300 965400 965500 965600 965700 965800 965900 966000 966100 966200 966300 966400 966500 966600 966700 966800 966900 967000 967100 967200 967300 967400 967500 967600 967700 967800 967900 968000 968100 968200 968300 968400 968500 968600 968700 968800 968900 969000 969100 969200 969300 969400 969500 969600 969700 969800 969900 970000 970100 970200 970300 970400 970500 970600 970700 970800 970900 971000 971100 971200 971300 971400 971500 971600 971700 971800 971900 972000 972100 972200 972300 972400 972500 972600 972700 972800 972900 973000 973100 973200 973300 973400 973500 973600 973700 973800 973900 974000 974100 974200 974300 974400 974500 974600 974700 974800 974900 975000 975100 975200 975300 975400 975500 975600 975700 975800 975900 976000 976100 976200 976300 976400 976500 976600 976700 976800 976900 977000 977100 977200 977300 977400 977500 977600 977700 977800 977900 978000 978100 978200 978300 978400 978500 978600 978700 978800 978900 979000 979100 979200 979300 979400 979500 979600 979700 979800 979900 980000 980100 980200 980300 980400 980500 980600 980700 980800 980900 981000 981100 981200 981300 981400 981500 981600 981700 981800 981900 982000 982100 982200 982300 982400 982500 982600 982700 982800 982900 983000 983100 983200 983300 983400 983500 983600 983700 983800 983900 984000 984100 984200 984300 984400 984500 984600 984700 984800 984900 985000 985100 985200 985300 985400 985500 985600 985700 985800 985900 986000 986100 986200 986300 986400 986500 986600 986700 986800 986900 987000 987100 987200 987300 987400 987500 987600 987700 987800 987900 988000 988100 988200 988300 988400 988500 988600 988700 988800 988900 989000 989100 989200 989300 989400 989500 989600 989700 989800 989900 990000 990100 990200 990300 990400 990500 990600 990700 990800 990900 991000 991100 991200 991300 991400 991500 991600 991700 991800 991900 992000 992100 992200 992300 992400 992500 992600 992700 992800 992900 993000 993100 993200 993300 993400 993500 993600 993700 993800 993900 994000 994100 994200 994300 994400 994500 994600 994700 994800 994900 995000 995100 995200 995300 995400 995500 995600 995700 995800 995900 996000 996100 996200 996300 996400 996500 996600 996700 996800 996900 997000 997100 997200 997300 997400 997500 997600 997700 997800 997900 998000 998100 998200 998300 998400 998500 998600 998700 998800 998900 999000 999100 999200 999300 999400 999500 999600 999700 999800 999900 1000000 1000100 1000200 1000300 1000400 1000500 1000600 1000700 1000800 1000900 1001000 1001100 1001200 1001300 1001400 1001500 1001600 1001700 1001800 1001900 1002000 1002100 1002200 1002300 1002400 1002500 1002600 1002700 1002800 1002900 1003000 1003100 1003200 1003300 1003400 1003500 1003600 1003700 1003800 1003900 1004000 1004100 1004200 1004300 1004400 1004500 1004600 1004700 1004800 1004900 1005000 1005100 1005200 1005300 1005400 1005500 1005600 1005700 1005800 1005900 1006000 1006100 1006200 1006300 1006400 1006500 1006600 1006700 1006800 1006900 1007000 1007100 1007200 1007300 1007400 1007500 1007600 1007700 1007800 1007900 1008000 1008100 1008200 1008300 1008400 1008500 1008600 1008700 1008800 1008900 1009000 1009100 1009200 1009300 1009400 1009500 1009600 1009700 1009800 1009900 1010000 1010100 1010200 1010300 1010400 1010500 1010600 1010700 1010800 1010900 1011000 1011100 1011200 1011300 1011400 1011500 1011600 1011700 1011800 1011900 1012000 1012100 1012200 1012300 1012400 1012500 1012600 1012700 1012800 1012900 1013000 1013100 1013200 1013300 1013400 1013500 1013600 1013700 1013800 1013900 1014000 1014100 1014200 1014300 1014400 1014500 1014600 1014700 1014800 1014900 1015000 1015100 1015200 1015300 1015400 1015500 1015600 1015700 1015800 1015900 1016000 1016100 1016200 1016300 1016400 1016500 1016600 1016700 1016800 1016900 1017000 1017100 1017200 1017300 1017400 1017500 1017600 1017700 1017800 1017900 1018000 1018100 1018200 1018300 1018400 1018500 1018600 1018700 1018800 1018900 1019000 1019100 1019200 1019300 1019400 1019500 1019600 1019700 1019800 1019900 1020000 1020100 1020200 1020300 1020400 1020500 1020600 1020700 1020800 1020900 1021000 1021100 1021200 1021300 1021400 1021500 1021600 1021700 1021800 1021900 1022000 1022100 1022200 1022300 1022400 1022500 1022600 1022700 1022800 1022900 1023000 1023100 1023200 1023300 1023400 1023500 1023600 1023700 1023800 1023900 1024000 1024100 1024200 1024300 1024400 1024500 1024600 1024700 1024800 1024900 1025000 1025100 1025200 1025300 1025400 1025500 1025600 1025700 1025800 1025900 1026000 1026100 1026200 1026300 1026400 1026500 1026600 1026700 1026800 1026900 1027000 1027100 1027200 1027300 1027400 1027500 1027600 1027700 1027800 1027900 1028000 1028100 1028200 1028300 1028400 1028500 1028600 1028700 1028800 1028900 1029000 1029100 1029200 1029300 1029400 1029500 1029600 1029700 1029800 1029900 1030000 1030100 1030200 1030300 1030400 1030500 1030600 1030700 1030800 1030900 1031000 1031100 1031200 1031300 1031400 1031500 1031600 1031700 1031800 1031900 1032000 1032100 1032200 1032300 1032400 1032500 1032600 1032700 1032800 1032900 1033000 1033100 1033200 1033300 1033400 1033500 1033600 1033700 1033800 1033900 1034000 1034100 1034200 1034300 1034400 1034500 1034600 1034700 1034800 1034900 1035000 1035100 1035200 1035300 1035400 1035500 1035600 1035700 1035800 1035900 1036000 1036100 1036200 1036300 1036400 1036500 1036600 1036700 1036800 1036900 1037000 1037100 1037200 1037300 1037400 1037500 1037600 1037700 1037800 1037900 1038000 1038100 1038200 1038300 1038400 1038500 1038600 1038700 1038800 1038900 1039000 1039100 1039200 1039300 1039400 1039500 1039600 1039700 1039800 1039900 1040000 1040100 1040200 1040300 1040400 1040500 1040600 1040700 1040800 1040900 1041000 1041100 1041200 1041300 1041400 1041500 1041600 1041700 1041800 1041900 1042000 1042100 1042200 1042300 1042400 1042500 1042600 1042700 1042800 1042900 1043000 1043100 1043200 1043300 1043400 1043500 1043600 1043700 1043800 1043900 1044000 1044100 1044200 1044300 1044400 1044500 1044600 1044700 1044800 "
     ]
    }
   ],
   "source": [
    "# Finding the different parts of speech used in sentence\n",
    "deter=[]\n",
    "noun=[]\n",
    "verb=[]\n",
    "adj=[]\n",
    "prn=[]\n",
    "advr=[]\n",
    "whq=[]\n",
    "for i in train.index:\n",
    "    j=train.loc[i,'question_text']\n",
    "    k=nltk.pos_tag(j.split())\n",
    "    det=[x[1] for x in k if x[1].startswith('DT')]\n",
    "    nn=[x[1] for x in k if x[1].startswith('NN')]\n",
    "    vb=[x[1] for x in k if x[1].startswith('VB')]\n",
    "    ad=[x[1] for x in k if x[1].startswith('JJ')]\n",
    "    pr=[x[1] for x in k if x[1].startswith('PR')]\n",
    "    adv=[x[1] for x in k if x[1].startswith('RB')]\n",
    "    wh=[x[1] for x in k if x[1].startswith('WR')]\n",
    "    deter.append(len(det))\n",
    "    noun.append(len(nn))\n",
    "    verb.append(len(vb))\n",
    "    adj.append(len(ad))\n",
    "    prn.append(len(pr))\n",
    "    advr.append(len(adv))\n",
    "    whq.append(len(wh))\n",
    "    if len(deter)%100==0:\n",
    "        print(len(deter),end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T18:08:18.131536Z",
     "start_time": "2020-04-02T18:08:16.756052Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setting the numbers as columns in training file\n",
    "train['Articles']=deter\n",
    "train['Nouns']=noun\n",
    "train['Verbs']=verb\n",
    "train['Adjectives']=adj\n",
    "train['Pronouns']=prn\n",
    "train['Question Words']=whq\n",
    "train['Adverbs']=advr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T18:10:47.996313Z",
     "start_time": "2020-04-02T18:08:18.133511Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 20000 30000 40000 50000 60000 70000 80000 90000 100000 110000 120000 130000 140000 150000 160000 170000 180000 190000 200000 210000 220000 230000 240000 250000 260000 270000 280000 290000 300000 310000 320000 330000 340000 350000 360000 370000 380000 390000 400000 410000 420000 430000 440000 450000 460000 470000 480000 490000 500000 510000 520000 530000 540000 550000 560000 570000 580000 590000 600000 610000 620000 630000 640000 650000 660000 670000 680000 690000 700000 710000 720000 730000 740000 750000 760000 770000 780000 790000 800000 810000 820000 830000 840000 850000 860000 870000 880000 890000 900000 910000 920000 930000 940000 950000 960000 970000 980000 990000 1000000 1010000 1020000 1030000 1040000 "
     ]
    }
   ],
   "source": [
    "# Getting positive, negative, neutral and overall sentiment score\n",
    "neg=[]\n",
    "neu=[]\n",
    "pos=[]\n",
    "comp=[]\n",
    "for i in train.index:\n",
    "    j=train.loc[i,'question_text']\n",
    "    k=senti.polarity_scores(j)\n",
    "    neg.append(k['neg'])\n",
    "    neu.append(k['neu'])\n",
    "    pos.append(k['pos'])\n",
    "    comp.append(k['compound'])\n",
    "    if len(neg)%10000==0:\n",
    "        print(len(neg),end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T18:10:49.214065Z",
     "start_time": "2020-04-02T18:10:47.997307Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "      <th>Length</th>\n",
       "      <th>Words</th>\n",
       "      <th>Special Characters</th>\n",
       "      <th>Capital Words</th>\n",
       "      <th>Positive words</th>\n",
       "      <th>Negative words</th>\n",
       "      <th>Stop words</th>\n",
       "      <th>Exclamation</th>\n",
       "      <th>...</th>\n",
       "      <th>Nouns</th>\n",
       "      <th>Verbs</th>\n",
       "      <th>Adjectives</th>\n",
       "      <th>Pronouns</th>\n",
       "      <th>Question Words</th>\n",
       "      <th>Adverbs</th>\n",
       "      <th>Positive score</th>\n",
       "      <th>Negative score</th>\n",
       "      <th>Neutral score</th>\n",
       "      <th>Final score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>172360</th>\n",
       "      <td>Is there any beach available in Delhi for night out?</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188522</th>\n",
       "      <td>What is the unit of vector parallel to each of vector?</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235537</th>\n",
       "      <td>How change LTE to VOlTE?</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345543</th>\n",
       "      <td>What percentage of US Democrat politicians are lawyers?</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566414</th>\n",
       "      <td>How did Cabela's Inc. manages to establish such large stores?</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180555</th>\n",
       "      <td>Where can I buy tamper proof courier bags online?</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155574</th>\n",
       "      <td>What are some reasons to trust a Jew?</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.5106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130815</th>\n",
       "      <td>What are the considerations in using a static class vs. a singleton? I need a class to handle functions with no relevance to specific instances.</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.901</td>\n",
       "      <td>-0.2960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107187</th>\n",
       "      <td>What is the purpose of the bit in a horse harness?</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856532</th>\n",
       "      <td>What is Annie Dillard known for?</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1044898 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                            question_text  \\\n",
       "172360                                                                                               Is there any beach available in Delhi for night out?   \n",
       "188522                                                                                             What is the unit of vector parallel to each of vector?   \n",
       "1235537                                                                                                                          How change LTE to VOlTE?   \n",
       "345543                                                                                            What percentage of US Democrat politicians are lawyers?   \n",
       "566414                                                                                      How did Cabela's Inc. manages to establish such large stores?   \n",
       "...                                                                                                                                                   ...   \n",
       "1180555                                                                                                 Where can I buy tamper proof courier bags online?   \n",
       "155574                                                                                                              What are some reasons to trust a Jew?   \n",
       "1130815  What are the considerations in using a static class vs. a singleton? I need a class to handle functions with no relevance to specific instances.   \n",
       "107187                                                                                                 What is the purpose of the bit in a horse harness?   \n",
       "856532                                                                                                                   What is Annie Dillard known for?   \n",
       "\n",
       "         target  Length  Words  Special Characters  Capital Words  \\\n",
       "172360        0      52     10                   1              2   \n",
       "188522        0      54     11                   1              1   \n",
       "1235537       0      24      5                   1              2   \n",
       "345543        0      55      8                   1              2   \n",
       "566414        0      61     10                   3              3   \n",
       "...         ...     ...    ...                 ...            ...   \n",
       "1180555       0      49      9                   1              1   \n",
       "155574        1      37      8                   1              2   \n",
       "1130815       0     144     25                   3              1   \n",
       "107187        0      50     11                   1              1   \n",
       "856532        0      32      6                   1              3   \n",
       "\n",
       "         Positive words  Negative words  Stop words  Exclamation  ...  Nouns  \\\n",
       "172360                0               0           4            0  ...      4   \n",
       "188522                0               0           6            0  ...      4   \n",
       "1235537               0               0           1            0  ...      2   \n",
       "345543                0               0           2            0  ...      4   \n",
       "566414                0               0           3            0  ...      3   \n",
       "...                 ...             ...         ...          ...  ...    ...   \n",
       "1180555               0               0           1            0  ...      3   \n",
       "155574                1               0           4            0  ...      2   \n",
       "1130815               0               0          10            0  ...      7   \n",
       "107187                0               0           6            0  ...      4   \n",
       "856532                0               0           1            0  ...      3   \n",
       "\n",
       "         Verbs  Adjectives  Pronouns  Question Words  Adverbs  Positive score  \\\n",
       "172360       1           1         0               0        0           0.000   \n",
       "188522       1           0         0               0        0           0.000   \n",
       "1235537      1           0         0               1        0           0.000   \n",
       "345543       1           1         0               0        0           0.000   \n",
       "566414       3           2         0               1        0           0.000   \n",
       "...        ...         ...       ...             ...      ...             ...   \n",
       "1180555      2           0         1               1        0           0.000   \n",
       "155574       2           0         0               0        0           0.355   \n",
       "1130815      4           2         1               0        0           0.000   \n",
       "107187       1           0         0               0        0           0.000   \n",
       "856532       2           0         0               0        0           0.000   \n",
       "\n",
       "         Negative score  Neutral score  Final score  \n",
       "172360            0.000          1.000       0.0000  \n",
       "188522            0.000          1.000       0.0000  \n",
       "1235537           0.000          1.000       0.0000  \n",
       "345543            0.000          1.000       0.0000  \n",
       "566414            0.000          1.000       0.0000  \n",
       "...                 ...            ...          ...  \n",
       "1180555           0.000          1.000       0.0000  \n",
       "155574            0.000          0.645       0.5106  \n",
       "1130815           0.099          0.901      -0.2960  \n",
       "107187            0.000          1.000       0.0000  \n",
       "856532            0.000          1.000       0.0000  \n",
       "\n",
       "[1044898 rows x 22 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Setting the values in training file\n",
    "train['Positive score']=pos\n",
    "train['Negative score']=neg\n",
    "train['Neutral score']=neu\n",
    "train['Final score']=comp\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T18:10:56.146172Z",
     "start_time": "2020-04-02T18:10:49.215017Z"
    }
   },
   "outputs": [],
   "source": [
    "# Saving file\n",
    "train.to_csv(r'D:\\DS\\NLP\\quora-insincere-questions-classification\\feature.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T17:18:06.323864Z",
     "start_time": "2020-04-04T17:18:02.979940Z"
    }
   },
   "outputs": [],
   "source": [
    "#Reading the file\n",
    "feature=pd.read_csv(r'D:\\DS\\NLP\\quora-insincere-questions-classification\\feature.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T17:18:18.705977Z",
     "start_time": "2020-04-04T17:18:18.645141Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "      <th>Length</th>\n",
       "      <th>Words</th>\n",
       "      <th>Special Characters</th>\n",
       "      <th>Capital Words</th>\n",
       "      <th>Positive words</th>\n",
       "      <th>Negative words</th>\n",
       "      <th>Stop words</th>\n",
       "      <th>...</th>\n",
       "      <th>Nouns</th>\n",
       "      <th>Verbs</th>\n",
       "      <th>Adjectives</th>\n",
       "      <th>Pronouns</th>\n",
       "      <th>Question Words</th>\n",
       "      <th>Adverbs</th>\n",
       "      <th>Positive score</th>\n",
       "      <th>Negative score</th>\n",
       "      <th>Neutral score</th>\n",
       "      <th>Final score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>172360</td>\n",
       "      <td>Is there any beach available in Delhi for night out?</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188522</td>\n",
       "      <td>What is the unit of vector parallel to each of vector?</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1235537</td>\n",
       "      <td>How change LTE to VOlTE?</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>345543</td>\n",
       "      <td>What percentage of US Democrat politicians are lawyers?</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>566414</td>\n",
       "      <td>How did Cabela's Inc. manages to establish such large stores?</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                                  question_text  \\\n",
       "0      172360           Is there any beach available in Delhi for night out?   \n",
       "1      188522         What is the unit of vector parallel to each of vector?   \n",
       "2     1235537                                       How change LTE to VOlTE?   \n",
       "3      345543        What percentage of US Democrat politicians are lawyers?   \n",
       "4      566414  How did Cabela's Inc. manages to establish such large stores?   \n",
       "\n",
       "   target  Length  Words  Special Characters  Capital Words  Positive words  \\\n",
       "0       0      52     10                   1              2               0   \n",
       "1       0      54     11                   1              1               0   \n",
       "2       0      24      5                   1              2               0   \n",
       "3       0      55      8                   1              2               0   \n",
       "4       0      61     10                   3              3               0   \n",
       "\n",
       "   Negative words  Stop words  ...  Nouns  Verbs  Adjectives  Pronouns  \\\n",
       "0               0           4  ...      4      1           1         0   \n",
       "1               0           6  ...      4      1           0         0   \n",
       "2               0           1  ...      2      1           0         0   \n",
       "3               0           2  ...      4      1           1         0   \n",
       "4               0           3  ...      3      3           2         0   \n",
       "\n",
       "   Question Words  Adverbs  Positive score  Negative score  Neutral score  \\\n",
       "0               0        0             0.0             0.0            1.0   \n",
       "1               0        0             0.0             0.0            1.0   \n",
       "2               1        0             0.0             0.0            1.0   \n",
       "3               0        0             0.0             0.0            1.0   \n",
       "4               1        0             0.0             0.0            1.0   \n",
       "\n",
       "   Final score  \n",
       "0          0.0  \n",
       "1          0.0  \n",
       "2          0.0  \n",
       "3          0.0  \n",
       "4          0.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T17:18:46.732800Z",
     "start_time": "2020-04-04T17:18:34.133519Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Length',\n",
       " 'Words',\n",
       " 'Special Characters',\n",
       " 'Capital Words',\n",
       " 'Negative words',\n",
       " 'Stop words',\n",
       " 'Question',\n",
       " 'Articles',\n",
       " 'Nouns',\n",
       " 'Verbs',\n",
       " 'Adjectives',\n",
       " 'Question Words',\n",
       " 'Adverbs',\n",
       " 'Positive score',\n",
       " 'Negative score',\n",
       " 'Neutral score',\n",
       " 'Final score']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting information value metric for feature selection\n",
    "iv={}\n",
    "for i in feature.drop(['target','question_text','Unnamed: 0'],axis=1).columns:\n",
    "    ct=woe(feature,'target',i)\n",
    "    iv[i]=sum(ct['IV'])\n",
    "impcols=[]\n",
    "for i,j in iv.items():\n",
    "    if j>=0.05:\n",
    "        impcols.append(i)\n",
    "impcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T17:19:39.762244Z",
     "start_time": "2020-04-04T17:19:39.670441Z"
    }
   },
   "outputs": [],
   "source": [
    "# Choosing imporant columns\n",
    "traincols=feature.loc[:,impcols]\n",
    "traincols['target']=feature['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T17:19:43.709726Z",
     "start_time": "2020-04-04T17:19:43.616973Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating dataframe to take on woe values\n",
    "woetrain=pd.DataFrame()\n",
    "woetrain['target']=feature['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T18:31:56.032687Z",
     "start_time": "2020-04-04T17:24:53.446337Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/17\n",
      "2/17\n",
      "3/17\n",
      "4/17\n",
      "5/17\n",
      "6/17\n",
      "7/17\n",
      "8/17\n",
      "9/17\n",
      "10/17\n",
      "11/17\n",
      "12/17\n",
      "13/17\n",
      "14/17\n",
      "15/17\n",
      "16/17\n",
      "17/17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>WOE_['Length']</th>\n",
       "      <th>WOE_['Words']</th>\n",
       "      <th>WOE_['Special Characters']</th>\n",
       "      <th>WOE_['Capital Words']</th>\n",
       "      <th>WOE_['Negative words']</th>\n",
       "      <th>WOE_['Stop words']</th>\n",
       "      <th>WOE_['Question']</th>\n",
       "      <th>WOE_['Articles']</th>\n",
       "      <th>WOE_['Nouns']</th>\n",
       "      <th>WOE_['Verbs']</th>\n",
       "      <th>WOE_['Adjectives']</th>\n",
       "      <th>WOE_['Question Words']</th>\n",
       "      <th>WOE_['Adverbs']</th>\n",
       "      <th>WOE_['Positive score']</th>\n",
       "      <th>WOE_['Negative score']</th>\n",
       "      <th>WOE_['Neutral score']</th>\n",
       "      <th>WOE_['Final score']</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.590682</td>\n",
       "      <td>0.550918</td>\n",
       "      <td>0.396929</td>\n",
       "      <td>-0.147791</td>\n",
       "      <td>0.252903</td>\n",
       "      <td>0.467112</td>\n",
       "      <td>0.076399</td>\n",
       "      <td>0.138917</td>\n",
       "      <td>0.135311</td>\n",
       "      <td>0.644238</td>\n",
       "      <td>0.281961</td>\n",
       "      <td>0.380696</td>\n",
       "      <td>0.131932</td>\n",
       "      <td>-0.017822</td>\n",
       "      <td>0.404594</td>\n",
       "      <td>0.522979</td>\n",
       "      <td>0.509005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.590682</td>\n",
       "      <td>0.421115</td>\n",
       "      <td>0.396929</td>\n",
       "      <td>0.722952</td>\n",
       "      <td>0.252903</td>\n",
       "      <td>-0.025530</td>\n",
       "      <td>0.076399</td>\n",
       "      <td>-0.089787</td>\n",
       "      <td>0.135311</td>\n",
       "      <td>0.644238</td>\n",
       "      <td>0.281961</td>\n",
       "      <td>0.380696</td>\n",
       "      <td>0.131932</td>\n",
       "      <td>-0.017822</td>\n",
       "      <td>0.404594</td>\n",
       "      <td>0.522979</td>\n",
       "      <td>0.509005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.331453</td>\n",
       "      <td>0.288053</td>\n",
       "      <td>0.396929</td>\n",
       "      <td>-0.147791</td>\n",
       "      <td>0.252903</td>\n",
       "      <td>0.179206</td>\n",
       "      <td>0.076399</td>\n",
       "      <td>0.138917</td>\n",
       "      <td>0.496441</td>\n",
       "      <td>0.644238</td>\n",
       "      <td>0.281961</td>\n",
       "      <td>-0.368412</td>\n",
       "      <td>0.131932</td>\n",
       "      <td>-0.017822</td>\n",
       "      <td>0.404594</td>\n",
       "      <td>0.522979</td>\n",
       "      <td>0.509005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.552418</td>\n",
       "      <td>0.629396</td>\n",
       "      <td>0.396929</td>\n",
       "      <td>-0.147791</td>\n",
       "      <td>0.252903</td>\n",
       "      <td>0.390734</td>\n",
       "      <td>0.076399</td>\n",
       "      <td>0.138917</td>\n",
       "      <td>0.135311</td>\n",
       "      <td>0.644238</td>\n",
       "      <td>0.281961</td>\n",
       "      <td>0.380696</td>\n",
       "      <td>0.131932</td>\n",
       "      <td>-0.017822</td>\n",
       "      <td>0.404594</td>\n",
       "      <td>0.522979</td>\n",
       "      <td>0.509005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.458060</td>\n",
       "      <td>0.550918</td>\n",
       "      <td>-0.429643</td>\n",
       "      <td>-0.449739</td>\n",
       "      <td>0.252903</td>\n",
       "      <td>0.545425</td>\n",
       "      <td>0.076399</td>\n",
       "      <td>0.138917</td>\n",
       "      <td>0.353022</td>\n",
       "      <td>-0.132154</td>\n",
       "      <td>-0.269975</td>\n",
       "      <td>-0.368412</td>\n",
       "      <td>0.131932</td>\n",
       "      <td>-0.017822</td>\n",
       "      <td>0.404594</td>\n",
       "      <td>0.522979</td>\n",
       "      <td>0.509005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044893</th>\n",
       "      <td>0</td>\n",
       "      <td>0.632045</td>\n",
       "      <td>0.629417</td>\n",
       "      <td>0.396929</td>\n",
       "      <td>0.722952</td>\n",
       "      <td>0.252903</td>\n",
       "      <td>0.179206</td>\n",
       "      <td>0.076399</td>\n",
       "      <td>0.138917</td>\n",
       "      <td>0.353022</td>\n",
       "      <td>0.306160</td>\n",
       "      <td>0.281961</td>\n",
       "      <td>-0.368412</td>\n",
       "      <td>0.131932</td>\n",
       "      <td>-0.017822</td>\n",
       "      <td>0.404594</td>\n",
       "      <td>0.522979</td>\n",
       "      <td>0.509005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044894</th>\n",
       "      <td>1</td>\n",
       "      <td>0.557712</td>\n",
       "      <td>0.629396</td>\n",
       "      <td>0.396929</td>\n",
       "      <td>-0.147791</td>\n",
       "      <td>0.252903</td>\n",
       "      <td>0.467112</td>\n",
       "      <td>0.076399</td>\n",
       "      <td>-0.089787</td>\n",
       "      <td>0.496441</td>\n",
       "      <td>0.306160</td>\n",
       "      <td>0.281961</td>\n",
       "      <td>0.380696</td>\n",
       "      <td>0.131932</td>\n",
       "      <td>0.561482</td>\n",
       "      <td>0.404594</td>\n",
       "      <td>-0.269510</td>\n",
       "      <td>0.010548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044895</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.855564</td>\n",
       "      <td>-0.878086</td>\n",
       "      <td>-0.429643</td>\n",
       "      <td>0.722952</td>\n",
       "      <td>0.252903</td>\n",
       "      <td>-0.834759</td>\n",
       "      <td>0.076399</td>\n",
       "      <td>-1.015604</td>\n",
       "      <td>-0.583569</td>\n",
       "      <td>-0.553839</td>\n",
       "      <td>-0.269975</td>\n",
       "      <td>0.380696</td>\n",
       "      <td>0.131932</td>\n",
       "      <td>-0.017822</td>\n",
       "      <td>0.404594</td>\n",
       "      <td>0.522979</td>\n",
       "      <td>-0.539346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044896</th>\n",
       "      <td>0</td>\n",
       "      <td>0.632045</td>\n",
       "      <td>0.421115</td>\n",
       "      <td>0.396929</td>\n",
       "      <td>0.722952</td>\n",
       "      <td>0.252903</td>\n",
       "      <td>-0.025530</td>\n",
       "      <td>0.076399</td>\n",
       "      <td>-0.572525</td>\n",
       "      <td>0.135311</td>\n",
       "      <td>0.644238</td>\n",
       "      <td>0.281961</td>\n",
       "      <td>0.380696</td>\n",
       "      <td>0.131932</td>\n",
       "      <td>-0.017822</td>\n",
       "      <td>0.404594</td>\n",
       "      <td>0.522979</td>\n",
       "      <td>0.509005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044897</th>\n",
       "      <td>0</td>\n",
       "      <td>0.455097</td>\n",
       "      <td>0.448486</td>\n",
       "      <td>0.396929</td>\n",
       "      <td>-0.449739</td>\n",
       "      <td>0.252903</td>\n",
       "      <td>0.179206</td>\n",
       "      <td>0.076399</td>\n",
       "      <td>0.138917</td>\n",
       "      <td>0.353022</td>\n",
       "      <td>0.306160</td>\n",
       "      <td>0.281961</td>\n",
       "      <td>0.380696</td>\n",
       "      <td>0.131932</td>\n",
       "      <td>-0.017822</td>\n",
       "      <td>0.404594</td>\n",
       "      <td>0.522979</td>\n",
       "      <td>0.509005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1044898 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         target  WOE_['Length']  WOE_['Words']  WOE_['Special Characters']  \\\n",
       "0             0        0.590682       0.550918                    0.396929   \n",
       "1             0        0.590682       0.421115                    0.396929   \n",
       "2             0        0.331453       0.288053                    0.396929   \n",
       "3             0        0.552418       0.629396                    0.396929   \n",
       "4             0        0.458060       0.550918                   -0.429643   \n",
       "...         ...             ...            ...                         ...   \n",
       "1044893       0        0.632045       0.629417                    0.396929   \n",
       "1044894       1        0.557712       0.629396                    0.396929   \n",
       "1044895       0       -0.855564      -0.878086                   -0.429643   \n",
       "1044896       0        0.632045       0.421115                    0.396929   \n",
       "1044897       0        0.455097       0.448486                    0.396929   \n",
       "\n",
       "         WOE_['Capital Words']  WOE_['Negative words']  WOE_['Stop words']  \\\n",
       "0                    -0.147791                0.252903            0.467112   \n",
       "1                     0.722952                0.252903           -0.025530   \n",
       "2                    -0.147791                0.252903            0.179206   \n",
       "3                    -0.147791                0.252903            0.390734   \n",
       "4                    -0.449739                0.252903            0.545425   \n",
       "...                        ...                     ...                 ...   \n",
       "1044893               0.722952                0.252903            0.179206   \n",
       "1044894              -0.147791                0.252903            0.467112   \n",
       "1044895               0.722952                0.252903           -0.834759   \n",
       "1044896               0.722952                0.252903           -0.025530   \n",
       "1044897              -0.449739                0.252903            0.179206   \n",
       "\n",
       "         WOE_['Question']  WOE_['Articles']  WOE_['Nouns']  WOE_['Verbs']  \\\n",
       "0                0.076399          0.138917       0.135311       0.644238   \n",
       "1                0.076399         -0.089787       0.135311       0.644238   \n",
       "2                0.076399          0.138917       0.496441       0.644238   \n",
       "3                0.076399          0.138917       0.135311       0.644238   \n",
       "4                0.076399          0.138917       0.353022      -0.132154   \n",
       "...                   ...               ...            ...            ...   \n",
       "1044893          0.076399          0.138917       0.353022       0.306160   \n",
       "1044894          0.076399         -0.089787       0.496441       0.306160   \n",
       "1044895          0.076399         -1.015604      -0.583569      -0.553839   \n",
       "1044896          0.076399         -0.572525       0.135311       0.644238   \n",
       "1044897          0.076399          0.138917       0.353022       0.306160   \n",
       "\n",
       "         WOE_['Adjectives']  WOE_['Question Words']  WOE_['Adverbs']  \\\n",
       "0                  0.281961                0.380696         0.131932   \n",
       "1                  0.281961                0.380696         0.131932   \n",
       "2                  0.281961               -0.368412         0.131932   \n",
       "3                  0.281961                0.380696         0.131932   \n",
       "4                 -0.269975               -0.368412         0.131932   \n",
       "...                     ...                     ...              ...   \n",
       "1044893            0.281961               -0.368412         0.131932   \n",
       "1044894            0.281961                0.380696         0.131932   \n",
       "1044895           -0.269975                0.380696         0.131932   \n",
       "1044896            0.281961                0.380696         0.131932   \n",
       "1044897            0.281961                0.380696         0.131932   \n",
       "\n",
       "         WOE_['Positive score']  WOE_['Negative score']  \\\n",
       "0                     -0.017822                0.404594   \n",
       "1                     -0.017822                0.404594   \n",
       "2                     -0.017822                0.404594   \n",
       "3                     -0.017822                0.404594   \n",
       "4                     -0.017822                0.404594   \n",
       "...                         ...                     ...   \n",
       "1044893               -0.017822                0.404594   \n",
       "1044894                0.561482                0.404594   \n",
       "1044895               -0.017822                0.404594   \n",
       "1044896               -0.017822                0.404594   \n",
       "1044897               -0.017822                0.404594   \n",
       "\n",
       "         WOE_['Neutral score']  WOE_['Final score']  \n",
       "0                     0.522979             0.509005  \n",
       "1                     0.522979             0.509005  \n",
       "2                     0.522979             0.509005  \n",
       "3                     0.522979             0.509005  \n",
       "4                     0.522979             0.509005  \n",
       "...                        ...                  ...  \n",
       "1044893               0.522979             0.509005  \n",
       "1044894              -0.269510             0.010548  \n",
       "1044895               0.522979            -0.539346  \n",
       "1044896               0.522979             0.509005  \n",
       "1044897               0.522979             0.509005  \n",
       "\n",
       "[1044898 rows x 18 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Substituting woe values into the training file\n",
    "f=1\n",
    "for i in traincols.drop(['target'],axis=1).columns:\n",
    "    ct=woe(traincols,'target',i)\n",
    "    if 'bin' in ct.columns:\n",
    "        val=[]\n",
    "        for j in traincols[i]:\n",
    "            flag=0\n",
    "            for m in range(0,len(ct),1):\n",
    "                if j in ct['bin'][m]:\n",
    "                    val.append(ct['WOE'][m])\n",
    "                    flag=1\n",
    "                    continue\n",
    "            if flag==0:\n",
    "                high=ct.loc[len(ct)-1,'bin']\n",
    "                if j>=high.right:\n",
    "                    val.append(ct['WOE'][len(ct)-1])\n",
    "                else:\n",
    "                    val.append(ct['WOE'][0])\n",
    "    else:\n",
    "        val=[]\n",
    "        for j in traincols[i]:\n",
    "            flag=0\n",
    "            for m in range(0,len(ct),1):\n",
    "                if j==ct[i][m]:\n",
    "                    val.append(ct['WOE'][m])\n",
    "                    flag=1\n",
    "                    continue\n",
    "            if flag==0:\n",
    "                val.append(ct['WOE'][0])\n",
    "    val=np.asarray(val,'float64')\n",
    "    woetrain[str('WOE_'+str(np.array(i).flatten()))]=val     \n",
    "    print(str(f)+'/'+str(len(traincols.drop(['target'],axis=1).columns)))\n",
    "    f=f+1\n",
    "woetrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T18:32:20.830358Z",
     "start_time": "2020-04-04T18:31:56.034666Z"
    }
   },
   "outputs": [],
   "source": [
    "# Saving the WOE substituted training file\n",
    "woetrain.to_csv(r'D:\\DS\\NLP\\quora-insincere-questions-classification\\woe20bin.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test file WOE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T04:31:10.675438Z",
     "start_time": "2020-04-04T04:31:02.411308Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating same features as training file- length, no of words, special characters, capital words\n",
    "leng=[len(test.loc[i,'question_text']) for i in test.index]\n",
    "test['Length']=leng\n",
    "words=[len(test.loc[i,'question_text'].split()) for i in test.index]\n",
    "test['Words']=words\n",
    "spchar = [len(re.sub('[A-Za-z0-9\\s]+', '', test.loc[i,'question_text'])) for i in test.index] \n",
    "test['Special Characters']=spchar\n",
    "capwrd=[len(re.findall('([A-Z][a-z]+)', test.loc[i,'question_text'])) for i in test.index]\n",
    "test['Capital Words']=capwrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T04:32:37.142170Z",
     "start_time": "2020-04-04T04:31:30.626866Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating same features as training file- positive words\n",
    "senti = SentimentIntensityAnalyzer()\n",
    "poslen=[]\n",
    "for i in test.index:\n",
    "    j=test.loc[i,'question_text']\n",
    "    pos=[]\n",
    "    for p in j.split():\n",
    "        if (senti.polarity_scores(p)['compound']) >= 0.5:\n",
    "            pos.append(p)\n",
    "    poslen.append(len(pos))\n",
    "test['Positive words']=poslen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T04:33:45.226287Z",
     "start_time": "2020-04-04T04:32:37.143173Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "      <th>Length</th>\n",
       "      <th>Words</th>\n",
       "      <th>Special Characters</th>\n",
       "      <th>Capital Words</th>\n",
       "      <th>Positive words</th>\n",
       "      <th>Negative words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What can you say about feminism?</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>What do you know about Bram Fischer and the Rivonia Trial?</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>How difficult is it to find a good instructor to take a class near you?</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>How do I become a fast learner both in my professional career and in my personal life?</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Has the United States become the largest dictatorship in the world?</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306100</th>\n",
       "      <td>On Quora is it as good as downvoting the answer if you are not up voting it?</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306101</th>\n",
       "      <td>Are the Wahabis Muslim's puritans?</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306110</th>\n",
       "      <td>What are some comic ideas for you Tube videos to shoot alone?</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306111</th>\n",
       "      <td>If you had $10 million of Bitcoin, could you sell it and pay no capital gain tax if you also quit work and had no ordinary income for the year?</td>\n",
       "      <td>0</td>\n",
       "      <td>143</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306120</th>\n",
       "      <td>How can one start a research project based on biochemistry at UG level?</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>261224 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                           question_text  \\\n",
       "10                                                                                                                      What can you say about feminism?   \n",
       "15                                                                                            What do you know about Bram Fischer and the Rivonia Trial?   \n",
       "16                                                                               How difficult is it to find a good instructor to take a class near you?   \n",
       "21                                                                How do I become a fast learner both in my professional career and in my personal life?   \n",
       "22                                                                                   Has the United States become the largest dictatorship in the world?   \n",
       "...                                                                                                                                                  ...   \n",
       "1306100                                                                     On Quora is it as good as downvoting the answer if you are not up voting it?   \n",
       "1306101                                                                                                               Are the Wahabis Muslim's puritans?   \n",
       "1306110                                                                                    What are some comic ideas for you Tube videos to shoot alone?   \n",
       "1306111  If you had $10 million of Bitcoin, could you sell it and pay no capital gain tax if you also quit work and had no ordinary income for the year?   \n",
       "1306120                                                                          How can one start a research project based on biochemistry at UG level?   \n",
       "\n",
       "         target  Length  Words  Special Characters  Capital Words  \\\n",
       "10            0      32      6                   1              1   \n",
       "15            0      58     11                   1              5   \n",
       "16            0      71     15                   1              1   \n",
       "21            0      86     17                   1              1   \n",
       "22            1      67     11                   1              3   \n",
       "...         ...     ...    ...                 ...            ...   \n",
       "1306100       0      76     17                   1              2   \n",
       "1306101       0      34      5                   2              3   \n",
       "1306110       0      61     12                   1              2   \n",
       "1306111       0     143     30                   3              2   \n",
       "1306120       0      71     13                   1              1   \n",
       "\n",
       "         Positive words  Negative words  \n",
       "10                    0               0  \n",
       "15                    0               0  \n",
       "16                    0               0  \n",
       "21                    0               0  \n",
       "22                    0               0  \n",
       "...                 ...             ...  \n",
       "1306100               0               0  \n",
       "1306101               0               0  \n",
       "1306110               0               0  \n",
       "1306111               1               0  \n",
       "1306120               0               0  \n",
       "\n",
       "[261224 rows x 8 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating same features as training file- negative words\n",
    "neglen=[]\n",
    "for i in test.index:\n",
    "    j=test.loc[i,'question_text']\n",
    "    neg=[]\n",
    "    for p in j.split():\n",
    "        if (senti.polarity_scores(p)['compound']) <= -0.5:\n",
    "            neg.append(p)\n",
    "    neglen.append(len(neg))\n",
    "test['Negative words']=neglen\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T04:33:52.300578Z",
     "start_time": "2020-04-04T04:33:45.228254Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating same features as training file- stop words\n",
    "stp=nltk.corpus.stopwords.words('english')\n",
    "nostp=[]\n",
    "for i in test.index:\n",
    "    j=test.loc[i,'question_text']\n",
    "    stpwrds=[]\n",
    "    for p in j.split():\n",
    "        if p in stp:\n",
    "            stpwrds.append(p)\n",
    "    nostp.append(len(stpwrds))\n",
    "test['Stop words']=nostp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T04:33:54.925320Z",
     "start_time": "2020-04-04T04:33:52.302044Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating same features as training file- exclamation marks\n",
    "exc=[]\n",
    "for i in test.index:\n",
    "    c=0\n",
    "    j=test.loc[i,'question_text']\n",
    "    for k in j.split():\n",
    "        if k.endswith('!'):\n",
    "            c+=1\n",
    "    exc.append(c)\n",
    "test['Exclamation']=exc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T04:33:57.508304Z",
     "start_time": "2020-04-04T04:33:54.926362Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating same features as training file- question marks\n",
    "ques=[]\n",
    "for i in test.index:\n",
    "    c=0\n",
    "    j=test.loc[i,'question_text']\n",
    "    for k in j.split():\n",
    "        if k.endswith('?'):\n",
    "            c+=1\n",
    "    ques.append(c)\n",
    "test[\"Question\"]=ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T04:37:31.456835Z",
     "start_time": "2020-04-04T04:33:57.509308Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 2000 3000 4000 5000 6000 7000 8000 9000 10000 11000 12000 13000 14000 15000 16000 17000 18000 19000 20000 21000 22000 23000 24000 25000 26000 27000 28000 29000 30000 31000 32000 33000 34000 35000 36000 37000 38000 39000 40000 41000 42000 43000 44000 45000 46000 47000 48000 49000 50000 51000 52000 53000 54000 55000 56000 57000 58000 59000 60000 61000 62000 63000 64000 65000 66000 67000 68000 69000 70000 71000 72000 73000 74000 75000 76000 77000 78000 79000 80000 81000 82000 83000 84000 85000 86000 87000 88000 89000 90000 91000 92000 93000 94000 95000 96000 97000 98000 99000 100000 101000 102000 103000 104000 105000 106000 107000 108000 109000 110000 111000 112000 113000 114000 115000 116000 117000 118000 119000 120000 121000 122000 123000 124000 125000 126000 127000 128000 129000 130000 131000 132000 133000 134000 135000 136000 137000 138000 139000 140000 141000 142000 143000 144000 145000 146000 147000 148000 149000 150000 151000 152000 153000 154000 155000 156000 157000 158000 159000 160000 161000 162000 163000 164000 165000 166000 167000 168000 169000 170000 171000 172000 173000 174000 175000 176000 177000 178000 179000 180000 181000 182000 183000 184000 185000 186000 187000 188000 189000 190000 191000 192000 193000 194000 195000 196000 197000 198000 199000 200000 201000 202000 203000 204000 205000 206000 207000 208000 209000 210000 211000 212000 213000 214000 215000 216000 217000 218000 219000 220000 221000 222000 223000 224000 225000 226000 227000 228000 229000 230000 231000 232000 233000 234000 235000 236000 237000 238000 239000 240000 241000 242000 243000 244000 245000 246000 247000 248000 249000 250000 251000 252000 253000 254000 255000 256000 257000 258000 259000 260000 261000 "
     ]
    }
   ],
   "source": [
    "# Creating same features as training file- parts of speech\n",
    "deter=[]\n",
    "noun=[]\n",
    "verb=[]\n",
    "adj=[]\n",
    "prn=[]\n",
    "advr=[]\n",
    "whq=[]\n",
    "for i in test.index:\n",
    "    j=test.loc[i,'question_text']\n",
    "    k=nltk.pos_tag(j.split())\n",
    "    det=[x[1] for x in k if x[1].startswith('DT')]\n",
    "    nn=[x[1] for x in k if x[1].startswith('NN')]\n",
    "    vb=[x[1] for x in k if x[1].startswith('VB')]\n",
    "    ad=[x[1] for x in k if x[1].startswith('JJ')]\n",
    "    pr=[x[1] for x in k if x[1].startswith('PR')]\n",
    "    adv=[x[1] for x in k if x[1].startswith('RB')]\n",
    "    wh=[x[1] for x in k if x[1].startswith('WR')]\n",
    "    deter.append(len(det))\n",
    "    noun.append(len(nn))\n",
    "    verb.append(len(vb))\n",
    "    adj.append(len(ad))\n",
    "    prn.append(len(pr))\n",
    "    advr.append(len(adv))\n",
    "    whq.append(len(wh))\n",
    "    if len(deter)%1000==0:\n",
    "        print(len(deter),end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T04:37:31.822895Z",
     "start_time": "2020-04-04T04:37:31.457796Z"
    }
   },
   "outputs": [],
   "source": [
    "test['Articles']=deter\n",
    "test['Nouns']=noun\n",
    "test['Verbs']=verb\n",
    "test['Adjectives']=adj\n",
    "test['Pronouns']=prn\n",
    "test['Question Words']=whq\n",
    "test['Adverbs']=advr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T04:38:12.207884Z",
     "start_time": "2020-04-04T04:37:31.823864Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 2000 3000 4000 5000 6000 7000 8000 9000 10000 11000 12000 13000 14000 15000 16000 17000 18000 19000 20000 21000 22000 23000 24000 25000 26000 27000 28000 29000 30000 31000 32000 33000 34000 35000 36000 37000 38000 39000 40000 41000 42000 43000 44000 45000 46000 47000 48000 49000 50000 51000 52000 53000 54000 55000 56000 57000 58000 59000 60000 61000 62000 63000 64000 65000 66000 67000 68000 69000 70000 71000 72000 73000 74000 75000 76000 77000 78000 79000 80000 81000 82000 83000 84000 85000 86000 87000 88000 89000 90000 91000 92000 93000 94000 95000 96000 97000 98000 99000 100000 101000 102000 103000 104000 105000 106000 107000 108000 109000 110000 111000 112000 113000 114000 115000 116000 117000 118000 119000 120000 121000 122000 123000 124000 125000 126000 127000 128000 129000 130000 131000 132000 133000 134000 135000 136000 137000 138000 139000 140000 141000 142000 143000 144000 145000 146000 147000 148000 149000 150000 151000 152000 153000 154000 155000 156000 157000 158000 159000 160000 161000 162000 163000 164000 165000 166000 167000 168000 169000 170000 171000 172000 173000 174000 175000 176000 177000 178000 179000 180000 181000 182000 183000 184000 185000 186000 187000 188000 189000 190000 191000 192000 193000 194000 195000 196000 197000 198000 199000 200000 201000 202000 203000 204000 205000 206000 207000 208000 209000 210000 211000 212000 213000 214000 215000 216000 217000 218000 219000 220000 221000 222000 223000 224000 225000 226000 227000 228000 229000 230000 231000 232000 233000 234000 235000 236000 237000 238000 239000 240000 241000 242000 243000 244000 245000 246000 247000 248000 249000 250000 251000 252000 253000 254000 255000 256000 257000 258000 259000 260000 261000 "
     ]
    }
   ],
   "source": [
    "# Creating same features as training file- sentiment values\n",
    "neg=[]\n",
    "neu=[]\n",
    "pos=[]\n",
    "comp=[]\n",
    "for i in test.index:\n",
    "    j=test.loc[i,'question_text']\n",
    "    k=senti.polarity_scores(j)\n",
    "    neg.append(k['neg'])\n",
    "    neu.append(k['neu'])\n",
    "    pos.append(k['pos'])\n",
    "    comp.append(k['compound'])\n",
    "    if len(neg)%1000==0:\n",
    "        print(len(neg),end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T04:38:12.556946Z",
     "start_time": "2020-04-04T04:38:12.208838Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "      <th>Length</th>\n",
       "      <th>Words</th>\n",
       "      <th>Special Characters</th>\n",
       "      <th>Capital Words</th>\n",
       "      <th>Positive words</th>\n",
       "      <th>Negative words</th>\n",
       "      <th>Stop words</th>\n",
       "      <th>Exclamation</th>\n",
       "      <th>...</th>\n",
       "      <th>Nouns</th>\n",
       "      <th>Verbs</th>\n",
       "      <th>Adjectives</th>\n",
       "      <th>Pronouns</th>\n",
       "      <th>Question Words</th>\n",
       "      <th>Adverbs</th>\n",
       "      <th>Positive score</th>\n",
       "      <th>Negative score</th>\n",
       "      <th>Neutral score</th>\n",
       "      <th>Final score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What can you say about feminism?</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>What do you know about Bram Fischer and the Rivonia Trial?</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>How difficult is it to find a good instructor to take a class near you?</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.1027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>How do I become a fast learner both in my professional career and in my personal life?</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Has the United States become the largest dictatorship in the world?</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.4215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306100</th>\n",
       "      <td>On Quora is it as good as downvoting the answer if you are not up voting it?</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.4404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306101</th>\n",
       "      <td>Are the Wahabis Muslim's puritans?</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306110</th>\n",
       "      <td>What are some comic ideas for you Tube videos to shoot alone?</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.694</td>\n",
       "      <td>-0.5267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306111</th>\n",
       "      <td>If you had $10 million of Bitcoin, could you sell it and pay no capital gain tax if you also quit work and had no ordinary income for the year?</td>\n",
       "      <td>0</td>\n",
       "      <td>143</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.739</td>\n",
       "      <td>-0.1027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306120</th>\n",
       "      <td>How can one start a research project based on biochemistry at UG level?</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>261224 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                           question_text  \\\n",
       "10                                                                                                                      What can you say about feminism?   \n",
       "15                                                                                            What do you know about Bram Fischer and the Rivonia Trial?   \n",
       "16                                                                               How difficult is it to find a good instructor to take a class near you?   \n",
       "21                                                                How do I become a fast learner both in my professional career and in my personal life?   \n",
       "22                                                                                   Has the United States become the largest dictatorship in the world?   \n",
       "...                                                                                                                                                  ...   \n",
       "1306100                                                                     On Quora is it as good as downvoting the answer if you are not up voting it?   \n",
       "1306101                                                                                                               Are the Wahabis Muslim's puritans?   \n",
       "1306110                                                                                    What are some comic ideas for you Tube videos to shoot alone?   \n",
       "1306111  If you had $10 million of Bitcoin, could you sell it and pay no capital gain tax if you also quit work and had no ordinary income for the year?   \n",
       "1306120                                                                          How can one start a research project based on biochemistry at UG level?   \n",
       "\n",
       "         target  Length  Words  Special Characters  Capital Words  \\\n",
       "10            0      32      6                   1              1   \n",
       "15            0      58     11                   1              5   \n",
       "16            0      71     15                   1              1   \n",
       "21            0      86     17                   1              1   \n",
       "22            1      67     11                   1              3   \n",
       "...         ...     ...    ...                 ...            ...   \n",
       "1306100       0      76     17                   1              2   \n",
       "1306101       0      34      5                   2              3   \n",
       "1306110       0      61     12                   1              2   \n",
       "1306111       0     143     30                   3              2   \n",
       "1306120       0      71     13                   1              1   \n",
       "\n",
       "         Positive words  Negative words  Stop words  Exclamation  ...  Nouns  \\\n",
       "10                    0               0           3            0  ...      1   \n",
       "15                    0               0           5            0  ...      4   \n",
       "16                    0               0           6            0  ...      3   \n",
       "21                    0               0           8            0  ...      3   \n",
       "22                    0               0           4            0  ...      4   \n",
       "...                 ...             ...         ...          ...  ...    ...   \n",
       "1306100               0               0          10            0  ...      3   \n",
       "1306101               0               0           1            0  ...      3   \n",
       "1306110               0               0           5            0  ...      3   \n",
       "1306111               1               0          14            0  ...      7   \n",
       "1306120               0               0           4            0  ...      5   \n",
       "\n",
       "         Verbs  Adjectives  Pronouns  Question Words  Adverbs  Positive score  \\\n",
       "10           1           0         1               0        0           0.000   \n",
       "15           2           0         1               0        0           0.000   \n",
       "16           3           2         1               1        0           0.177   \n",
       "21           2           3         3               1        0           0.000   \n",
       "22           2           1         0               0        0           0.219   \n",
       "...        ...         ...       ...             ...      ...             ...   \n",
       "1306100      4           1         2               0        2           0.153   \n",
       "1306101      1           0         0               0        0           0.000   \n",
       "1306110      3           1         1               0        0           0.000   \n",
       "1306111      6           1         4               0        1           0.097   \n",
       "1306120      2           0         0               1        0           0.000   \n",
       "\n",
       "         Negative score  Neutral score  Final score  \n",
       "10                0.000          1.000       0.0000  \n",
       "15                0.000          1.000       0.0000  \n",
       "16                0.152          0.671       0.1027  \n",
       "21                0.000          1.000       0.0000  \n",
       "22                0.000          0.781       0.4215  \n",
       "...                 ...            ...          ...  \n",
       "1306100           0.000          0.847       0.4404  \n",
       "1306101           0.000          1.000       0.0000  \n",
       "1306110           0.306          0.694      -0.5267  \n",
       "1306111           0.165          0.739      -0.1027  \n",
       "1306120           0.000          1.000       0.0000  \n",
       "\n",
       "[261224 rows x 22 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Positive score']=pos\n",
    "test['Negative score']=neg\n",
    "test['Neutral score']=neu\n",
    "test['Final score']=comp\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T04:38:14.426418Z",
     "start_time": "2020-04-04T04:38:12.557956Z"
    }
   },
   "outputs": [],
   "source": [
    "# Saving basic features file\n",
    "test.to_csv(r'D:\\DS\\NLP\\quora-insincere-questions-classification\\testfeature.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T18:32:22.028149Z",
     "start_time": "2020-04-04T18:32:20.831297Z"
    }
   },
   "outputs": [],
   "source": [
    "testfeature=pd.read_csv(r'D:\\DS\\NLP\\quora-insincere-questions-classification\\testfeature.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T02:35:29.490345Z",
     "start_time": "2020-04-05T02:35:29.459278Z"
    }
   },
   "outputs": [],
   "source": [
    "# Getting important columns only\n",
    "testcols=testfeature.loc[:,impcols]\n",
    "testcols['target']=testfeature['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T02:35:39.443024Z",
     "start_time": "2020-04-05T02:35:39.412751Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating a dataframe to take in woe values\n",
    "woetest=pd.DataFrame()\n",
    "woetest['target']=testfeature['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T02:56:36.380792Z",
     "start_time": "2020-04-05T02:35:40.581413Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/17\n",
      "2/17\n",
      "3/17\n",
      "4/17\n",
      "5/17\n",
      "6/17\n",
      "7/17\n",
      "8/17\n",
      "9/17\n",
      "10/17\n",
      "11/17\n",
      "12/17\n",
      "13/17\n",
      "14/17\n",
      "15/17\n",
      "16/17\n",
      "17/17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>WOE_['Length']</th>\n",
       "      <th>WOE_['Words']</th>\n",
       "      <th>WOE_['Special Characters']</th>\n",
       "      <th>WOE_['Capital Words']</th>\n",
       "      <th>WOE_['Negative words']</th>\n",
       "      <th>WOE_['Stop words']</th>\n",
       "      <th>WOE_['Question']</th>\n",
       "      <th>WOE_['Articles']</th>\n",
       "      <th>WOE_['Nouns']</th>\n",
       "      <th>WOE_['Verbs']</th>\n",
       "      <th>WOE_['Adjectives']</th>\n",
       "      <th>WOE_['Question Words']</th>\n",
       "      <th>WOE_['Adverbs']</th>\n",
       "      <th>WOE_['Positive score']</th>\n",
       "      <th>WOE_['Negative score']</th>\n",
       "      <th>WOE_['Neutral score']</th>\n",
       "      <th>WOE_['Final score']</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.455097</td>\n",
       "      <td>0.448486</td>\n",
       "      <td>0.396929</td>\n",
       "      <td>0.722952</td>\n",
       "      <td>0.252903</td>\n",
       "      <td>0.545425</td>\n",
       "      <td>0.076399</td>\n",
       "      <td>0.138917</td>\n",
       "      <td>0.645670</td>\n",
       "      <td>0.644238</td>\n",
       "      <td>0.281961</td>\n",
       "      <td>0.380696</td>\n",
       "      <td>0.131932</td>\n",
       "      <td>-0.017822</td>\n",
       "      <td>0.404594</td>\n",
       "      <td>0.522979</td>\n",
       "      <td>0.509005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.505908</td>\n",
       "      <td>0.421115</td>\n",
       "      <td>0.396929</td>\n",
       "      <td>-0.974260</td>\n",
       "      <td>0.252903</td>\n",
       "      <td>0.216139</td>\n",
       "      <td>0.076399</td>\n",
       "      <td>0.138917</td>\n",
       "      <td>0.135311</td>\n",
       "      <td>0.306160</td>\n",
       "      <td>0.281961</td>\n",
       "      <td>0.380696</td>\n",
       "      <td>0.131932</td>\n",
       "      <td>-0.017822</td>\n",
       "      <td>0.404594</td>\n",
       "      <td>0.522979</td>\n",
       "      <td>0.509005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.240919</td>\n",
       "      <td>-0.075055</td>\n",
       "      <td>0.396929</td>\n",
       "      <td>0.722952</td>\n",
       "      <td>0.252903</td>\n",
       "      <td>-0.025530</td>\n",
       "      <td>0.076399</td>\n",
       "      <td>-0.089787</td>\n",
       "      <td>0.353022</td>\n",
       "      <td>-0.132154</td>\n",
       "      <td>-0.269975</td>\n",
       "      <td>-0.368412</td>\n",
       "      <td>0.131932</td>\n",
       "      <td>-0.310125</td>\n",
       "      <td>-0.888514</td>\n",
       "      <td>-0.387307</td>\n",
       "      <td>-0.111049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.205666</td>\n",
       "      <td>-0.248210</td>\n",
       "      <td>0.396929</td>\n",
       "      <td>0.722952</td>\n",
       "      <td>0.252903</td>\n",
       "      <td>-0.449134</td>\n",
       "      <td>0.076399</td>\n",
       "      <td>-0.089787</td>\n",
       "      <td>0.353022</td>\n",
       "      <td>0.306160</td>\n",
       "      <td>-0.757623</td>\n",
       "      <td>-0.368412</td>\n",
       "      <td>0.131932</td>\n",
       "      <td>-0.017822</td>\n",
       "      <td>0.404594</td>\n",
       "      <td>0.522979</td>\n",
       "      <td>0.509005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.354693</td>\n",
       "      <td>0.421115</td>\n",
       "      <td>0.396929</td>\n",
       "      <td>-0.449739</td>\n",
       "      <td>0.252903</td>\n",
       "      <td>0.467112</td>\n",
       "      <td>0.076399</td>\n",
       "      <td>-0.572525</td>\n",
       "      <td>0.135311</td>\n",
       "      <td>0.306160</td>\n",
       "      <td>0.281961</td>\n",
       "      <td>0.380696</td>\n",
       "      <td>0.131932</td>\n",
       "      <td>-0.062996</td>\n",
       "      <td>0.404594</td>\n",
       "      <td>-0.315595</td>\n",
       "      <td>0.111252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261219</th>\n",
       "      <td>0</td>\n",
       "      <td>0.156899</td>\n",
       "      <td>-0.248210</td>\n",
       "      <td>0.396929</td>\n",
       "      <td>-0.147791</td>\n",
       "      <td>0.252903</td>\n",
       "      <td>-0.834759</td>\n",
       "      <td>0.076399</td>\n",
       "      <td>0.138917</td>\n",
       "      <td>0.353022</td>\n",
       "      <td>-0.553839</td>\n",
       "      <td>0.281961</td>\n",
       "      <td>0.380696</td>\n",
       "      <td>-1.017107</td>\n",
       "      <td>-0.618379</td>\n",
       "      <td>0.404594</td>\n",
       "      <td>-0.395241</td>\n",
       "      <td>0.596492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261220</th>\n",
       "      <td>0</td>\n",
       "      <td>0.455097</td>\n",
       "      <td>0.288053</td>\n",
       "      <td>-0.231227</td>\n",
       "      <td>-0.449739</td>\n",
       "      <td>0.252903</td>\n",
       "      <td>0.179206</td>\n",
       "      <td>0.076399</td>\n",
       "      <td>0.138917</td>\n",
       "      <td>0.353022</td>\n",
       "      <td>0.644238</td>\n",
       "      <td>0.281961</td>\n",
       "      <td>0.380696</td>\n",
       "      <td>0.131932</td>\n",
       "      <td>-0.017822</td>\n",
       "      <td>0.404594</td>\n",
       "      <td>0.522979</td>\n",
       "      <td>0.509005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261221</th>\n",
       "      <td>0</td>\n",
       "      <td>0.458060</td>\n",
       "      <td>0.301318</td>\n",
       "      <td>0.396929</td>\n",
       "      <td>-0.147791</td>\n",
       "      <td>0.252903</td>\n",
       "      <td>0.216139</td>\n",
       "      <td>0.076399</td>\n",
       "      <td>0.138917</td>\n",
       "      <td>0.353022</td>\n",
       "      <td>-0.132154</td>\n",
       "      <td>0.281961</td>\n",
       "      <td>0.380696</td>\n",
       "      <td>0.131932</td>\n",
       "      <td>-0.017822</td>\n",
       "      <td>-0.895498</td>\n",
       "      <td>-0.387307</td>\n",
       "      <td>-0.997039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261222</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.855564</td>\n",
       "      <td>-1.317091</td>\n",
       "      <td>-0.429643</td>\n",
       "      <td>-0.147791</td>\n",
       "      <td>0.252903</td>\n",
       "      <td>-1.253889</td>\n",
       "      <td>0.076399</td>\n",
       "      <td>-0.572525</td>\n",
       "      <td>-0.583569</td>\n",
       "      <td>-1.056555</td>\n",
       "      <td>0.281961</td>\n",
       "      <td>0.380696</td>\n",
       "      <td>0.131932</td>\n",
       "      <td>-0.017822</td>\n",
       "      <td>-0.888514</td>\n",
       "      <td>-0.258340</td>\n",
       "      <td>0.509005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261223</th>\n",
       "      <td>0</td>\n",
       "      <td>0.240919</td>\n",
       "      <td>0.201565</td>\n",
       "      <td>0.396929</td>\n",
       "      <td>0.722952</td>\n",
       "      <td>0.252903</td>\n",
       "      <td>0.467112</td>\n",
       "      <td>0.076399</td>\n",
       "      <td>0.138917</td>\n",
       "      <td>-0.116554</td>\n",
       "      <td>0.306160</td>\n",
       "      <td>0.281961</td>\n",
       "      <td>-0.368412</td>\n",
       "      <td>0.131932</td>\n",
       "      <td>-0.017822</td>\n",
       "      <td>0.404594</td>\n",
       "      <td>0.522979</td>\n",
       "      <td>0.509005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>261224 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        target  WOE_['Length']  WOE_['Words']  WOE_['Special Characters']  \\\n",
       "0            0        0.455097       0.448486                    0.396929   \n",
       "1            0        0.505908       0.421115                    0.396929   \n",
       "2            0        0.240919      -0.075055                    0.396929   \n",
       "3            0       -0.205666      -0.248210                    0.396929   \n",
       "4            1        0.354693       0.421115                    0.396929   \n",
       "...        ...             ...            ...                         ...   \n",
       "261219       0        0.156899      -0.248210                    0.396929   \n",
       "261220       0        0.455097       0.288053                   -0.231227   \n",
       "261221       0        0.458060       0.301318                    0.396929   \n",
       "261222       0       -0.855564      -1.317091                   -0.429643   \n",
       "261223       0        0.240919       0.201565                    0.396929   \n",
       "\n",
       "        WOE_['Capital Words']  WOE_['Negative words']  WOE_['Stop words']  \\\n",
       "0                    0.722952                0.252903            0.545425   \n",
       "1                   -0.974260                0.252903            0.216139   \n",
       "2                    0.722952                0.252903           -0.025530   \n",
       "3                    0.722952                0.252903           -0.449134   \n",
       "4                   -0.449739                0.252903            0.467112   \n",
       "...                       ...                     ...                 ...   \n",
       "261219              -0.147791                0.252903           -0.834759   \n",
       "261220              -0.449739                0.252903            0.179206   \n",
       "261221              -0.147791                0.252903            0.216139   \n",
       "261222              -0.147791                0.252903           -1.253889   \n",
       "261223               0.722952                0.252903            0.467112   \n",
       "\n",
       "        WOE_['Question']  WOE_['Articles']  WOE_['Nouns']  WOE_['Verbs']  \\\n",
       "0               0.076399          0.138917       0.645670       0.644238   \n",
       "1               0.076399          0.138917       0.135311       0.306160   \n",
       "2               0.076399         -0.089787       0.353022      -0.132154   \n",
       "3               0.076399         -0.089787       0.353022       0.306160   \n",
       "4               0.076399         -0.572525       0.135311       0.306160   \n",
       "...                  ...               ...            ...            ...   \n",
       "261219          0.076399          0.138917       0.353022      -0.553839   \n",
       "261220          0.076399          0.138917       0.353022       0.644238   \n",
       "261221          0.076399          0.138917       0.353022      -0.132154   \n",
       "261222          0.076399         -0.572525      -0.583569      -1.056555   \n",
       "261223          0.076399          0.138917      -0.116554       0.306160   \n",
       "\n",
       "        WOE_['Adjectives']  WOE_['Question Words']  WOE_['Adverbs']  \\\n",
       "0                 0.281961                0.380696         0.131932   \n",
       "1                 0.281961                0.380696         0.131932   \n",
       "2                -0.269975               -0.368412         0.131932   \n",
       "3                -0.757623               -0.368412         0.131932   \n",
       "4                 0.281961                0.380696         0.131932   \n",
       "...                    ...                     ...              ...   \n",
       "261219            0.281961                0.380696        -1.017107   \n",
       "261220            0.281961                0.380696         0.131932   \n",
       "261221            0.281961                0.380696         0.131932   \n",
       "261222            0.281961                0.380696         0.131932   \n",
       "261223            0.281961               -0.368412         0.131932   \n",
       "\n",
       "        WOE_['Positive score']  WOE_['Negative score']  WOE_['Neutral score']  \\\n",
       "0                    -0.017822                0.404594               0.522979   \n",
       "1                    -0.017822                0.404594               0.522979   \n",
       "2                    -0.310125               -0.888514              -0.387307   \n",
       "3                    -0.017822                0.404594               0.522979   \n",
       "4                    -0.062996                0.404594              -0.315595   \n",
       "...                        ...                     ...                    ...   \n",
       "261219               -0.618379                0.404594              -0.395241   \n",
       "261220               -0.017822                0.404594               0.522979   \n",
       "261221               -0.017822               -0.895498              -0.387307   \n",
       "261222               -0.017822               -0.888514              -0.258340   \n",
       "261223               -0.017822                0.404594               0.522979   \n",
       "\n",
       "        WOE_['Final score']  \n",
       "0                  0.509005  \n",
       "1                  0.509005  \n",
       "2                 -0.111049  \n",
       "3                  0.509005  \n",
       "4                  0.111252  \n",
       "...                     ...  \n",
       "261219             0.596492  \n",
       "261220             0.509005  \n",
       "261221            -0.997039  \n",
       "261222             0.509005  \n",
       "261223             0.509005  \n",
       "\n",
       "[261224 rows x 18 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Substituting feature values with woe values\n",
    "f=1\n",
    "for i in traincols.drop(['target'],axis=1).columns:\n",
    "    ct=woe(traincols,'target',i)\n",
    "    if 'bin' in ct.columns:\n",
    "        val=[]\n",
    "        for j in testcols[i]:\n",
    "            flag=0\n",
    "            for m in range(0,len(ct),1):\n",
    "                if j in ct['bin'][m]:\n",
    "                    val.append(ct['WOE'][m])\n",
    "                    flag=1\n",
    "                    continue\n",
    "            if flag==0:\n",
    "                high=ct.loc[len(ct)-1,'bin']\n",
    "                if j>=high.right:\n",
    "                    val.append(ct['WOE'][len(ct)-1])\n",
    "                else:\n",
    "                    val.append(ct['WOE'][0])\n",
    "    else:\n",
    "        val=[]\n",
    "        for j in testcols[i]:\n",
    "            flag=0\n",
    "            for m in range(0,len(ct),1):\n",
    "                if j==ct[i][m]:\n",
    "                    val.append(ct['WOE'][m])\n",
    "                    flag=1\n",
    "                    continue\n",
    "            if flag==0:\n",
    "                val.append(ct['WOE'][0])\n",
    "    val=np.asarray(val,'float64')\n",
    "    woetest[str('WOE_'+str(np.array(i).flatten()))]=val     \n",
    "    print(str(f)+'/'+str(len(traincols.drop(['target'],axis=1).columns)))\n",
    "    f=f+1\n",
    "woetest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T02:56:45.172767Z",
     "start_time": "2020-04-05T02:56:36.382787Z"
    }
   },
   "outputs": [],
   "source": [
    "# Saving substituted file\n",
    "woetest.to_csv(r'D:\\DS\\NLP\\quora-insincere-questions-classification\\woetest20bin.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T10:52:53.930597Z",
     "start_time": "2020-04-09T10:52:53.914986Z"
    }
   },
   "outputs": [],
   "source": [
    "# Formatting puncutations by adding space before them\n",
    "puncts = [',',',','’',',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n",
    " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
    " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
    " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
    " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n",
    "def clean_punct(x):\n",
    "    for punct in puncts:\n",
    "        if punct in x:\n",
    "            x=x.replace(punct,' {}' .format(punct))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T10:52:53.946229Z",
     "start_time": "2020-04-09T10:52:53.930597Z"
    }
   },
   "outputs": [],
   "source": [
    "# Adding space before digits\n",
    "def spacing_digit(x):\n",
    "    re_tok=re.compile('([0-9])')\n",
    "    return re_tok.sub(r' \\1 ', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T10:52:53.961862Z",
     "start_time": "2020-04-09T10:52:53.946229Z"
    }
   },
   "outputs": [],
   "source": [
    "# Adding space before numbers\n",
    "def spacing_number(x):\n",
    "    re_tok=re.compile('([0-9]{1,})')\n",
    "    return re_tok.sub(r' \\1 ', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T10:52:53.977471Z",
     "start_time": "2020-04-09T10:52:53.961862Z"
    }
   },
   "outputs": [],
   "source": [
    "#def remove_number(x):\n",
    " #   return re.sub('\\d+',' ',x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T10:52:54.024302Z",
     "start_time": "2020-04-09T10:52:53.993091Z"
    }
   },
   "outputs": [],
   "source": [
    "# Replacing contraction with full form\n",
    "contraction_dict={\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"‘cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\", \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\", \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\", \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "def _get_mispell(contraction_dict):\n",
    "    mispell_re=re.compile('(%s)' % '|'.join(contraction_dict.keys()))\n",
    "    return contraction_dict,mispell_re\n",
    "\n",
    "mispellings,mispellings_re= _get_mispell(contraction_dict)\n",
    "def replace_contractions(text):\n",
    "    def replace(match):\n",
    "        return mispellings[match.group(0)]\n",
    "    return mispellings_re.sub(replace,text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T10:52:57.679693Z",
     "start_time": "2020-04-09T10:52:57.664106Z"
    }
   },
   "outputs": [],
   "source": [
    "# Removing stop words\n",
    "stpwrd=nltk.corpus.stopwords.words('english')\n",
    "def remove_stopwords(text, is_lower_case=True):\n",
    "    tokenizer=nltk.tokenize.toktok.ToktokTokenizer()\n",
    "    tokens=tokenizer.tokenize(text)\n",
    "    tokens=[token.strip() for token in tokens]\n",
    "    filtered_tokens=[token for token in tokens if token not in stpwrd]\n",
    "    filtered_text=\" \".join(filtered_tokens)\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T10:52:58.117124Z",
     "start_time": "2020-04-09T10:52:58.085903Z"
    }
   },
   "outputs": [],
   "source": [
    "# Replacing word with its lemma form\n",
    "wordnet_lemmatizer=nltk.stem.WordNetLemmatizer()\n",
    "def lemma_text(text):\n",
    "    tokenizer=nltk.tokenize.toktok.ToktokTokenizer()\n",
    "    tokens=tokenizer.tokenize(text)\n",
    "    tokens=[token.strip() for token in tokens]\n",
    "    tokens=[wordnet_lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T10:52:59.382449Z",
     "start_time": "2020-04-09T10:52:59.366798Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function that combines all above processing function\n",
    "def clean_sentence(x):\n",
    "    x=x.lower()\n",
    "    x=clean_punct(x)\n",
    "    x=spacing_digit(x)\n",
    "    x=spacing_number(x)\n",
    "    #x=remove_number(x)\n",
    "    x=remove_stopwords(x)\n",
    "    x=replace_contractions(x)\n",
    "    x=lemma_text(x)\n",
    "    x=x.replace(\"'\",\"\")\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading WOE Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T13:00:12.257914Z",
     "start_time": "2020-04-09T12:59:55.917785Z"
    }
   },
   "outputs": [],
   "source": [
    "#Load if kernel restarted\n",
    "woetrain=pd.read_csv(r'D:\\DS\\NLP\\quora-insincere-questions-classification\\woe20bin.csv')\n",
    "woetest=pd.read_csv(r'D:\\DS\\NLP\\quora-insincere-questions-classification\\woetest20bin.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T13:00:12.351387Z",
     "start_time": "2020-04-09T13:00:12.257914Z"
    }
   },
   "outputs": [],
   "source": [
    "woetr=woetrain.drop(['target','Unnamed: 0'],axis=1)\n",
    "woete=woetest.drop(['target','Unnamed: 0'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T10:53:34.717896Z",
     "start_time": "2020-04-09T10:53:34.671034Z"
    }
   },
   "outputs": [],
   "source": [
    "trainwu=train.copy()\n",
    "testwu=test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T10:56:37.180141Z",
     "start_time": "2020-04-09T10:53:34.890209Z"
    }
   },
   "outputs": [],
   "source": [
    "# Processing the training file\n",
    "trainwu[\"question_text\"] = trainwu[\"question_text\"].apply(lambda x:clean_sentence(x))\n",
    "testwu[\"question_text\"] = testwu[\"question_text\"].apply(lambda x:clean_sentence(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T03:37:24.567409Z",
     "start_time": "2020-04-08T03:37:24.449692Z"
    }
   },
   "outputs": [],
   "source": [
    "#Run this only if csv not loaded in previous step\n",
    "woetr=woetrain.drop(['target'],axis=1)\n",
    "woete=woetest.drop(['target'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T10:39:48.061271Z",
     "start_time": "2020-04-09T10:39:48.045776Z"
    }
   },
   "outputs": [],
   "source": [
    "# TFIDF vectorizer initiation\n",
    "tfidf=TfidfVectorizer(ngram_range=(1,3),analyzer='word',min_df=1,max_df=0.99,strip_accents='unicode',\n",
    "                                 sublinear_tf=True,dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T10:40:50.469056Z",
     "start_time": "2020-04-09T10:39:48.061271Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=0.99, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 3), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents='unicode',\n",
       "                sublinear_tf=True, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feeding all words to tfidf\n",
    "vocab=list(trainwu['question_text'].values)+list(testwu['question_text'].values)\n",
    "tfidf.fit(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T10:41:24.164447Z",
     "start_time": "2020-04-09T10:40:50.469056Z"
    }
   },
   "outputs": [],
   "source": [
    "# Transforming the training and test files to tfidf values\n",
    "xtrain=tfidf.transform(list(trainwu['question_text'].values))\n",
    "xtest=tfidf.transform(list(testwu['question_text'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T10:41:25.752471Z",
     "start_time": "2020-04-09T10:41:24.164447Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1044898, 8533794)\n"
     ]
    }
   ],
   "source": [
    "# Concatenating WOE files\n",
    "finaltrain = sp.sparse.hstack((xtrain, woetr))\n",
    "finaltest=sp.sparse.hstack((xtest,woete))\n",
    "print(finaltrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T10:42:51.162161Z",
     "start_time": "2020-04-09T10:41:25.752471Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 40 epochs took 84 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.4, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=150, multi_class='auto', n_jobs=-1, penalty='l2',\n",
       "                   random_state=None, solver='saga', tol=0.0001, verbose=3,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic regression training\n",
    "logit1=LogisticRegression(n_jobs=-1,class_weight='balanced',penalty='l2',verbose=3,solver='saga',max_iter=150,C=0.4)\n",
    "logit1.fit(finaltrain,train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T10:42:59.879120Z",
     "start_time": "2020-04-09T10:42:51.162161Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training F1 score: 0.6118175827850393\n",
      "Testing F1 score: 0.5331526396556191\n",
      "Optimum F1 score: 0.59\n"
     ]
    }
   ],
   "source": [
    "# Prediction and optimum f1 score\n",
    "pred=logit1.predict(finaltrain)\n",
    "print('Training F1 score:',metrics.f1_score(train['target'],pred))\n",
    "pred=logit1.predict(finaltest)\n",
    "print('Testing F1 score:',metrics.f1_score(test['target'],pred))\n",
    "pred=logit1.predict_proba(finaltest)\n",
    "pred=pred[:,1]\n",
    "search_result = threshold_search(test['target'], pred)\n",
    "print('Optimum F1 score:',round(search_result['f1'],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T10:44:49.229414Z",
     "start_time": "2020-04-09T10:44:47.870362Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>target</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>L1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>172360</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.027577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>188522</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.022630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1235537</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.055480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>345543</td>\n",
       "      <td>0</td>\n",
       "      <td>0.101580</td>\n",
       "      <td>0.057472</td>\n",
       "      <td>0.688056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>566414</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.123943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044893</th>\n",
       "      <td>1044893</td>\n",
       "      <td>1180555</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010346</td>\n",
       "      <td>0.009663</td>\n",
       "      <td>0.090877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044894</th>\n",
       "      <td>1044894</td>\n",
       "      <td>155574</td>\n",
       "      <td>1</td>\n",
       "      <td>0.230059</td>\n",
       "      <td>0.198934</td>\n",
       "      <td>0.832992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044895</th>\n",
       "      <td>1044895</td>\n",
       "      <td>1130815</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.045584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044896</th>\n",
       "      <td>1044896</td>\n",
       "      <td>107187</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.076284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044897</th>\n",
       "      <td>1044897</td>\n",
       "      <td>856532</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.063408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1044898 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  Unnamed: 0.1  target        V2        V3        L1\n",
       "0                 0        172360       0  0.000468  0.000433  0.027577\n",
       "1                 1        188522       0  0.000012  0.000023  0.022630\n",
       "2                 2       1235537       0  0.000025  0.000038  0.055480\n",
       "3                 3        345543       0  0.101580  0.057472  0.688056\n",
       "4                 4        566414       0  0.000258  0.000345  0.123943\n",
       "...             ...           ...     ...       ...       ...       ...\n",
       "1044893     1044893       1180555       0  0.010346  0.009663  0.090877\n",
       "1044894     1044894        155574       1  0.230059  0.198934  0.832992\n",
       "1044895     1044895       1130815       0  0.000239  0.000407  0.045584\n",
       "1044896     1044896        107187       0  0.000489  0.000237  0.076284\n",
       "1044897     1044897        856532       0  0.000066  0.000156  0.063408\n",
       "\n",
       "[1044898 rows x 6 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving prediction in a dataframe\n",
    "trainmodelsop=pd.read_csv(r'D:\\DS\\NLP\\quora-insincere-questions-classification\\trainmodeloutputs.csv')\n",
    "trainmodelsop['L1']=logit1.predict_proba(finaltrain)[:,1]\n",
    "trainmodelsop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T10:45:05.694306Z",
     "start_time": "2020-04-09T10:44:59.773816Z"
    }
   },
   "outputs": [],
   "source": [
    "trainmodelsop.to_csv(r'D:\\DS\\NLP\\quora-insincere-questions-classification\\trainmodeloutputs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T10:45:23.330775Z",
     "start_time": "2020-04-09T10:45:22.721511Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>target</th>\n",
       "      <th>V1</th>\n",
       "      <th>V3</th>\n",
       "      <th>L1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024300</td>\n",
       "      <td>0.022419</td>\n",
       "      <td>0.507896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.003438</td>\n",
       "      <td>0.120155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.068159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.034296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0.096897</td>\n",
       "      <td>0.107733</td>\n",
       "      <td>0.325269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261219</th>\n",
       "      <td>261219</td>\n",
       "      <td>1306100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.034349</td>\n",
       "      <td>0.062328</td>\n",
       "      <td>0.392208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261220</th>\n",
       "      <td>261220</td>\n",
       "      <td>1306101</td>\n",
       "      <td>0</td>\n",
       "      <td>0.371634</td>\n",
       "      <td>0.523747</td>\n",
       "      <td>0.762480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261221</th>\n",
       "      <td>261221</td>\n",
       "      <td>1306110</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004838</td>\n",
       "      <td>0.008398</td>\n",
       "      <td>0.139296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261222</th>\n",
       "      <td>261222</td>\n",
       "      <td>1306111</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009653</td>\n",
       "      <td>0.031900</td>\n",
       "      <td>0.207141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261223</th>\n",
       "      <td>261223</td>\n",
       "      <td>1306120</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.023978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>261224 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  Unnamed: 0.1  target        V1        V3        L1\n",
       "0                0            10       0  0.024300  0.022419  0.507896\n",
       "1                1            15       0  0.000732  0.003438  0.120155\n",
       "2                2            16       0  0.000131  0.000277  0.068159\n",
       "3                3            21       0  0.000191  0.000143  0.034296\n",
       "4                4            22       1  0.096897  0.107733  0.325269\n",
       "...            ...           ...     ...       ...       ...       ...\n",
       "261219      261219       1306100       0  0.034349  0.062328  0.392208\n",
       "261220      261220       1306101       0  0.371634  0.523747  0.762480\n",
       "261221      261221       1306110       0  0.004838  0.008398  0.139296\n",
       "261222      261222       1306111       0  0.009653  0.031900  0.207141\n",
       "261223      261223       1306120       0  0.000023  0.000031  0.023978\n",
       "\n",
       "[261224 rows x 6 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testmodelsop=pd.read_csv(r'D:\\DS\\NLP\\quora-insincere-questions-classification\\testmodeloutputs.csv')\n",
    "testmodelsop['L1']=logit1.predict_proba(finaltest)[:,1]\n",
    "testmodelsop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T10:45:47.184747Z",
     "start_time": "2020-04-09T10:45:45.700520Z"
    }
   },
   "outputs": [],
   "source": [
    "testmodelsop.to_csv(r'D:\\DS\\NLP\\quora-insincere-questions-classification\\testmodeloutputs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T10:56:39.913680Z",
     "start_time": "2020-04-09T10:56:37.180141Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Words</th>\n",
       "      <th>Special Characters</th>\n",
       "      <th>Capital Words</th>\n",
       "      <th>Positive words</th>\n",
       "      <th>Negative words</th>\n",
       "      <th>Stop words</th>\n",
       "      <th>Exclamation</th>\n",
       "      <th>Question</th>\n",
       "      <th>Articles</th>\n",
       "      <th>Nouns</th>\n",
       "      <th>Verbs</th>\n",
       "      <th>Adjectives</th>\n",
       "      <th>Pronouns</th>\n",
       "      <th>Question Words</th>\n",
       "      <th>Adverbs</th>\n",
       "      <th>Positive score</th>\n",
       "      <th>Negative score</th>\n",
       "      <th>Neutral score</th>\n",
       "      <th>Final score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Length  Words  Special Characters  Capital Words  Positive words  \\\n",
       "0      52     10                   1              2               0   \n",
       "1      54     11                   1              1               0   \n",
       "2      24      5                   1              2               0   \n",
       "3      55      8                   1              2               0   \n",
       "4      61     10                   3              3               0   \n",
       "\n",
       "   Negative words  Stop words  Exclamation  Question  Articles  Nouns  Verbs  \\\n",
       "0               0           4            0         1         1      4      1   \n",
       "1               0           6            0         1         2      4      1   \n",
       "2               0           1            0         1         0      2      1   \n",
       "3               0           2            0         1         0      4      1   \n",
       "4               0           3            0         1         0      3      3   \n",
       "\n",
       "   Adjectives  Pronouns  Question Words  Adverbs  Positive score  \\\n",
       "0           1         0               0        0             0.0   \n",
       "1           0         0               0        0             0.0   \n",
       "2           0         0               1        0             0.0   \n",
       "3           1         0               0        0             0.0   \n",
       "4           2         0               1        0             0.0   \n",
       "\n",
       "   Negative score  Neutral score  Final score  \n",
       "0             0.0            1.0          0.0  \n",
       "1             0.0            1.0          0.0  \n",
       "2             0.0            1.0          0.0  \n",
       "3             0.0            1.0          0.0  \n",
       "4             0.0            1.0          0.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading basic feature file for GBM\n",
    "features=pd.read_csv('D:/DS/NLP/quora-insincere-questions-classification/feature.csv')\n",
    "features.drop(['Unnamed: 0','question_text','target'],axis=1,inplace=True)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T10:56:40.710399Z",
     "start_time": "2020-04-09T10:56:39.913680Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Words</th>\n",
       "      <th>Special Characters</th>\n",
       "      <th>Capital Words</th>\n",
       "      <th>Positive words</th>\n",
       "      <th>Negative words</th>\n",
       "      <th>Stop words</th>\n",
       "      <th>Exclamation</th>\n",
       "      <th>Question</th>\n",
       "      <th>Articles</th>\n",
       "      <th>Nouns</th>\n",
       "      <th>Verbs</th>\n",
       "      <th>Adjectives</th>\n",
       "      <th>Pronouns</th>\n",
       "      <th>Question Words</th>\n",
       "      <th>Adverbs</th>\n",
       "      <th>Positive score</th>\n",
       "      <th>Negative score</th>\n",
       "      <th>Neutral score</th>\n",
       "      <th>Final score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.1027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.4215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Length  Words  Special Characters  Capital Words  Positive words  \\\n",
       "0      32      6                   1              1               0   \n",
       "1      58     11                   1              5               0   \n",
       "2      71     15                   1              1               0   \n",
       "3      86     17                   1              1               0   \n",
       "4      67     11                   1              3               0   \n",
       "\n",
       "   Negative words  Stop words  Exclamation  Question  Articles  Nouns  Verbs  \\\n",
       "0               0           3            0         1         0      1      1   \n",
       "1               0           5            0         1         1      4      2   \n",
       "2               0           6            0         1         2      3      3   \n",
       "3               0           8            0         1         2      3      2   \n",
       "4               0           4            0         1         3      4      2   \n",
       "\n",
       "   Adjectives  Pronouns  Question Words  Adverbs  Positive score  \\\n",
       "0           0         1               0        0           0.000   \n",
       "1           0         1               0        0           0.000   \n",
       "2           2         1               1        0           0.177   \n",
       "3           3         3               1        0           0.000   \n",
       "4           1         0               0        0           0.219   \n",
       "\n",
       "   Negative score  Neutral score  Final score  \n",
       "0           0.000          1.000       0.0000  \n",
       "1           0.000          1.000       0.0000  \n",
       "2           0.152          0.671       0.1027  \n",
       "3           0.000          1.000       0.0000  \n",
       "4           0.000          0.781       0.4215  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading basic feature file for GBM\n",
    "testfeatures=pd.read_csv('D:/DS/NLP/quora-insincere-questions-classification/testfeature.csv')\n",
    "testfeatures.drop(['Unnamed: 0','question_text','target'],axis=1,inplace=True)\n",
    "testfeatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T10:56:40.725990Z",
     "start_time": "2020-04-09T10:56:40.710399Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize tfidf\n",
    "tfidf=TfidfVectorizer(ngram_range=(1,3),analyzer='word',min_df=1,max_df=0.99,strip_accents='unicode',\n",
    "                                 sublinear_tf=True,dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T10:57:45.334773Z",
     "start_time": "2020-04-09T10:56:40.725990Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=0.99, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 3), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents='unicode',\n",
       "                sublinear_tf=True, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feed all words\n",
    "vocab=list(trainwu['question_text'].values)+list(testwu['question_text'].values)\n",
    "tfidf.fit(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T10:58:17.905411Z",
     "start_time": "2020-04-09T10:57:45.334773Z"
    }
   },
   "outputs": [],
   "source": [
    "# Transforming the training and test files to tfidf values\n",
    "xtrain=tfidf.transform(list(trainwu['question_text'].values))\n",
    "xtest=tfidf.transform(list(testwu['question_text'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T10:58:19.451755Z",
     "start_time": "2020-04-09T10:58:17.905411Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1044898, 8533797)\n"
     ]
    }
   ],
   "source": [
    "# Concatenating feature columns\n",
    "gbmtrain=sp.sparse.hstack((xtrain, features))\n",
    "gbmtest=sp.sparse.hstack((xtest,testfeatures))\n",
    "print(gbmtrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T12:25:12.889078Z",
     "start_time": "2020-04-09T12:25:12.857833Z"
    }
   },
   "outputs": [],
   "source": [
    "# Light GBM Parameters\n",
    "param = {\"objective\": \"binary\",'metric': {'auc'},\"num_threads\": -1,\"bagging_fraction\": 0.8,\n",
    "         \"feature_fraction\": 0.8,\"is_unbalance\":True,\"learning_rate\": 0.07,\"num_leaves\": 25,\"min_split_gain\":.05,\n",
    "         \"reg_lambda\": 0.3,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T12:25:17.684915Z",
     "start_time": "2020-04-09T12:25:13.263959Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating light gbm dataset\n",
    "data=lgb.Dataset(gbmtrain,label=trainwu['target'])\n",
    "vdata=lgb.Dataset(gbmtest,label=testwu['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T12:46:47.916820Z",
     "start_time": "2020-04-09T12:25:17.684915Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\ttraining's auc: 0.915068\tvalid_1's auc: 0.913839\n",
      "[200]\ttraining's auc: 0.929828\tvalid_1's auc: 0.927839\n",
      "[300]\ttraining's auc: 0.937237\tvalid_1's auc: 0.934317\n",
      "[400]\ttraining's auc: 0.942108\tvalid_1's auc: 0.938184\n",
      "[500]\ttraining's auc: 0.945754\tvalid_1's auc: 0.940761\n",
      "[600]\ttraining's auc: 0.948669\tvalid_1's auc: 0.942639\n",
      "[700]\ttraining's auc: 0.95112\tvalid_1's auc: 0.944139\n",
      "[800]\ttraining's auc: 0.95329\tvalid_1's auc: 0.945331\n",
      "[900]\ttraining's auc: 0.955163\tvalid_1's auc: 0.946274\n",
      "[1000]\ttraining's auc: 0.95686\tvalid_1's auc: 0.947021\n",
      "[1100]\ttraining's auc: 0.958413\tvalid_1's auc: 0.947704\n",
      "[1200]\ttraining's auc: 0.959788\tvalid_1's auc: 0.948296\n",
      "[1300]\ttraining's auc: 0.961057\tvalid_1's auc: 0.948795\n",
      "[1400]\ttraining's auc: 0.962188\tvalid_1's auc: 0.949201\n",
      "[1500]\ttraining's auc: 0.96324\tvalid_1's auc: 0.949555\n",
      "[1600]\ttraining's auc: 0.964258\tvalid_1's auc: 0.949909\n",
      "[1700]\ttraining's auc: 0.965195\tvalid_1's auc: 0.950186\n",
      "[1800]\ttraining's auc: 0.96607\tvalid_1's auc: 0.950438\n",
      "[1900]\ttraining's auc: 0.966914\tvalid_1's auc: 0.950646\n",
      "[2000]\ttraining's auc: 0.967711\tvalid_1's auc: 0.950809\n",
      "[2100]\ttraining's auc: 0.968427\tvalid_1's auc: 0.950975\n",
      "[2200]\ttraining's auc: 0.96916\tvalid_1's auc: 0.951157\n",
      "[2300]\ttraining's auc: 0.969846\tvalid_1's auc: 0.951272\n",
      "[2400]\ttraining's auc: 0.970475\tvalid_1's auc: 0.951389\n",
      "[2500]\ttraining's auc: 0.971074\tvalid_1's auc: 0.951529\n",
      "[2600]\ttraining's auc: 0.971644\tvalid_1's auc: 0.951583\n",
      "[2700]\ttraining's auc: 0.972201\tvalid_1's auc: 0.951664\n",
      "[2800]\ttraining's auc: 0.972742\tvalid_1's auc: 0.951772\n",
      "[2900]\ttraining's auc: 0.973271\tvalid_1's auc: 0.951858\n",
      "[3000]\ttraining's auc: 0.973776\tvalid_1's auc: 0.951902\n",
      "[3100]\ttraining's auc: 0.974251\tvalid_1's auc: 0.951952\n",
      "[3200]\ttraining's auc: 0.97471\tvalid_1's auc: 0.952028\n",
      "[3300]\ttraining's auc: 0.975165\tvalid_1's auc: 0.952079\n",
      "[3400]\ttraining's auc: 0.975588\tvalid_1's auc: 0.952154\n",
      "[3500]\ttraining's auc: 0.976011\tvalid_1's auc: 0.952183\n",
      "[3600]\ttraining's auc: 0.976418\tvalid_1's auc: 0.95225\n",
      "[3700]\ttraining's auc: 0.976793\tvalid_1's auc: 0.95226\n",
      "[3800]\ttraining's auc: 0.977187\tvalid_1's auc: 0.952247\n",
      "[3900]\ttraining's auc: 0.977569\tvalid_1's auc: 0.952216\n",
      "Early stopping, best iteration is:\n",
      "[3708]\ttraining's auc: 0.976825\tvalid_1's auc: 0.952266\n"
     ]
    }
   ],
   "source": [
    "# Light GBM training\n",
    "clf = lgb.train(param,data,15000,valid_sets = [data,vdata], verbose_eval=100, early_stopping_rounds = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T12:50:53.772620Z",
     "start_time": "2020-04-09T12:47:28.017676Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py:546: UserWarning: Converting data to scipy sparse matrix.\n",
      "  warnings.warn('Converting data to scipy sparse matrix.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum Train F1 score: 0.688\n",
      "Optimum Test F1 score: 0.615\n"
     ]
    }
   ],
   "source": [
    "# Prediction and optimum f1 score\n",
    "pred=clf.predict(gbmtrain,num_iteration=clf.best_iteration)\n",
    "search_result = threshold_search(train['target'], pred)\n",
    "print('Optimum Train F1 score:',round(search_result['f1'],3))\n",
    "pred=clf.predict(gbmtest,num_iteration=clf.best_iteration)\n",
    "search_result = threshold_search(test['target'], pred)\n",
    "print('Optimum Test F1 score:',round(search_result['f1'],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T12:53:20.584895Z",
     "start_time": "2020-04-09T12:51:04.473240Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>target</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>L1</th>\n",
       "      <th>GBM1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172360</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.027577</td>\n",
       "      <td>0.007062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>188522</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.022630</td>\n",
       "      <td>0.006376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1235537</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.055480</td>\n",
       "      <td>0.073269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>345543</td>\n",
       "      <td>0</td>\n",
       "      <td>0.101580</td>\n",
       "      <td>0.057472</td>\n",
       "      <td>0.688056</td>\n",
       "      <td>0.789218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>566414</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.123943</td>\n",
       "      <td>0.066225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044893</th>\n",
       "      <td>1044893</td>\n",
       "      <td>1044893</td>\n",
       "      <td>1180555</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010346</td>\n",
       "      <td>0.009663</td>\n",
       "      <td>0.090877</td>\n",
       "      <td>0.061587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044894</th>\n",
       "      <td>1044894</td>\n",
       "      <td>1044894</td>\n",
       "      <td>155574</td>\n",
       "      <td>1</td>\n",
       "      <td>0.230059</td>\n",
       "      <td>0.198934</td>\n",
       "      <td>0.832992</td>\n",
       "      <td>0.862744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044895</th>\n",
       "      <td>1044895</td>\n",
       "      <td>1044895</td>\n",
       "      <td>1130815</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.045584</td>\n",
       "      <td>0.058104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044896</th>\n",
       "      <td>1044896</td>\n",
       "      <td>1044896</td>\n",
       "      <td>107187</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.076284</td>\n",
       "      <td>0.073334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044897</th>\n",
       "      <td>1044897</td>\n",
       "      <td>1044897</td>\n",
       "      <td>856532</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.063408</td>\n",
       "      <td>0.025247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1044898 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  target        V2        V3  \\\n",
       "0                 0             0          172360       0  0.000468  0.000433   \n",
       "1                 1             1          188522       0  0.000012  0.000023   \n",
       "2                 2             2         1235537       0  0.000025  0.000038   \n",
       "3                 3             3          345543       0  0.101580  0.057472   \n",
       "4                 4             4          566414       0  0.000258  0.000345   \n",
       "...             ...           ...             ...     ...       ...       ...   \n",
       "1044893     1044893       1044893         1180555       0  0.010346  0.009663   \n",
       "1044894     1044894       1044894          155574       1  0.230059  0.198934   \n",
       "1044895     1044895       1044895         1130815       0  0.000239  0.000407   \n",
       "1044896     1044896       1044896          107187       0  0.000489  0.000237   \n",
       "1044897     1044897       1044897          856532       0  0.000066  0.000156   \n",
       "\n",
       "               L1      GBM1  \n",
       "0        0.027577  0.007062  \n",
       "1        0.022630  0.006376  \n",
       "2        0.055480  0.073269  \n",
       "3        0.688056  0.789218  \n",
       "4        0.123943  0.066225  \n",
       "...           ...       ...  \n",
       "1044893  0.090877  0.061587  \n",
       "1044894  0.832992  0.862744  \n",
       "1044895  0.045584  0.058104  \n",
       "1044896  0.076284  0.073334  \n",
       "1044897  0.063408  0.025247  \n",
       "\n",
       "[1044898 rows x 8 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving prediction for ensembling at end\n",
    "trainmodelsop=pd.read_csv(r'D:\\DS\\NLP\\quora-insincere-questions-classification\\trainmodeloutputs.csv')\n",
    "trainmodelsop['GBM1']=clf.predict(gbmtrain,num_iteration=clf.best_iteration)\n",
    "trainmodelsop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T12:53:45.391570Z",
     "start_time": "2020-04-09T12:53:36.487410Z"
    }
   },
   "outputs": [],
   "source": [
    "trainmodelsop.to_csv(r'D:\\DS\\NLP\\quora-insincere-questions-classification\\trainmodeloutputs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T12:54:26.959891Z",
     "start_time": "2020-04-09T12:53:52.936668Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py:546: UserWarning: Converting data to scipy sparse matrix.\n",
      "  warnings.warn('Converting data to scipy sparse matrix.')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>target</th>\n",
       "      <th>V1</th>\n",
       "      <th>V3</th>\n",
       "      <th>L1</th>\n",
       "      <th>GBM1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024300</td>\n",
       "      <td>0.022419</td>\n",
       "      <td>0.507896</td>\n",
       "      <td>0.302853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.003438</td>\n",
       "      <td>0.120155</td>\n",
       "      <td>0.117613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.068159</td>\n",
       "      <td>0.045665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.034296</td>\n",
       "      <td>0.016712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0.096897</td>\n",
       "      <td>0.107733</td>\n",
       "      <td>0.325269</td>\n",
       "      <td>0.217999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261219</th>\n",
       "      <td>261219</td>\n",
       "      <td>261219</td>\n",
       "      <td>1306100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.034349</td>\n",
       "      <td>0.062328</td>\n",
       "      <td>0.392208</td>\n",
       "      <td>0.501407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261220</th>\n",
       "      <td>261220</td>\n",
       "      <td>261220</td>\n",
       "      <td>1306101</td>\n",
       "      <td>0</td>\n",
       "      <td>0.371634</td>\n",
       "      <td>0.523747</td>\n",
       "      <td>0.762480</td>\n",
       "      <td>0.874843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261221</th>\n",
       "      <td>261221</td>\n",
       "      <td>261221</td>\n",
       "      <td>1306110</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004838</td>\n",
       "      <td>0.008398</td>\n",
       "      <td>0.139296</td>\n",
       "      <td>0.060111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261222</th>\n",
       "      <td>261222</td>\n",
       "      <td>261222</td>\n",
       "      <td>1306111</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009653</td>\n",
       "      <td>0.031900</td>\n",
       "      <td>0.207141</td>\n",
       "      <td>0.084060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261223</th>\n",
       "      <td>261223</td>\n",
       "      <td>261223</td>\n",
       "      <td>1306120</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.023978</td>\n",
       "      <td>0.013343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>261224 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  target        V1        V3  \\\n",
       "0                0             0              10       0  0.024300  0.022419   \n",
       "1                1             1              15       0  0.000732  0.003438   \n",
       "2                2             2              16       0  0.000131  0.000277   \n",
       "3                3             3              21       0  0.000191  0.000143   \n",
       "4                4             4              22       1  0.096897  0.107733   \n",
       "...            ...           ...             ...     ...       ...       ...   \n",
       "261219      261219        261219         1306100       0  0.034349  0.062328   \n",
       "261220      261220        261220         1306101       0  0.371634  0.523747   \n",
       "261221      261221        261221         1306110       0  0.004838  0.008398   \n",
       "261222      261222        261222         1306111       0  0.009653  0.031900   \n",
       "261223      261223        261223         1306120       0  0.000023  0.000031   \n",
       "\n",
       "              L1      GBM1  \n",
       "0       0.507896  0.302853  \n",
       "1       0.120155  0.117613  \n",
       "2       0.068159  0.045665  \n",
       "3       0.034296  0.016712  \n",
       "4       0.325269  0.217999  \n",
       "...          ...       ...  \n",
       "261219  0.392208  0.501407  \n",
       "261220  0.762480  0.874843  \n",
       "261221  0.139296  0.060111  \n",
       "261222  0.207141  0.084060  \n",
       "261223  0.023978  0.013343  \n",
       "\n",
       "[261224 rows x 8 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving prediction for ensembling at end\n",
    "testmodelsop=pd.read_csv(r'D:\\DS\\NLP\\quora-insincere-questions-classification\\testmodeloutputs.csv')\n",
    "testmodelsop['GBM1']=clf.predict(gbmtest,num_iteration=clf.best_iteration)\n",
    "testmodelsop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T12:55:04.326366Z",
     "start_time": "2020-04-09T12:55:02.076636Z"
    }
   },
   "outputs": [],
   "source": [
    "testmodelsop.to_csv(r'D:\\DS\\NLP\\quora-insincere-questions-classification\\testmodeloutputs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T12:55:14.526834Z",
     "start_time": "2020-04-09T12:55:14.386290Z"
    }
   },
   "outputs": [],
   "source": [
    "trainwu=train.copy()\n",
    "testwu=test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T12:58:15.155463Z",
     "start_time": "2020-04-09T12:55:14.542456Z"
    }
   },
   "outputs": [],
   "source": [
    "trainwu[\"question_text\"] = trainwu[\"question_text\"].apply(lambda x:clean_sentence(x))\n",
    "testwu[\"question_text\"] = testwu[\"question_text\"].apply(lambda x:clean_sentence(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T12:58:15.170869Z",
     "start_time": "2020-04-09T12:58:15.155463Z"
    }
   },
   "outputs": [],
   "source": [
    "# Count vectorizer initiation\n",
    "cv=CountVectorizer(ngram_range=(1,3),analyzer='word',min_df=1,max_df=0.999,strip_accents='unicode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T12:59:12.687532Z",
     "start_time": "2020-04-09T12:58:15.170869Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=0.999, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 3), preprocessor=None, stop_words=None,\n",
       "                strip_accents='unicode', token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feeding all words to count vectorizer\n",
    "vocab=list(trainwu['question_text'].values)+list(testwu['question_text'].values)\n",
    "cv.fit(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T12:59:37.492414Z",
     "start_time": "2020-04-09T12:59:12.687532Z"
    }
   },
   "outputs": [],
   "source": [
    "# Transforming our text using cv\n",
    "xtrain=cv.transform(list(trainwu['question_text'].values))\n",
    "xtest=cv.transform(list(testwu['question_text'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T13:00:40.626012Z",
     "start_time": "2020-04-09T13:00:39.157619Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1044898, 8533794)\n"
     ]
    }
   ],
   "source": [
    "# Concatenating WOE files\n",
    "finaltrain = sp.sparse.hstack((xtrain, woetr))\n",
    "finaltest=sp.sparse.hstack((xtest,woete))\n",
    "print(finaltrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T13:03:00.579956Z",
     "start_time": "2020-04-09T13:00:52.107701Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 77 epochs took 127 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.07, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=200, multi_class='auto', n_jobs=-1, penalty='l2',\n",
       "                   random_state=None, solver='saga', tol=0.0008, verbose=1,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logistic regression training\n",
    "logit2=LogisticRegression(n_jobs=-1,solver='saga',max_iter=200,verbose=1,class_weight='balanced',penalty='l2',C=0.07,tol=0.0008)\n",
    "logit2.fit(finaltrain,trainwu['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T13:03:18.403859Z",
     "start_time": "2020-04-09T13:03:09.734422Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training F1 score: 0.684838642878162\n",
      "Testing F1 score: 0.5749469402193138\n",
      "Optimum Test F1 score: 0.609\n"
     ]
    }
   ],
   "source": [
    "# Prediction and optimum f1 score\n",
    "pred=logit2.predict(finaltrain)\n",
    "print('Training F1 score:',metrics.f1_score(trainwu['target'],pred))\n",
    "pred=logit2.predict(finaltest)\n",
    "print('Testing F1 score:',metrics.f1_score(testwu['target'],pred))\n",
    "pred=logit2.predict_proba(finaltest)\n",
    "pred=pred[:,1]\n",
    "search_result = threshold_search(testwu['target'], pred)\n",
    "print('Optimum Test F1 score:',round(search_result['f1'],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T13:03:35.946611Z",
     "start_time": "2020-04-09T13:03:34.572006Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1</th>\n",
       "      <th>target</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>L1</th>\n",
       "      <th>GBM1</th>\n",
       "      <th>L2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172360</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.027577</td>\n",
       "      <td>0.007062</td>\n",
       "      <td>0.023413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>188522</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.022630</td>\n",
       "      <td>0.006376</td>\n",
       "      <td>0.015940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1235537</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.055480</td>\n",
       "      <td>0.073269</td>\n",
       "      <td>0.087146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>345543</td>\n",
       "      <td>0</td>\n",
       "      <td>0.101580</td>\n",
       "      <td>0.057472</td>\n",
       "      <td>0.688056</td>\n",
       "      <td>0.789218</td>\n",
       "      <td>0.618124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>566414</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.123943</td>\n",
       "      <td>0.066225</td>\n",
       "      <td>0.050635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044893</th>\n",
       "      <td>1044893</td>\n",
       "      <td>1044893</td>\n",
       "      <td>1044893</td>\n",
       "      <td>1180555</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010346</td>\n",
       "      <td>0.009663</td>\n",
       "      <td>0.090877</td>\n",
       "      <td>0.061587</td>\n",
       "      <td>0.102847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044894</th>\n",
       "      <td>1044894</td>\n",
       "      <td>1044894</td>\n",
       "      <td>1044894</td>\n",
       "      <td>155574</td>\n",
       "      <td>1</td>\n",
       "      <td>0.230059</td>\n",
       "      <td>0.198934</td>\n",
       "      <td>0.832992</td>\n",
       "      <td>0.862744</td>\n",
       "      <td>0.708256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044895</th>\n",
       "      <td>1044895</td>\n",
       "      <td>1044895</td>\n",
       "      <td>1044895</td>\n",
       "      <td>1130815</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.045584</td>\n",
       "      <td>0.058104</td>\n",
       "      <td>0.003764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044896</th>\n",
       "      <td>1044896</td>\n",
       "      <td>1044896</td>\n",
       "      <td>1044896</td>\n",
       "      <td>107187</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.076284</td>\n",
       "      <td>0.073334</td>\n",
       "      <td>0.098819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044897</th>\n",
       "      <td>1044897</td>\n",
       "      <td>1044897</td>\n",
       "      <td>1044897</td>\n",
       "      <td>856532</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.063408</td>\n",
       "      <td>0.025247</td>\n",
       "      <td>0.069858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1044898 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  Unnamed: 0.1.1.1  target  \\\n",
       "0                 0             0               0            172360       0   \n",
       "1                 1             1               1            188522       0   \n",
       "2                 2             2               2           1235537       0   \n",
       "3                 3             3               3            345543       0   \n",
       "4                 4             4               4            566414       0   \n",
       "...             ...           ...             ...               ...     ...   \n",
       "1044893     1044893       1044893         1044893           1180555       0   \n",
       "1044894     1044894       1044894         1044894            155574       1   \n",
       "1044895     1044895       1044895         1044895           1130815       0   \n",
       "1044896     1044896       1044896         1044896            107187       0   \n",
       "1044897     1044897       1044897         1044897            856532       0   \n",
       "\n",
       "               V2        V3        L1      GBM1        L2  \n",
       "0        0.000468  0.000433  0.027577  0.007062  0.023413  \n",
       "1        0.000012  0.000023  0.022630  0.006376  0.015940  \n",
       "2        0.000025  0.000038  0.055480  0.073269  0.087146  \n",
       "3        0.101580  0.057472  0.688056  0.789218  0.618124  \n",
       "4        0.000258  0.000345  0.123943  0.066225  0.050635  \n",
       "...           ...       ...       ...       ...       ...  \n",
       "1044893  0.010346  0.009663  0.090877  0.061587  0.102847  \n",
       "1044894  0.230059  0.198934  0.832992  0.862744  0.708256  \n",
       "1044895  0.000239  0.000407  0.045584  0.058104  0.003764  \n",
       "1044896  0.000489  0.000237  0.076284  0.073334  0.098819  \n",
       "1044897  0.000066  0.000156  0.063408  0.025247  0.069858  \n",
       "\n",
       "[1044898 rows x 10 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving prediction for ensembling at end\n",
    "trainmodelsop=pd.read_csv(r'D:\\DS\\NLP\\quora-insincere-questions-classification\\trainmodeloutputs.csv')\n",
    "trainmodelsop['L2']=logit2.predict_proba(finaltrain)[:,1]\n",
    "trainmodelsop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T13:05:21.406292Z",
     "start_time": "2020-04-09T13:05:10.955587Z"
    }
   },
   "outputs": [],
   "source": [
    "trainmodelsop.to_csv(r'D:\\DS\\NLP\\quora-insincere-questions-classification\\trainmodeloutputs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T13:05:21.812445Z",
     "start_time": "2020-04-09T13:05:21.406292Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1</th>\n",
       "      <th>target</th>\n",
       "      <th>V1</th>\n",
       "      <th>V3</th>\n",
       "      <th>L1</th>\n",
       "      <th>GBM1</th>\n",
       "      <th>L2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024300</td>\n",
       "      <td>0.022419</td>\n",
       "      <td>0.507896</td>\n",
       "      <td>0.302853</td>\n",
       "      <td>0.301129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.003438</td>\n",
       "      <td>0.120155</td>\n",
       "      <td>0.117613</td>\n",
       "      <td>0.111000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.068159</td>\n",
       "      <td>0.045665</td>\n",
       "      <td>0.042989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.034296</td>\n",
       "      <td>0.016712</td>\n",
       "      <td>0.023646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0.096897</td>\n",
       "      <td>0.107733</td>\n",
       "      <td>0.325269</td>\n",
       "      <td>0.217999</td>\n",
       "      <td>0.310578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261219</th>\n",
       "      <td>261219</td>\n",
       "      <td>261219</td>\n",
       "      <td>261219</td>\n",
       "      <td>1306100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.034349</td>\n",
       "      <td>0.062328</td>\n",
       "      <td>0.392208</td>\n",
       "      <td>0.501407</td>\n",
       "      <td>0.384330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261220</th>\n",
       "      <td>261220</td>\n",
       "      <td>261220</td>\n",
       "      <td>261220</td>\n",
       "      <td>1306101</td>\n",
       "      <td>0</td>\n",
       "      <td>0.371634</td>\n",
       "      <td>0.523747</td>\n",
       "      <td>0.762480</td>\n",
       "      <td>0.874843</td>\n",
       "      <td>0.703858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261221</th>\n",
       "      <td>261221</td>\n",
       "      <td>261221</td>\n",
       "      <td>261221</td>\n",
       "      <td>1306110</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004838</td>\n",
       "      <td>0.008398</td>\n",
       "      <td>0.139296</td>\n",
       "      <td>0.060111</td>\n",
       "      <td>0.064519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261222</th>\n",
       "      <td>261222</td>\n",
       "      <td>261222</td>\n",
       "      <td>261222</td>\n",
       "      <td>1306111</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009653</td>\n",
       "      <td>0.031900</td>\n",
       "      <td>0.207141</td>\n",
       "      <td>0.084060</td>\n",
       "      <td>0.030491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261223</th>\n",
       "      <td>261223</td>\n",
       "      <td>261223</td>\n",
       "      <td>261223</td>\n",
       "      <td>1306120</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.023978</td>\n",
       "      <td>0.013343</td>\n",
       "      <td>0.010014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>261224 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  Unnamed: 0.1.1.1  target  \\\n",
       "0                0             0               0                10       0   \n",
       "1                1             1               1                15       0   \n",
       "2                2             2               2                16       0   \n",
       "3                3             3               3                21       0   \n",
       "4                4             4               4                22       1   \n",
       "...            ...           ...             ...               ...     ...   \n",
       "261219      261219        261219          261219           1306100       0   \n",
       "261220      261220        261220          261220           1306101       0   \n",
       "261221      261221        261221          261221           1306110       0   \n",
       "261222      261222        261222          261222           1306111       0   \n",
       "261223      261223        261223          261223           1306120       0   \n",
       "\n",
       "              V1        V3        L1      GBM1        L2  \n",
       "0       0.024300  0.022419  0.507896  0.302853  0.301129  \n",
       "1       0.000732  0.003438  0.120155  0.117613  0.111000  \n",
       "2       0.000131  0.000277  0.068159  0.045665  0.042989  \n",
       "3       0.000191  0.000143  0.034296  0.016712  0.023646  \n",
       "4       0.096897  0.107733  0.325269  0.217999  0.310578  \n",
       "...          ...       ...       ...       ...       ...  \n",
       "261219  0.034349  0.062328  0.392208  0.501407  0.384330  \n",
       "261220  0.371634  0.523747  0.762480  0.874843  0.703858  \n",
       "261221  0.004838  0.008398  0.139296  0.060111  0.064519  \n",
       "261222  0.009653  0.031900  0.207141  0.084060  0.030491  \n",
       "261223  0.000023  0.000031  0.023978  0.013343  0.010014  \n",
       "\n",
       "[261224 rows x 10 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving prediction for ensembling at end\n",
    "testmodelsop=pd.read_csv(r'D:\\DS\\NLP\\quora-insincere-questions-classification\\testmodeloutputs.csv')\n",
    "testmodelsop['L2']=logit2.predict_proba(finaltest)[:,1]\n",
    "testmodelsop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T13:05:38.652239Z",
     "start_time": "2020-04-09T13:05:36.168411Z"
    }
   },
   "outputs": [],
   "source": [
    "testmodelsop.to_csv(r'D:\\DS\\NLP\\quora-insincere-questions-classification\\testmodeloutputs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T13:05:52.102224Z",
     "start_time": "2020-04-09T13:05:49.649653Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Words</th>\n",
       "      <th>Special Characters</th>\n",
       "      <th>Capital Words</th>\n",
       "      <th>Positive words</th>\n",
       "      <th>Negative words</th>\n",
       "      <th>Stop words</th>\n",
       "      <th>Exclamation</th>\n",
       "      <th>Question</th>\n",
       "      <th>Articles</th>\n",
       "      <th>Nouns</th>\n",
       "      <th>Verbs</th>\n",
       "      <th>Adjectives</th>\n",
       "      <th>Pronouns</th>\n",
       "      <th>Question Words</th>\n",
       "      <th>Adverbs</th>\n",
       "      <th>Positive score</th>\n",
       "      <th>Negative score</th>\n",
       "      <th>Neutral score</th>\n",
       "      <th>Final score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Length  Words  Special Characters  Capital Words  Positive words  \\\n",
       "0      52     10                   1              2               0   \n",
       "1      54     11                   1              1               0   \n",
       "2      24      5                   1              2               0   \n",
       "3      55      8                   1              2               0   \n",
       "4      61     10                   3              3               0   \n",
       "\n",
       "   Negative words  Stop words  Exclamation  Question  Articles  Nouns  Verbs  \\\n",
       "0               0           4            0         1         1      4      1   \n",
       "1               0           6            0         1         2      4      1   \n",
       "2               0           1            0         1         0      2      1   \n",
       "3               0           2            0         1         0      4      1   \n",
       "4               0           3            0         1         0      3      3   \n",
       "\n",
       "   Adjectives  Pronouns  Question Words  Adverbs  Positive score  \\\n",
       "0           1         0               0        0             0.0   \n",
       "1           0         0               0        0             0.0   \n",
       "2           0         0               1        0             0.0   \n",
       "3           1         0               0        0             0.0   \n",
       "4           2         0               1        0             0.0   \n",
       "\n",
       "   Negative score  Neutral score  Final score  \n",
       "0             0.0            1.0          0.0  \n",
       "1             0.0            1.0          0.0  \n",
       "2             0.0            1.0          0.0  \n",
       "3             0.0            1.0          0.0  \n",
       "4             0.0            1.0          0.0  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading basic feature file for GBM\n",
    "features=pd.read_csv('D:/DS/NLP/quora-insincere-questions-classification/feature.csv')\n",
    "features.drop(['Unnamed: 0','question_text','target'],axis=1,inplace=True)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T13:05:52.805126Z",
     "start_time": "2020-04-09T13:05:52.102224Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Words</th>\n",
       "      <th>Special Characters</th>\n",
       "      <th>Capital Words</th>\n",
       "      <th>Positive words</th>\n",
       "      <th>Negative words</th>\n",
       "      <th>Stop words</th>\n",
       "      <th>Exclamation</th>\n",
       "      <th>Question</th>\n",
       "      <th>Articles</th>\n",
       "      <th>Nouns</th>\n",
       "      <th>Verbs</th>\n",
       "      <th>Adjectives</th>\n",
       "      <th>Pronouns</th>\n",
       "      <th>Question Words</th>\n",
       "      <th>Adverbs</th>\n",
       "      <th>Positive score</th>\n",
       "      <th>Negative score</th>\n",
       "      <th>Neutral score</th>\n",
       "      <th>Final score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.1027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.4215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Length  Words  Special Characters  Capital Words  Positive words  \\\n",
       "0      32      6                   1              1               0   \n",
       "1      58     11                   1              5               0   \n",
       "2      71     15                   1              1               0   \n",
       "3      86     17                   1              1               0   \n",
       "4      67     11                   1              3               0   \n",
       "\n",
       "   Negative words  Stop words  Exclamation  Question  Articles  Nouns  Verbs  \\\n",
       "0               0           3            0         1         0      1      1   \n",
       "1               0           5            0         1         1      4      2   \n",
       "2               0           6            0         1         2      3      3   \n",
       "3               0           8            0         1         2      3      2   \n",
       "4               0           4            0         1         3      4      2   \n",
       "\n",
       "   Adjectives  Pronouns  Question Words  Adverbs  Positive score  \\\n",
       "0           0         1               0        0           0.000   \n",
       "1           0         1               0        0           0.000   \n",
       "2           2         1               1        0           0.177   \n",
       "3           3         3               1        0           0.000   \n",
       "4           1         0               0        0           0.219   \n",
       "\n",
       "   Negative score  Neutral score  Final score  \n",
       "0           0.000          1.000       0.0000  \n",
       "1           0.000          1.000       0.0000  \n",
       "2           0.152          0.671       0.1027  \n",
       "3           0.000          1.000       0.0000  \n",
       "4           0.000          0.781       0.4215  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading basic feature file for GBM\n",
    "testfeatures=pd.read_csv('D:/DS/NLP/quora-insincere-questions-classification/testfeature.csv')\n",
    "testfeatures.drop(['Unnamed: 0','question_text','target'],axis=1,inplace=True)\n",
    "testfeatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T13:06:11.191466Z",
     "start_time": "2020-04-09T13:06:11.176318Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initializing basic count vectorizer\n",
    "cv=CountVectorizer(ngram_range=(1,3),analyzer='word',min_df=1,max_df=0.95,strip_accents='unicode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T13:07:11.146150Z",
     "start_time": "2020-04-09T13:06:13.238291Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=0.95, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 3), preprocessor=None, stop_words=None,\n",
       "                strip_accents='unicode', token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feeding list of words to cv\n",
    "vocab=list(trainwu['question_text'].values)+list(testwu['question_text'].values)\n",
    "cv.fit(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T13:07:36.077992Z",
     "start_time": "2020-04-09T13:07:11.146150Z"
    }
   },
   "outputs": [],
   "source": [
    "# Transforming text using count vectorizer\n",
    "xtrain=cv.transform(list(trainwu['question_text'].values))\n",
    "xtest=cv.transform(list(testwu['question_text'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T13:07:37.593038Z",
     "start_time": "2020-04-09T13:07:36.077992Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1044898, 8533797)\n"
     ]
    }
   ],
   "source": [
    "# Concatenating the feature files\n",
    "gbmtrain=sp.sparse.hstack((xtrain, features))\n",
    "gbmtest=sp.sparse.hstack((xtest,testfeatures))\n",
    "print(gbmtrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T13:07:37.608623Z",
     "start_time": "2020-04-09T13:07:37.593038Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setting light GBM parameters\n",
    "param = {\"objective\": \"binary\",'metric': {'auc'},\"num_threads\": -1,\"bagging_fraction\": 0.8,\n",
    "         \"feature_fraction\": 0.8,\"is_unbalance\":True,\"learning_rate\": 0.05,\"num_leaves\": 35,\"min_split_gain\":.01,\n",
    "         \"reg_alpha\": 0.5,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T13:07:42.326522Z",
     "start_time": "2020-04-09T13:07:37.608623Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preparing dataset suitable for light gbm\n",
    "data=lgb.Dataset(gbmtrain,label=trainwu['target'])\n",
    "vdata=lgb.Dataset(gbmtest,label=testwu['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T13:34:06.065734Z",
     "start_time": "2020-04-09T13:07:42.326522Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\ttraining's auc: 0.913963\tvalid_1's auc: 0.912698\n",
      "[200]\ttraining's auc: 0.929204\tvalid_1's auc: 0.927577\n",
      "[300]\ttraining's auc: 0.936503\tvalid_1's auc: 0.934403\n",
      "[400]\ttraining's auc: 0.941192\tvalid_1's auc: 0.938506\n",
      "[500]\ttraining's auc: 0.944644\tvalid_1's auc: 0.941259\n",
      "[600]\ttraining's auc: 0.947344\tvalid_1's auc: 0.943249\n",
      "[700]\ttraining's auc: 0.949622\tvalid_1's auc: 0.94482\n",
      "[800]\ttraining's auc: 0.95157\tvalid_1's auc: 0.945977\n",
      "[900]\ttraining's auc: 0.953311\tvalid_1's auc: 0.94702\n",
      "[1000]\ttraining's auc: 0.954828\tvalid_1's auc: 0.947795\n",
      "[1100]\ttraining's auc: 0.956263\tvalid_1's auc: 0.948465\n",
      "[1200]\ttraining's auc: 0.957508\tvalid_1's auc: 0.949011\n",
      "[1300]\ttraining's auc: 0.958681\tvalid_1's auc: 0.949524\n",
      "[1400]\ttraining's auc: 0.959771\tvalid_1's auc: 0.949888\n",
      "[1500]\ttraining's auc: 0.960842\tvalid_1's auc: 0.950281\n",
      "[1600]\ttraining's auc: 0.961777\tvalid_1's auc: 0.950592\n",
      "[1700]\ttraining's auc: 0.962724\tvalid_1's auc: 0.950903\n",
      "[1800]\ttraining's auc: 0.96357\tvalid_1's auc: 0.951146\n",
      "[1900]\ttraining's auc: 0.964414\tvalid_1's auc: 0.951385\n",
      "[2000]\ttraining's auc: 0.965169\tvalid_1's auc: 0.95162\n",
      "[2100]\ttraining's auc: 0.965918\tvalid_1's auc: 0.951819\n",
      "[2200]\ttraining's auc: 0.966613\tvalid_1's auc: 0.951974\n",
      "[2300]\ttraining's auc: 0.967287\tvalid_1's auc: 0.952159\n",
      "[2400]\ttraining's auc: 0.967916\tvalid_1's auc: 0.952305\n",
      "[2500]\ttraining's auc: 0.96854\tvalid_1's auc: 0.952448\n",
      "[2600]\ttraining's auc: 0.969129\tvalid_1's auc: 0.952544\n",
      "[2700]\ttraining's auc: 0.969689\tvalid_1's auc: 0.952658\n",
      "[2800]\ttraining's auc: 0.970272\tvalid_1's auc: 0.952755\n",
      "[2900]\ttraining's auc: 0.970815\tvalid_1's auc: 0.952864\n",
      "[3000]\ttraining's auc: 0.971339\tvalid_1's auc: 0.952951\n",
      "[3100]\ttraining's auc: 0.971828\tvalid_1's auc: 0.953041\n",
      "[3200]\ttraining's auc: 0.972316\tvalid_1's auc: 0.953132\n",
      "[3300]\ttraining's auc: 0.972767\tvalid_1's auc: 0.953231\n",
      "[3400]\ttraining's auc: 0.973218\tvalid_1's auc: 0.953292\n",
      "[3500]\ttraining's auc: 0.973655\tvalid_1's auc: 0.953327\n",
      "[3600]\ttraining's auc: 0.974068\tvalid_1's auc: 0.953412\n",
      "[3700]\ttraining's auc: 0.974498\tvalid_1's auc: 0.95347\n",
      "[3800]\ttraining's auc: 0.974878\tvalid_1's auc: 0.95352\n",
      "[3900]\ttraining's auc: 0.975292\tvalid_1's auc: 0.953552\n",
      "[4000]\ttraining's auc: 0.975671\tvalid_1's auc: 0.953581\n",
      "[4100]\ttraining's auc: 0.976046\tvalid_1's auc: 0.953597\n",
      "[4200]\ttraining's auc: 0.97641\tvalid_1's auc: 0.953621\n",
      "[4300]\ttraining's auc: 0.976773\tvalid_1's auc: 0.953644\n",
      "[4400]\ttraining's auc: 0.97714\tvalid_1's auc: 0.953686\n",
      "[4500]\ttraining's auc: 0.977475\tvalid_1's auc: 0.953677\n",
      "[4600]\ttraining's auc: 0.977788\tvalid_1's auc: 0.953691\n",
      "[4700]\ttraining's auc: 0.978106\tvalid_1's auc: 0.953699\n",
      "[4800]\ttraining's auc: 0.978443\tvalid_1's auc: 0.953748\n",
      "[4900]\ttraining's auc: 0.97874\tvalid_1's auc: 0.953753\n",
      "[5000]\ttraining's auc: 0.979028\tvalid_1's auc: 0.953738\n",
      "Early stopping, best iteration is:\n",
      "[4849]\ttraining's auc: 0.978592\tvalid_1's auc: 0.953763\n"
     ]
    }
   ],
   "source": [
    "# Light GBM training\n",
    "clf2 = lgb.train(param,data,8000,valid_sets = [data,vdata], verbose_eval=100, early_stopping_rounds = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T13:40:01.532732Z",
     "start_time": "2020-04-09T13:35:15.283980Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py:546: UserWarning: Converting data to scipy sparse matrix.\n",
      "  warnings.warn('Converting data to scipy sparse matrix.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum Train F1 score: 0.708\n",
      "Optimum Test F1 score: 0.62\n"
     ]
    }
   ],
   "source": [
    "# Predicting and optimum f1 score\n",
    "pred=clf2.predict(gbmtrain,num_iteration=clf2.best_iteration)\n",
    "search_result = threshold_search(train['target'], pred)\n",
    "print('Optimum Train F1 score:',round(search_result['f1'],3))\n",
    "pred=clf2.predict(gbmtest,num_iteration=clf2.best_iteration)\n",
    "search_result = threshold_search(test['target'], pred)\n",
    "print('Optimum Test F1 score:',round(search_result['f1'],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T13:43:36.763628Z",
     "start_time": "2020-04-09T13:40:15.360393Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1.1</th>\n",
       "      <th>target</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>L1</th>\n",
       "      <th>GBM1</th>\n",
       "      <th>L2</th>\n",
       "      <th>GBM2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172360</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.027577</td>\n",
       "      <td>0.007062</td>\n",
       "      <td>0.023413</td>\n",
       "      <td>0.013476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>188522</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.022630</td>\n",
       "      <td>0.006376</td>\n",
       "      <td>0.015940</td>\n",
       "      <td>0.007689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1235537</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.055480</td>\n",
       "      <td>0.073269</td>\n",
       "      <td>0.087146</td>\n",
       "      <td>0.089432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>345543</td>\n",
       "      <td>0</td>\n",
       "      <td>0.101580</td>\n",
       "      <td>0.057472</td>\n",
       "      <td>0.688056</td>\n",
       "      <td>0.789218</td>\n",
       "      <td>0.618124</td>\n",
       "      <td>0.782704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>566414</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.123943</td>\n",
       "      <td>0.066225</td>\n",
       "      <td>0.050635</td>\n",
       "      <td>0.096038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044893</th>\n",
       "      <td>1044893</td>\n",
       "      <td>1044893</td>\n",
       "      <td>1044893</td>\n",
       "      <td>1044893</td>\n",
       "      <td>1180555</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010346</td>\n",
       "      <td>0.009663</td>\n",
       "      <td>0.090877</td>\n",
       "      <td>0.061587</td>\n",
       "      <td>0.102847</td>\n",
       "      <td>0.043326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044894</th>\n",
       "      <td>1044894</td>\n",
       "      <td>1044894</td>\n",
       "      <td>1044894</td>\n",
       "      <td>1044894</td>\n",
       "      <td>155574</td>\n",
       "      <td>1</td>\n",
       "      <td>0.230059</td>\n",
       "      <td>0.198934</td>\n",
       "      <td>0.832992</td>\n",
       "      <td>0.862744</td>\n",
       "      <td>0.708256</td>\n",
       "      <td>0.929677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044895</th>\n",
       "      <td>1044895</td>\n",
       "      <td>1044895</td>\n",
       "      <td>1044895</td>\n",
       "      <td>1044895</td>\n",
       "      <td>1130815</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.045584</td>\n",
       "      <td>0.058104</td>\n",
       "      <td>0.003764</td>\n",
       "      <td>0.021941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044896</th>\n",
       "      <td>1044896</td>\n",
       "      <td>1044896</td>\n",
       "      <td>1044896</td>\n",
       "      <td>1044896</td>\n",
       "      <td>107187</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.076284</td>\n",
       "      <td>0.073334</td>\n",
       "      <td>0.098819</td>\n",
       "      <td>0.109336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044897</th>\n",
       "      <td>1044897</td>\n",
       "      <td>1044897</td>\n",
       "      <td>1044897</td>\n",
       "      <td>1044897</td>\n",
       "      <td>856532</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.063408</td>\n",
       "      <td>0.025247</td>\n",
       "      <td>0.069858</td>\n",
       "      <td>0.037498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1044898 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  Unnamed: 0.1.1.1  \\\n",
       "0                 0             0               0                 0   \n",
       "1                 1             1               1                 1   \n",
       "2                 2             2               2                 2   \n",
       "3                 3             3               3                 3   \n",
       "4                 4             4               4                 4   \n",
       "...             ...           ...             ...               ...   \n",
       "1044893     1044893       1044893         1044893           1044893   \n",
       "1044894     1044894       1044894         1044894           1044894   \n",
       "1044895     1044895       1044895         1044895           1044895   \n",
       "1044896     1044896       1044896         1044896           1044896   \n",
       "1044897     1044897       1044897         1044897           1044897   \n",
       "\n",
       "         Unnamed: 0.1.1.1.1  target        V2        V3        L1      GBM1  \\\n",
       "0                    172360       0  0.000468  0.000433  0.027577  0.007062   \n",
       "1                    188522       0  0.000012  0.000023  0.022630  0.006376   \n",
       "2                   1235537       0  0.000025  0.000038  0.055480  0.073269   \n",
       "3                    345543       0  0.101580  0.057472  0.688056  0.789218   \n",
       "4                    566414       0  0.000258  0.000345  0.123943  0.066225   \n",
       "...                     ...     ...       ...       ...       ...       ...   \n",
       "1044893             1180555       0  0.010346  0.009663  0.090877  0.061587   \n",
       "1044894              155574       1  0.230059  0.198934  0.832992  0.862744   \n",
       "1044895             1130815       0  0.000239  0.000407  0.045584  0.058104   \n",
       "1044896              107187       0  0.000489  0.000237  0.076284  0.073334   \n",
       "1044897              856532       0  0.000066  0.000156  0.063408  0.025247   \n",
       "\n",
       "               L2      GBM2  \n",
       "0        0.023413  0.013476  \n",
       "1        0.015940  0.007689  \n",
       "2        0.087146  0.089432  \n",
       "3        0.618124  0.782704  \n",
       "4        0.050635  0.096038  \n",
       "...           ...       ...  \n",
       "1044893  0.102847  0.043326  \n",
       "1044894  0.708256  0.929677  \n",
       "1044895  0.003764  0.021941  \n",
       "1044896  0.098819  0.109336  \n",
       "1044897  0.069858  0.037498  \n",
       "\n",
       "[1044898 rows x 12 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving prediction for ensembling at end\n",
    "trainmodelsop=pd.read_csv(r'D:\\DS\\NLP\\quora-insincere-questions-classification\\trainmodeloutputs.csv')\n",
    "trainmodelsop['GBM2']=clf2.predict(gbmtrain,num_iteration=clf2.best_iteration)\n",
    "trainmodelsop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T13:44:05.819565Z",
     "start_time": "2020-04-09T13:43:53.525348Z"
    }
   },
   "outputs": [],
   "source": [
    "trainmodelsop.to_csv(r'D:\\DS\\NLP\\quora-insincere-questions-classification\\trainmodeloutputs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T13:44:55.229563Z",
     "start_time": "2020-04-09T13:44:05.819565Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py:546: UserWarning: Converting data to scipy sparse matrix.\n",
      "  warnings.warn('Converting data to scipy sparse matrix.')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1.1</th>\n",
       "      <th>target</th>\n",
       "      <th>V1</th>\n",
       "      <th>V3</th>\n",
       "      <th>L1</th>\n",
       "      <th>GBM1</th>\n",
       "      <th>L2</th>\n",
       "      <th>GBM2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024300</td>\n",
       "      <td>0.022419</td>\n",
       "      <td>0.507896</td>\n",
       "      <td>0.302853</td>\n",
       "      <td>0.301129</td>\n",
       "      <td>0.327991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.003438</td>\n",
       "      <td>0.120155</td>\n",
       "      <td>0.117613</td>\n",
       "      <td>0.111000</td>\n",
       "      <td>0.113504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.068159</td>\n",
       "      <td>0.045665</td>\n",
       "      <td>0.042989</td>\n",
       "      <td>0.043656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.034296</td>\n",
       "      <td>0.016712</td>\n",
       "      <td>0.023646</td>\n",
       "      <td>0.012958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0.096897</td>\n",
       "      <td>0.107733</td>\n",
       "      <td>0.325269</td>\n",
       "      <td>0.217999</td>\n",
       "      <td>0.310578</td>\n",
       "      <td>0.259091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261219</th>\n",
       "      <td>261219</td>\n",
       "      <td>261219</td>\n",
       "      <td>261219</td>\n",
       "      <td>261219</td>\n",
       "      <td>1306100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.034349</td>\n",
       "      <td>0.062328</td>\n",
       "      <td>0.392208</td>\n",
       "      <td>0.501407</td>\n",
       "      <td>0.384330</td>\n",
       "      <td>0.524310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261220</th>\n",
       "      <td>261220</td>\n",
       "      <td>261220</td>\n",
       "      <td>261220</td>\n",
       "      <td>261220</td>\n",
       "      <td>1306101</td>\n",
       "      <td>0</td>\n",
       "      <td>0.371634</td>\n",
       "      <td>0.523747</td>\n",
       "      <td>0.762480</td>\n",
       "      <td>0.874843</td>\n",
       "      <td>0.703858</td>\n",
       "      <td>0.897279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261221</th>\n",
       "      <td>261221</td>\n",
       "      <td>261221</td>\n",
       "      <td>261221</td>\n",
       "      <td>261221</td>\n",
       "      <td>1306110</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004838</td>\n",
       "      <td>0.008398</td>\n",
       "      <td>0.139296</td>\n",
       "      <td>0.060111</td>\n",
       "      <td>0.064519</td>\n",
       "      <td>0.079674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261222</th>\n",
       "      <td>261222</td>\n",
       "      <td>261222</td>\n",
       "      <td>261222</td>\n",
       "      <td>261222</td>\n",
       "      <td>1306111</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009653</td>\n",
       "      <td>0.031900</td>\n",
       "      <td>0.207141</td>\n",
       "      <td>0.084060</td>\n",
       "      <td>0.030491</td>\n",
       "      <td>0.161251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261223</th>\n",
       "      <td>261223</td>\n",
       "      <td>261223</td>\n",
       "      <td>261223</td>\n",
       "      <td>261223</td>\n",
       "      <td>1306120</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.023978</td>\n",
       "      <td>0.013343</td>\n",
       "      <td>0.010014</td>\n",
       "      <td>0.010956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>261224 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  Unnamed: 0.1.1.1  \\\n",
       "0                0             0               0                 0   \n",
       "1                1             1               1                 1   \n",
       "2                2             2               2                 2   \n",
       "3                3             3               3                 3   \n",
       "4                4             4               4                 4   \n",
       "...            ...           ...             ...               ...   \n",
       "261219      261219        261219          261219            261219   \n",
       "261220      261220        261220          261220            261220   \n",
       "261221      261221        261221          261221            261221   \n",
       "261222      261222        261222          261222            261222   \n",
       "261223      261223        261223          261223            261223   \n",
       "\n",
       "        Unnamed: 0.1.1.1.1  target        V1        V3        L1      GBM1  \\\n",
       "0                       10       0  0.024300  0.022419  0.507896  0.302853   \n",
       "1                       15       0  0.000732  0.003438  0.120155  0.117613   \n",
       "2                       16       0  0.000131  0.000277  0.068159  0.045665   \n",
       "3                       21       0  0.000191  0.000143  0.034296  0.016712   \n",
       "4                       22       1  0.096897  0.107733  0.325269  0.217999   \n",
       "...                    ...     ...       ...       ...       ...       ...   \n",
       "261219             1306100       0  0.034349  0.062328  0.392208  0.501407   \n",
       "261220             1306101       0  0.371634  0.523747  0.762480  0.874843   \n",
       "261221             1306110       0  0.004838  0.008398  0.139296  0.060111   \n",
       "261222             1306111       0  0.009653  0.031900  0.207141  0.084060   \n",
       "261223             1306120       0  0.000023  0.000031  0.023978  0.013343   \n",
       "\n",
       "              L2      GBM2  \n",
       "0       0.301129  0.327991  \n",
       "1       0.111000  0.113504  \n",
       "2       0.042989  0.043656  \n",
       "3       0.023646  0.012958  \n",
       "4       0.310578  0.259091  \n",
       "...          ...       ...  \n",
       "261219  0.384330  0.524310  \n",
       "261220  0.703858  0.897279  \n",
       "261221  0.064519  0.079674  \n",
       "261222  0.030491  0.161251  \n",
       "261223  0.010014  0.010956  \n",
       "\n",
       "[261224 rows x 12 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving prediction for ensembling at end\n",
    "testmodelsop=pd.read_csv(r'D:\\DS\\NLP\\quora-insincere-questions-classification\\testmodeloutputs.csv')\n",
    "testmodelsop['GBM2']=clf2.predict(gbmtest,num_iteration=clf2.best_iteration)\n",
    "testmodelsop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T13:45:13.459689Z",
     "start_time": "2020-04-09T13:45:10.319769Z"
    }
   },
   "outputs": [],
   "source": [
    "testmodelsop.to_csv(r'D:\\DS\\NLP\\quora-insincere-questions-classification\\testmodeloutputs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading embeddings & processing text to suit embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T07:00:22.296117Z",
     "start_time": "2020-04-07T07:00:22.290134Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\Anaconda\\lib\\site-packages\\tqdm\\std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import operator\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T06:46:42.267578Z",
     "start_time": "2020-04-07T06:39:37.086651Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loading glove embeddings\n",
    "def load_glove_index():\n",
    "    EMBEDDING_FILE=r'D:\\DS\\NLP\\quora-insincere-questions-classification\\embeddings\\glove.840B.300d\\glove.840B.300d.txt'\n",
    "    def get_coefs(word,*arr): \n",
    "        return word, np.asarray(arr, dtype='float32')[:300]\n",
    "    f=open(EMBEDDING_FILE,encoding=\"utf-8\")\n",
    "    embeddings_index=dict(get_coefs(*o.split(\" \")) for o in f)\n",
    "    return embeddings_index\n",
    "embeddings_index=load_glove_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T06:47:43.714320Z",
     "start_time": "2020-04-07T06:47:43.708369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2196016 word vectors.\n"
     ]
    }
   ],
   "source": [
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T06:56:02.617517Z",
     "start_time": "2020-04-07T06:56:02.610536Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to build vocabulary\n",
    "def build_vocab(texts):\n",
    "    sentences=texts.apply(lambda x: x.split()).values\n",
    "    vocab={}\n",
    "    for sentence in sentences:\n",
    "        for word in sentence:\n",
    "            try:\n",
    "                vocab[word]+=1\n",
    "            except KeyError:\n",
    "                vocab[word]=1\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T06:56:14.148582Z",
     "start_time": "2020-04-07T06:56:14.138878Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to check coverage of given vocabulary in our embedding\n",
    "def check_coverage(vocab, embeddings_index):\n",
    "    known_words={}\n",
    "    unknown_words={}\n",
    "    nb_known_words=0\n",
    "    nb_unknown_words=0\n",
    "    for word in vocab.keys():\n",
    "        try:\n",
    "            known_words[word]=embeddings_index[word]\n",
    "            nb_known_words+=vocab[word]\n",
    "        except:\n",
    "            unknown_words[word]=vocab[word]\n",
    "            nb_unknown_words+=vocab[word]\n",
    "            pass\n",
    "\n",
    "    print('Found embeddings for {:.2%} of vocab'.format(len(known_words)/len(vocab)))\n",
    "    print('Found embeddings for  {:.2%} of all text'.format(nb_known_words/(nb_known_words + nb_unknown_words)))\n",
    "    unknown_words=sorted(unknown_words.items(),key=operator.itemgetter(1))[::-1]\n",
    "\n",
    "    return unknown_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T06:56:19.205164Z",
     "start_time": "2020-04-07T06:56:19.076881Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>172360</th>\n",
       "      <td>Is there any beach available in Delhi for night out?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188522</th>\n",
       "      <td>What is the unit of vector parallel to each of vector?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235537</th>\n",
       "      <td>How change LTE to VOlTE?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345543</th>\n",
       "      <td>What percentage of US Democrat politicians are lawyers?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566414</th>\n",
       "      <td>How did Cabela's Inc. manages to establish such large stores?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180555</th>\n",
       "      <td>Where can I buy tamper proof courier bags online?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155574</th>\n",
       "      <td>What are some reasons to trust a Jew?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130815</th>\n",
       "      <td>What are the considerations in using a static class vs. a singleton? I need a class to handle functions with no relevance to specific instances.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107187</th>\n",
       "      <td>What is the purpose of the bit in a horse harness?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856532</th>\n",
       "      <td>What is Annie Dillard known for?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1044898 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                            question_text  \\\n",
       "172360                                                                                               Is there any beach available in Delhi for night out?   \n",
       "188522                                                                                             What is the unit of vector parallel to each of vector?   \n",
       "1235537                                                                                                                          How change LTE to VOlTE?   \n",
       "345543                                                                                            What percentage of US Democrat politicians are lawyers?   \n",
       "566414                                                                                      How did Cabela's Inc. manages to establish such large stores?   \n",
       "...                                                                                                                                                   ...   \n",
       "1180555                                                                                                 Where can I buy tamper proof courier bags online?   \n",
       "155574                                                                                                              What are some reasons to trust a Jew?   \n",
       "1130815  What are the considerations in using a static class vs. a singleton? I need a class to handle functions with no relevance to specific instances.   \n",
       "107187                                                                                                 What is the purpose of the bit in a horse harness?   \n",
       "856532                                                                                                                   What is Annie Dillard known for?   \n",
       "\n",
       "         target  \n",
       "172360        0  \n",
       "188522        0  \n",
       "1235537       0  \n",
       "345543        0  \n",
       "566414        0  \n",
       "...         ...  \n",
       "1180555       0  \n",
       "155574        1  \n",
       "1130815       0  \n",
       "107187        0  \n",
       "856532        0  \n",
       "\n",
       "[1044898 rows x 2 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T06:57:21.481688Z",
     "start_time": "2020-04-07T06:56:47.824054Z"
    }
   },
   "outputs": [],
   "source": [
    "# Building vocabulary for unprocessed and processed text\n",
    "vocab2=build_vocab(trainwu['question_text'])\n",
    "vocab3=build_vocab(insin['question_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T07:03:30.874819Z",
     "start_time": "2020-04-07T07:03:29.632143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Processed file:\n",
      "Found embeddings for 53.18% of vocab\n",
      "Found embeddings for  98.08% of all text\n",
      "\n",
      "For original training file:\n",
      "Found embeddings for 33.16% of vocab\n",
      "Found embeddings for  88.16% of all text\n"
     ]
    }
   ],
   "source": [
    "# Checking coverage of unprocessed and processed\n",
    "print('For Processed file:')\n",
    "oov_glove2=check_coverage(vocab2, embeddings_index)\n",
    "print('\\nFor original training file:')\n",
    "oov_glove3=check_coverage(vocab3, embeddings_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While processed has better coverage its due to heavy text processing used before. It loses lot of useful information so we will proceed with optimizing the coverage for unprocessed without losing too much info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T07:07:12.641478Z",
     "start_time": "2020-04-07T07:07:12.635093Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('India?', 16384),\n",
       " ('it?', 12900),\n",
       " (\"What's\", 12425),\n",
       " ('do?', 8753),\n",
       " ('life?', 7753),\n",
       " ('you?', 6295),\n",
       " ('me?', 6202),\n",
       " ('them?', 6140),\n",
       " ('time?', 5716),\n",
       " ('world?', 5386),\n",
       " ('people?', 4971),\n",
       " ('why?', 4943),\n",
       " ('Quora?', 4655),\n",
       " ('like?', 4487),\n",
       " ('for?', 4450),\n",
       " ('work?', 4206),\n",
       " ('2017?', 4050),\n",
       " ('mean?', 3971),\n",
       " ('2018?', 3594),\n",
       " ('country?', 3422)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the top uncovered words\n",
    "oov_glove3[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the above uncovered words are due to improper format of punctuations and contractions. We will correct that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T09:12:31.437125Z",
     "start_time": "2020-04-07T09:12:31.419174Z"
    }
   },
   "outputs": [],
   "source": [
    "contraction_mapping ={\"ain't\": \"is not\",\"Isn't\":'Is not',\"Can't\": \"Cannot\",\"What's\":'What is', \"aren't\": \"are not\",\n",
    "                      \"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \n",
    "                      \"Couldn't\": \"Could not\",\"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \n",
    "                      \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\",\n",
    "                      \"he's\": \"he is\", \"how'd\": \"how did\", \"How'd\": \"How did\",\"how'd'y\": \"how do you\", \"how'll\": \"how will\",\n",
    "                      \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \n",
    "                      \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \n",
    "                      \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \n",
    "                      \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\n",
    "                      \"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\n",
    "                      \"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\",\n",
    "                      \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\n",
    "                      \"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \n",
    "                      \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \n",
    "                      \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \n",
    "                      \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \n",
    "                      \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \n",
    "                      \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \n",
    "                      \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \n",
    "                      \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \n",
    "                      \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \n",
    "                      \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \n",
    "                      \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \n",
    "                      \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \n",
    "                      \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \n",
    "                      \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \n",
    "                      \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \n",
    "                      \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \n",
    "                      \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
    "                      \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                      \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \n",
    "                      \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\",\"Weren't\":\"Were not\", \n",
    "                      \"Aren't\":\"Are not\",\"Doesn't\":\"Does not\",\"Shouldn't\":\"Should not\",\"Wouldn't\":\"Would not\",\"U.S.\":\"USA\",\n",
    "                     \"U.S\":\"USA\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T09:12:31.943860Z",
     "start_time": "2020-04-07T09:12:31.937878Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to substitute contractions with full forms\n",
    "def clean_contractions(text, mapping):\n",
    "    specials=[\"’\", \"‘\", \"´\", \"`\"]\n",
    "    for s in specials:\n",
    "        text=text.replace(s, \"'\")\n",
    "    text=' '.join([mapping[t] if t in mapping else t for t in text.split(\" \")])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T09:12:36.191392Z",
     "start_time": "2020-04-07T09:12:32.587068Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "      <th>punctques</th>\n",
       "      <th>contrques</th>\n",
       "      <th>transf1</th>\n",
       "      <th>transf2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province as a nation in the 1960s?</td>\n",
       "      <td>0</td>\n",
       "      <td>How did Quebec nationalists see their province as a nation in the 1960s ?</td>\n",
       "      <td>How did Quebec nationalists see their province as a nation in the 1960s?</td>\n",
       "      <td>How did Quebec nationalists see their province as a nation in the 1960s ?</td>\n",
       "      <td>How did Quebec nationalists see their province as a nation in the 1960s ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you encourage people to adopt and not shop?</td>\n",
       "      <td>0</td>\n",
       "      <td>Do you have an adopted dog , how would you encourage people to adopt and not shop ?</td>\n",
       "      <td>Do you have an adopted dog, how would you encourage people to adopt and not shop?</td>\n",
       "      <td>Do you have an adopted dog , how would you encourage people to adopt and not shop ?</td>\n",
       "      <td>Do you have an adopted dog , how would you encourage people to adopt and not shop ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity affect space geometry?</td>\n",
       "      <td>0</td>\n",
       "      <td>Why does velocity affect time ? Does velocity affect space geometry ?</td>\n",
       "      <td>Why does velocity affect time? Does velocity affect space geometry?</td>\n",
       "      <td>Why does velocity affect time ? Does velocity affect space geometry ?</td>\n",
       "      <td>Why does velocity affect time ? Does velocity affect space geometry ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg hemispheres?</td>\n",
       "      <td>0</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg hemispheres ?</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg hemispheres?</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg hemispheres ?</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg hemispheres ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain bike by just changing the tyres?</td>\n",
       "      <td>0</td>\n",
       "      <td>Can I convert montra helicon D to a mountain bike by just changing the tyres ?</td>\n",
       "      <td>Can I convert montra helicon D to a mountain bike by just changing the tyres?</td>\n",
       "      <td>Can I convert montra helicon D to a mountain bike by just changing the tyres ?</td>\n",
       "      <td>Can I convert montra helicon D to a mountain bike by just changing the tyres ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306117</th>\n",
       "      <td>ffffcc4e2331aaf1e41e</td>\n",
       "      <td>What other technical skills do you need as a computer science undergrad other than c and c++?</td>\n",
       "      <td>0</td>\n",
       "      <td>What other technical skills do you need as a computer science undergrad other than c and c + + ?</td>\n",
       "      <td>What other technical skills do you need as a computer science undergrad other than c and c++?</td>\n",
       "      <td>What other technical skills do you need as a computer science undergrad other than c and c + + ?</td>\n",
       "      <td>What other technical skills do you need as a computer science undergrad other than c and c + + ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306118</th>\n",
       "      <td>ffffd431801e5a2f4861</td>\n",
       "      <td>Does MS in ECE have good job prospects in USA or like India there are more IT jobs present?</td>\n",
       "      <td>0</td>\n",
       "      <td>Does MS in ECE have good job prospects in USA or like India there are more IT jobs present ?</td>\n",
       "      <td>Does MS in ECE have good job prospects in USA or like India there are more IT jobs present?</td>\n",
       "      <td>Does MS in ECE have good job prospects in USA or like India there are more IT jobs present ?</td>\n",
       "      <td>Does MS in ECE have good job prospects in USA or like India there are more IT jobs present ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306119</th>\n",
       "      <td>ffffd48fb36b63db010c</td>\n",
       "      <td>Is foam insulation toxic?</td>\n",
       "      <td>0</td>\n",
       "      <td>Is foam insulation toxic ?</td>\n",
       "      <td>Is foam insulation toxic?</td>\n",
       "      <td>Is foam insulation toxic ?</td>\n",
       "      <td>Is foam insulation toxic ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306120</th>\n",
       "      <td>ffffec519fa37cf60c78</td>\n",
       "      <td>How can one start a research project based on biochemistry at UG level?</td>\n",
       "      <td>0</td>\n",
       "      <td>How can one start a research project based on biochemistry at UG level ?</td>\n",
       "      <td>How can one start a research project based on biochemistry at UG level?</td>\n",
       "      <td>How can one start a research project based on biochemistry at UG level ?</td>\n",
       "      <td>How can one start a research project based on biochemistry at UG level ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306121</th>\n",
       "      <td>ffffed09fedb5088744a</td>\n",
       "      <td>Who wins in a battle between a Wolverine and a Puma?</td>\n",
       "      <td>0</td>\n",
       "      <td>Who wins in a battle between a Wolverine and a Puma ?</td>\n",
       "      <td>Who wins in a battle between a Wolverine and a Puma?</td>\n",
       "      <td>Who wins in a battle between a Wolverine and a Puma ?</td>\n",
       "      <td>Who wins in a battle between a Wolverine and a Puma ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1306122 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          qid  \\\n",
       "0        00002165364db923c7e6   \n",
       "1        000032939017120e6e44   \n",
       "2        0000412ca6e4628ce2cf   \n",
       "3        000042bf85aa498cd78e   \n",
       "4        0000455dfa3e01eae3af   \n",
       "...                       ...   \n",
       "1306117  ffffcc4e2331aaf1e41e   \n",
       "1306118  ffffd431801e5a2f4861   \n",
       "1306119  ffffd48fb36b63db010c   \n",
       "1306120  ffffec519fa37cf60c78   \n",
       "1306121  ffffed09fedb5088744a   \n",
       "\n",
       "                                                                                         question_text  \\\n",
       "0                             How did Quebec nationalists see their province as a nation in the 1960s?   \n",
       "1                    Do you have an adopted dog, how would you encourage people to adopt and not shop?   \n",
       "2                                  Why does velocity affect time? Does velocity affect space geometry?   \n",
       "3                                            How did Otto von Guericke used the Magdeburg hemispheres?   \n",
       "4                        Can I convert montra helicon D to a mountain bike by just changing the tyres?   \n",
       "...                                                                                                ...   \n",
       "1306117  What other technical skills do you need as a computer science undergrad other than c and c++?   \n",
       "1306118    Does MS in ECE have good job prospects in USA or like India there are more IT jobs present?   \n",
       "1306119                                                                      Is foam insulation toxic?   \n",
       "1306120                        How can one start a research project based on biochemistry at UG level?   \n",
       "1306121                                           Who wins in a battle between a Wolverine and a Puma?   \n",
       "\n",
       "         target  \\\n",
       "0             0   \n",
       "1             0   \n",
       "2             0   \n",
       "3             0   \n",
       "4             0   \n",
       "...         ...   \n",
       "1306117       0   \n",
       "1306118       0   \n",
       "1306119       0   \n",
       "1306120       0   \n",
       "1306121       0   \n",
       "\n",
       "                                                                                                punctques  \\\n",
       "0                               How did Quebec nationalists see their province as a nation in the 1960s ?   \n",
       "1                     Do you have an adopted dog , how would you encourage people to adopt and not shop ?   \n",
       "2                                   Why does velocity affect time ? Does velocity affect space geometry ?   \n",
       "3                                              How did Otto von Guericke used the Magdeburg hemispheres ?   \n",
       "4                          Can I convert montra helicon D to a mountain bike by just changing the tyres ?   \n",
       "...                                                                                                   ...   \n",
       "1306117  What other technical skills do you need as a computer science undergrad other than c and c + + ?   \n",
       "1306118      Does MS in ECE have good job prospects in USA or like India there are more IT jobs present ?   \n",
       "1306119                                                                        Is foam insulation toxic ?   \n",
       "1306120                          How can one start a research project based on biochemistry at UG level ?   \n",
       "1306121                                             Who wins in a battle between a Wolverine and a Puma ?   \n",
       "\n",
       "                                                                                             contrques  \\\n",
       "0                             How did Quebec nationalists see their province as a nation in the 1960s?   \n",
       "1                    Do you have an adopted dog, how would you encourage people to adopt and not shop?   \n",
       "2                                  Why does velocity affect time? Does velocity affect space geometry?   \n",
       "3                                            How did Otto von Guericke used the Magdeburg hemispheres?   \n",
       "4                        Can I convert montra helicon D to a mountain bike by just changing the tyres?   \n",
       "...                                                                                                ...   \n",
       "1306117  What other technical skills do you need as a computer science undergrad other than c and c++?   \n",
       "1306118    Does MS in ECE have good job prospects in USA or like India there are more IT jobs present?   \n",
       "1306119                                                                      Is foam insulation toxic?   \n",
       "1306120                        How can one start a research project based on biochemistry at UG level?   \n",
       "1306121                                           Who wins in a battle between a Wolverine and a Puma?   \n",
       "\n",
       "                                                                                                  transf1  \\\n",
       "0                               How did Quebec nationalists see their province as a nation in the 1960s ?   \n",
       "1                     Do you have an adopted dog , how would you encourage people to adopt and not shop ?   \n",
       "2                                   Why does velocity affect time ? Does velocity affect space geometry ?   \n",
       "3                                              How did Otto von Guericke used the Magdeburg hemispheres ?   \n",
       "4                          Can I convert montra helicon D to a mountain bike by just changing the tyres ?   \n",
       "...                                                                                                   ...   \n",
       "1306117  What other technical skills do you need as a computer science undergrad other than c and c + + ?   \n",
       "1306118      Does MS in ECE have good job prospects in USA or like India there are more IT jobs present ?   \n",
       "1306119                                                                        Is foam insulation toxic ?   \n",
       "1306120                          How can one start a research project based on biochemistry at UG level ?   \n",
       "1306121                                             Who wins in a battle between a Wolverine and a Puma ?   \n",
       "\n",
       "                                                                                                  transf2  \n",
       "0                               How did Quebec nationalists see their province as a nation in the 1960s ?  \n",
       "1                     Do you have an adopted dog , how would you encourage people to adopt and not shop ?  \n",
       "2                                   Why does velocity affect time ? Does velocity affect space geometry ?  \n",
       "3                                              How did Otto von Guericke used the Magdeburg hemispheres ?  \n",
       "4                          Can I convert montra helicon D to a mountain bike by just changing the tyres ?  \n",
       "...                                                                                                   ...  \n",
       "1306117  What other technical skills do you need as a computer science undergrad other than c and c + + ?  \n",
       "1306118      Does MS in ECE have good job prospects in USA or like India there are more IT jobs present ?  \n",
       "1306119                                                                        Is foam insulation toxic ?  \n",
       "1306120                          How can one start a research project based on biochemistry at UG level ?  \n",
       "1306121                                             Who wins in a battle between a Wolverine and a Puma ?  \n",
       "\n",
       "[1306122 rows x 7 columns]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying contraction cleaning\n",
    "insin['contrques']=insin['question_text'].apply(lambda x:clean_contractions(x,contraction_mapping))\n",
    "insin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T09:12:36.200370Z",
     "start_time": "2020-04-07T09:12:36.192423Z"
    }
   },
   "outputs": [],
   "source": [
    "puncts=[',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n",
    " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
    " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
    " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
    " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T09:13:24.320839Z",
     "start_time": "2020-04-07T09:12:36.203361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 200000 300000 400000 500000 600000 700000 800000 900000 1000000 1100000 1200000 1300000 "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "      <th>punctques</th>\n",
       "      <th>contrques</th>\n",
       "      <th>transf1</th>\n",
       "      <th>transf2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province as a nation in the 1960s?</td>\n",
       "      <td>0</td>\n",
       "      <td>How did Quebec nationalists see their province as a nation in the 1960s ?</td>\n",
       "      <td>How did Quebec nationalists see their province as a nation in the 1960s?</td>\n",
       "      <td>How did Quebec nationalists see their province as a nation in the 1960s ?</td>\n",
       "      <td>How did Quebec nationalists see their province as a nation in the 1960s ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you encourage people to adopt and not shop?</td>\n",
       "      <td>0</td>\n",
       "      <td>Do you have an adopted dog , how would you encourage people to adopt and not shop ?</td>\n",
       "      <td>Do you have an adopted dog, how would you encourage people to adopt and not shop?</td>\n",
       "      <td>Do you have an adopted dog , how would you encourage people to adopt and not shop ?</td>\n",
       "      <td>Do you have an adopted dog , how would you encourage people to adopt and not shop ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity affect space geometry?</td>\n",
       "      <td>0</td>\n",
       "      <td>Why does velocity affect time ? Does velocity affect space geometry ?</td>\n",
       "      <td>Why does velocity affect time? Does velocity affect space geometry?</td>\n",
       "      <td>Why does velocity affect time ? Does velocity affect space geometry ?</td>\n",
       "      <td>Why does velocity affect time ? Does velocity affect space geometry ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg hemispheres?</td>\n",
       "      <td>0</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg hemispheres ?</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg hemispheres?</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg hemispheres ?</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg hemispheres ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain bike by just changing the tyres?</td>\n",
       "      <td>0</td>\n",
       "      <td>Can I convert montra helicon D to a mountain bike by just changing the tyres ?</td>\n",
       "      <td>Can I convert montra helicon D to a mountain bike by just changing the tyres?</td>\n",
       "      <td>Can I convert montra helicon D to a mountain bike by just changing the tyres ?</td>\n",
       "      <td>Can I convert montra helicon D to a mountain bike by just changing the tyres ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306117</th>\n",
       "      <td>ffffcc4e2331aaf1e41e</td>\n",
       "      <td>What other technical skills do you need as a computer science undergrad other than c and c++?</td>\n",
       "      <td>0</td>\n",
       "      <td>What other technical skills do you need as a computer science undergrad other than c and c + + ?</td>\n",
       "      <td>What other technical skills do you need as a computer science undergrad other than c and c++?</td>\n",
       "      <td>What other technical skills do you need as a computer science undergrad other than c and c + + ?</td>\n",
       "      <td>What other technical skills do you need as a computer science undergrad other than c and c + + ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306118</th>\n",
       "      <td>ffffd431801e5a2f4861</td>\n",
       "      <td>Does MS in ECE have good job prospects in USA or like India there are more IT jobs present?</td>\n",
       "      <td>0</td>\n",
       "      <td>Does MS in ECE have good job prospects in USA or like India there are more IT jobs present ?</td>\n",
       "      <td>Does MS in ECE have good job prospects in USA or like India there are more IT jobs present?</td>\n",
       "      <td>Does MS in ECE have good job prospects in USA or like India there are more IT jobs present ?</td>\n",
       "      <td>Does MS in ECE have good job prospects in USA or like India there are more IT jobs present ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306119</th>\n",
       "      <td>ffffd48fb36b63db010c</td>\n",
       "      <td>Is foam insulation toxic?</td>\n",
       "      <td>0</td>\n",
       "      <td>Is foam insulation toxic ?</td>\n",
       "      <td>Is foam insulation toxic?</td>\n",
       "      <td>Is foam insulation toxic ?</td>\n",
       "      <td>Is foam insulation toxic ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306120</th>\n",
       "      <td>ffffec519fa37cf60c78</td>\n",
       "      <td>How can one start a research project based on biochemistry at UG level?</td>\n",
       "      <td>0</td>\n",
       "      <td>How can one start a research project based on biochemistry at UG level ?</td>\n",
       "      <td>How can one start a research project based on biochemistry at UG level?</td>\n",
       "      <td>How can one start a research project based on biochemistry at UG level ?</td>\n",
       "      <td>How can one start a research project based on biochemistry at UG level ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306121</th>\n",
       "      <td>ffffed09fedb5088744a</td>\n",
       "      <td>Who wins in a battle between a Wolverine and a Puma?</td>\n",
       "      <td>0</td>\n",
       "      <td>Who wins in a battle between a Wolverine and a Puma ?</td>\n",
       "      <td>Who wins in a battle between a Wolverine and a Puma?</td>\n",
       "      <td>Who wins in a battle between a Wolverine and a Puma ?</td>\n",
       "      <td>Who wins in a battle between a Wolverine and a Puma ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1306122 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          qid  \\\n",
       "0        00002165364db923c7e6   \n",
       "1        000032939017120e6e44   \n",
       "2        0000412ca6e4628ce2cf   \n",
       "3        000042bf85aa498cd78e   \n",
       "4        0000455dfa3e01eae3af   \n",
       "...                       ...   \n",
       "1306117  ffffcc4e2331aaf1e41e   \n",
       "1306118  ffffd431801e5a2f4861   \n",
       "1306119  ffffd48fb36b63db010c   \n",
       "1306120  ffffec519fa37cf60c78   \n",
       "1306121  ffffed09fedb5088744a   \n",
       "\n",
       "                                                                                         question_text  \\\n",
       "0                             How did Quebec nationalists see their province as a nation in the 1960s?   \n",
       "1                    Do you have an adopted dog, how would you encourage people to adopt and not shop?   \n",
       "2                                  Why does velocity affect time? Does velocity affect space geometry?   \n",
       "3                                            How did Otto von Guericke used the Magdeburg hemispheres?   \n",
       "4                        Can I convert montra helicon D to a mountain bike by just changing the tyres?   \n",
       "...                                                                                                ...   \n",
       "1306117  What other technical skills do you need as a computer science undergrad other than c and c++?   \n",
       "1306118    Does MS in ECE have good job prospects in USA or like India there are more IT jobs present?   \n",
       "1306119                                                                      Is foam insulation toxic?   \n",
       "1306120                        How can one start a research project based on biochemistry at UG level?   \n",
       "1306121                                           Who wins in a battle between a Wolverine and a Puma?   \n",
       "\n",
       "         target  \\\n",
       "0             0   \n",
       "1             0   \n",
       "2             0   \n",
       "3             0   \n",
       "4             0   \n",
       "...         ...   \n",
       "1306117       0   \n",
       "1306118       0   \n",
       "1306119       0   \n",
       "1306120       0   \n",
       "1306121       0   \n",
       "\n",
       "                                                                                                punctques  \\\n",
       "0                               How did Quebec nationalists see their province as a nation in the 1960s ?   \n",
       "1                     Do you have an adopted dog , how would you encourage people to adopt and not shop ?   \n",
       "2                                   Why does velocity affect time ? Does velocity affect space geometry ?   \n",
       "3                                              How did Otto von Guericke used the Magdeburg hemispheres ?   \n",
       "4                          Can I convert montra helicon D to a mountain bike by just changing the tyres ?   \n",
       "...                                                                                                   ...   \n",
       "1306117  What other technical skills do you need as a computer science undergrad other than c and c + + ?   \n",
       "1306118      Does MS in ECE have good job prospects in USA or like India there are more IT jobs present ?   \n",
       "1306119                                                                        Is foam insulation toxic ?   \n",
       "1306120                          How can one start a research project based on biochemistry at UG level ?   \n",
       "1306121                                             Who wins in a battle between a Wolverine and a Puma ?   \n",
       "\n",
       "                                                                                             contrques  \\\n",
       "0                             How did Quebec nationalists see their province as a nation in the 1960s?   \n",
       "1                    Do you have an adopted dog, how would you encourage people to adopt and not shop?   \n",
       "2                                  Why does velocity affect time? Does velocity affect space geometry?   \n",
       "3                                            How did Otto von Guericke used the Magdeburg hemispheres?   \n",
       "4                        Can I convert montra helicon D to a mountain bike by just changing the tyres?   \n",
       "...                                                                                                ...   \n",
       "1306117  What other technical skills do you need as a computer science undergrad other than c and c++?   \n",
       "1306118    Does MS in ECE have good job prospects in USA or like India there are more IT jobs present?   \n",
       "1306119                                                                      Is foam insulation toxic?   \n",
       "1306120                        How can one start a research project based on biochemistry at UG level?   \n",
       "1306121                                           Who wins in a battle between a Wolverine and a Puma?   \n",
       "\n",
       "                                                                                                  transf1  \\\n",
       "0                               How did Quebec nationalists see their province as a nation in the 1960s ?   \n",
       "1                     Do you have an adopted dog , how would you encourage people to adopt and not shop ?   \n",
       "2                                   Why does velocity affect time ? Does velocity affect space geometry ?   \n",
       "3                                              How did Otto von Guericke used the Magdeburg hemispheres ?   \n",
       "4                          Can I convert montra helicon D to a mountain bike by just changing the tyres ?   \n",
       "...                                                                                                   ...   \n",
       "1306117  What other technical skills do you need as a computer science undergrad other than c and c + + ?   \n",
       "1306118      Does MS in ECE have good job prospects in USA or like India there are more IT jobs present ?   \n",
       "1306119                                                                        Is foam insulation toxic ?   \n",
       "1306120                          How can one start a research project based on biochemistry at UG level ?   \n",
       "1306121                                             Who wins in a battle between a Wolverine and a Puma ?   \n",
       "\n",
       "                                                                                                  transf2  \n",
       "0                               How did Quebec nationalists see their province as a nation in the 1960s ?  \n",
       "1                     Do you have an adopted dog , how would you encourage people to adopt and not shop ?  \n",
       "2                                   Why does velocity affect time ? Does velocity affect space geometry ?  \n",
       "3                                              How did Otto von Guericke used the Magdeburg hemispheres ?  \n",
       "4                          Can I convert montra helicon D to a mountain bike by just changing the tyres ?  \n",
       "...                                                                                                   ...  \n",
       "1306117  What other technical skills do you need as a computer science undergrad other than c and c + + ?  \n",
       "1306118      Does MS in ECE have good job prospects in USA or like India there are more IT jobs present ?  \n",
       "1306119                                                                        Is foam insulation toxic ?  \n",
       "1306120                          How can one start a research project based on biochemistry at UG level ?  \n",
       "1306121                                             Who wins in a battle between a Wolverine and a Puma ?  \n",
       "\n",
       "[1306122 rows x 7 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Formatting the punctuations so as to separate words and punctuations\n",
    "punctques=[]\n",
    "for i in insin['contrques'].values:\n",
    "    sent=i\n",
    "    for j in puncts:\n",
    "        if ((j+' ') in sent) or (sent.endswith(j)):\n",
    "            rep=' '+j\n",
    "            sent=sent.replace(j,rep)\n",
    "    punctques.append(sent)\n",
    "    if len(punctques)%100000==0:\n",
    "        print(len(punctques),end=' ')\n",
    "insin['punctques']=punctques\n",
    "insin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T09:13:34.366948Z",
     "start_time": "2020-04-07T09:13:24.321839Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For original training file:\n",
      "Found embeddings for 53.79% of vocab\n",
      "Found embeddings for  98.32% of all text\n"
     ]
    }
   ],
   "source": [
    "# Checking coverage after processing\n",
    "vocab3=build_vocab(insin['punctques'])\n",
    "print('\\nFor original training file:')\n",
    "oov_glove3=check_coverage(vocab3, embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T09:13:36.558297Z",
     "start_time": "2020-04-07T09:13:36.551316Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('\"The', 2244),\n",
       " (\"Trump's\", 1760),\n",
       " ('(or', 1146),\n",
       " ('(in', 1044),\n",
       " ('[math', 1024),\n",
       " ('(I', 1013),\n",
       " ('(not', 893),\n",
       " (\"someone's\", 885),\n",
       " (\"today's\", 855),\n",
       " ('Quorans', 850),\n",
       " ('.g', 849),\n",
       " ('(like', 757),\n",
       " (\"one's\", 743),\n",
       " (\"people's\", 728),\n",
       " ('\"I', 704),\n",
       " (\"India's\", 691),\n",
       " ('(and', 690),\n",
       " ('.e', 655),\n",
       " ('(e', 606),\n",
       " ('(for', 564)]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top uncovered words\n",
    "oov_glove3[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T09:13:37.079328Z",
     "start_time": "2020-04-07T09:13:37.075340Z"
    }
   },
   "outputs": [],
   "source": [
    "# Many of the uncovered ones above are ending with 's. We will remove the apostrophy.\n",
    "def ends(x):\n",
    "    x=x.replace(\"'s\",'s')    \n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T09:13:38.183982Z",
     "start_time": "2020-04-07T09:13:37.641433Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "      <th>punctques</th>\n",
       "      <th>contrques</th>\n",
       "      <th>transf1</th>\n",
       "      <th>transf2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province as a nation in the 1960s?</td>\n",
       "      <td>0</td>\n",
       "      <td>How did Quebec nationalists see their province as a nation in the 1960s ?</td>\n",
       "      <td>How did Quebec nationalists see their province as a nation in the 1960s?</td>\n",
       "      <td>How did Quebec nationalists see their province as a nation in the 1960s ?</td>\n",
       "      <td>How did Quebec nationalists see their province as a nation in the 1960s ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you encourage people to adopt and not shop?</td>\n",
       "      <td>0</td>\n",
       "      <td>Do you have an adopted dog , how would you encourage people to adopt and not shop ?</td>\n",
       "      <td>Do you have an adopted dog, how would you encourage people to adopt and not shop?</td>\n",
       "      <td>Do you have an adopted dog , how would you encourage people to adopt and not shop ?</td>\n",
       "      <td>Do you have an adopted dog , how would you encourage people to adopt and not shop ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity affect space geometry?</td>\n",
       "      <td>0</td>\n",
       "      <td>Why does velocity affect time ? Does velocity affect space geometry ?</td>\n",
       "      <td>Why does velocity affect time? Does velocity affect space geometry?</td>\n",
       "      <td>Why does velocity affect time ? Does velocity affect space geometry ?</td>\n",
       "      <td>Why does velocity affect time ? Does velocity affect space geometry ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg hemispheres?</td>\n",
       "      <td>0</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg hemispheres ?</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg hemispheres?</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg hemispheres ?</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg hemispheres ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain bike by just changing the tyres?</td>\n",
       "      <td>0</td>\n",
       "      <td>Can I convert montra helicon D to a mountain bike by just changing the tyres ?</td>\n",
       "      <td>Can I convert montra helicon D to a mountain bike by just changing the tyres?</td>\n",
       "      <td>Can I convert montra helicon D to a mountain bike by just changing the tyres ?</td>\n",
       "      <td>Can I convert montra helicon D to a mountain bike by just changing the tyres ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306117</th>\n",
       "      <td>ffffcc4e2331aaf1e41e</td>\n",
       "      <td>What other technical skills do you need as a computer science undergrad other than c and c++?</td>\n",
       "      <td>0</td>\n",
       "      <td>What other technical skills do you need as a computer science undergrad other than c and c + + ?</td>\n",
       "      <td>What other technical skills do you need as a computer science undergrad other than c and c++?</td>\n",
       "      <td>What other technical skills do you need as a computer science undergrad other than c and c + + ?</td>\n",
       "      <td>What other technical skills do you need as a computer science undergrad other than c and c + + ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306118</th>\n",
       "      <td>ffffd431801e5a2f4861</td>\n",
       "      <td>Does MS in ECE have good job prospects in USA or like India there are more IT jobs present?</td>\n",
       "      <td>0</td>\n",
       "      <td>Does MS in ECE have good job prospects in USA or like India there are more IT jobs present ?</td>\n",
       "      <td>Does MS in ECE have good job prospects in USA or like India there are more IT jobs present?</td>\n",
       "      <td>Does MS in ECE have good job prospects in USA or like India there are more IT jobs present ?</td>\n",
       "      <td>Does MS in ECE have good job prospects in USA or like India there are more IT jobs present ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306119</th>\n",
       "      <td>ffffd48fb36b63db010c</td>\n",
       "      <td>Is foam insulation toxic?</td>\n",
       "      <td>0</td>\n",
       "      <td>Is foam insulation toxic ?</td>\n",
       "      <td>Is foam insulation toxic?</td>\n",
       "      <td>Is foam insulation toxic ?</td>\n",
       "      <td>Is foam insulation toxic ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306120</th>\n",
       "      <td>ffffec519fa37cf60c78</td>\n",
       "      <td>How can one start a research project based on biochemistry at UG level?</td>\n",
       "      <td>0</td>\n",
       "      <td>How can one start a research project based on biochemistry at UG level ?</td>\n",
       "      <td>How can one start a research project based on biochemistry at UG level?</td>\n",
       "      <td>How can one start a research project based on biochemistry at UG level ?</td>\n",
       "      <td>How can one start a research project based on biochemistry at UG level ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306121</th>\n",
       "      <td>ffffed09fedb5088744a</td>\n",
       "      <td>Who wins in a battle between a Wolverine and a Puma?</td>\n",
       "      <td>0</td>\n",
       "      <td>Who wins in a battle between a Wolverine and a Puma ?</td>\n",
       "      <td>Who wins in a battle between a Wolverine and a Puma?</td>\n",
       "      <td>Who wins in a battle between a Wolverine and a Puma ?</td>\n",
       "      <td>Who wins in a battle between a Wolverine and a Puma ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1306122 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          qid  \\\n",
       "0        00002165364db923c7e6   \n",
       "1        000032939017120e6e44   \n",
       "2        0000412ca6e4628ce2cf   \n",
       "3        000042bf85aa498cd78e   \n",
       "4        0000455dfa3e01eae3af   \n",
       "...                       ...   \n",
       "1306117  ffffcc4e2331aaf1e41e   \n",
       "1306118  ffffd431801e5a2f4861   \n",
       "1306119  ffffd48fb36b63db010c   \n",
       "1306120  ffffec519fa37cf60c78   \n",
       "1306121  ffffed09fedb5088744a   \n",
       "\n",
       "                                                                                         question_text  \\\n",
       "0                             How did Quebec nationalists see their province as a nation in the 1960s?   \n",
       "1                    Do you have an adopted dog, how would you encourage people to adopt and not shop?   \n",
       "2                                  Why does velocity affect time? Does velocity affect space geometry?   \n",
       "3                                            How did Otto von Guericke used the Magdeburg hemispheres?   \n",
       "4                        Can I convert montra helicon D to a mountain bike by just changing the tyres?   \n",
       "...                                                                                                ...   \n",
       "1306117  What other technical skills do you need as a computer science undergrad other than c and c++?   \n",
       "1306118    Does MS in ECE have good job prospects in USA or like India there are more IT jobs present?   \n",
       "1306119                                                                      Is foam insulation toxic?   \n",
       "1306120                        How can one start a research project based on biochemistry at UG level?   \n",
       "1306121                                           Who wins in a battle between a Wolverine and a Puma?   \n",
       "\n",
       "         target  \\\n",
       "0             0   \n",
       "1             0   \n",
       "2             0   \n",
       "3             0   \n",
       "4             0   \n",
       "...         ...   \n",
       "1306117       0   \n",
       "1306118       0   \n",
       "1306119       0   \n",
       "1306120       0   \n",
       "1306121       0   \n",
       "\n",
       "                                                                                                punctques  \\\n",
       "0                               How did Quebec nationalists see their province as a nation in the 1960s ?   \n",
       "1                     Do you have an adopted dog , how would you encourage people to adopt and not shop ?   \n",
       "2                                   Why does velocity affect time ? Does velocity affect space geometry ?   \n",
       "3                                              How did Otto von Guericke used the Magdeburg hemispheres ?   \n",
       "4                          Can I convert montra helicon D to a mountain bike by just changing the tyres ?   \n",
       "...                                                                                                   ...   \n",
       "1306117  What other technical skills do you need as a computer science undergrad other than c and c + + ?   \n",
       "1306118      Does MS in ECE have good job prospects in USA or like India there are more IT jobs present ?   \n",
       "1306119                                                                        Is foam insulation toxic ?   \n",
       "1306120                          How can one start a research project based on biochemistry at UG level ?   \n",
       "1306121                                             Who wins in a battle between a Wolverine and a Puma ?   \n",
       "\n",
       "                                                                                             contrques  \\\n",
       "0                             How did Quebec nationalists see their province as a nation in the 1960s?   \n",
       "1                    Do you have an adopted dog, how would you encourage people to adopt and not shop?   \n",
       "2                                  Why does velocity affect time? Does velocity affect space geometry?   \n",
       "3                                            How did Otto von Guericke used the Magdeburg hemispheres?   \n",
       "4                        Can I convert montra helicon D to a mountain bike by just changing the tyres?   \n",
       "...                                                                                                ...   \n",
       "1306117  What other technical skills do you need as a computer science undergrad other than c and c++?   \n",
       "1306118    Does MS in ECE have good job prospects in USA or like India there are more IT jobs present?   \n",
       "1306119                                                                      Is foam insulation toxic?   \n",
       "1306120                        How can one start a research project based on biochemistry at UG level?   \n",
       "1306121                                           Who wins in a battle between a Wolverine and a Puma?   \n",
       "\n",
       "                                                                                                  transf1  \\\n",
       "0                               How did Quebec nationalists see their province as a nation in the 1960s ?   \n",
       "1                     Do you have an adopted dog , how would you encourage people to adopt and not shop ?   \n",
       "2                                   Why does velocity affect time ? Does velocity affect space geometry ?   \n",
       "3                                              How did Otto von Guericke used the Magdeburg hemispheres ?   \n",
       "4                          Can I convert montra helicon D to a mountain bike by just changing the tyres ?   \n",
       "...                                                                                                   ...   \n",
       "1306117  What other technical skills do you need as a computer science undergrad other than c and c + + ?   \n",
       "1306118      Does MS in ECE have good job prospects in USA or like India there are more IT jobs present ?   \n",
       "1306119                                                                        Is foam insulation toxic ?   \n",
       "1306120                          How can one start a research project based on biochemistry at UG level ?   \n",
       "1306121                                             Who wins in a battle between a Wolverine and a Puma ?   \n",
       "\n",
       "                                                                                                  transf2  \n",
       "0                               How did Quebec nationalists see their province as a nation in the 1960s ?  \n",
       "1                     Do you have an adopted dog , how would you encourage people to adopt and not shop ?  \n",
       "2                                   Why does velocity affect time ? Does velocity affect space geometry ?  \n",
       "3                                              How did Otto von Guericke used the Magdeburg hemispheres ?  \n",
       "4                          Can I convert montra helicon D to a mountain bike by just changing the tyres ?  \n",
       "...                                                                                                   ...  \n",
       "1306117  What other technical skills do you need as a computer science undergrad other than c and c + + ?  \n",
       "1306118      Does MS in ECE have good job prospects in USA or like India there are more IT jobs present ?  \n",
       "1306119                                                                        Is foam insulation toxic ?  \n",
       "1306120                          How can one start a research project based on biochemistry at UG level ?  \n",
       "1306121                                             Who wins in a battle between a Wolverine and a Puma ?  \n",
       "\n",
       "[1306122 rows x 7 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transforming text\n",
    "insin['transf1'] = insin['punctques'].apply(lambda x: ends(x))\n",
    "insin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T09:13:48.101464Z",
     "start_time": "2020-04-07T09:13:38.184983Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For original training file:\n",
      "Found embeddings for 55.30% of vocab\n",
      "Found embeddings for  98.56% of all text\n"
     ]
    }
   ],
   "source": [
    "# Checking coverage\n",
    "vocab3=build_vocab(insin['transf1'])\n",
    "print('\\nFor original training file:')\n",
    "oov_glove3=check_coverage(vocab3, embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T09:13:48.107442Z",
     "start_time": "2020-04-07T09:13:48.103425Z"
    }
   },
   "outputs": [],
   "source": [
    "# Formatting brackets in text\n",
    "def brackets(x):\n",
    "    x=x.replace(\"(\",'( ')\n",
    "    x=x.replace(\")\",' )')\n",
    "    x=x.replace(\"[\",\"[ \")\n",
    "    x=x.replace(\"]\",\" ]\")\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T09:13:49.111761Z",
     "start_time": "2020-04-07T09:13:48.109410Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "      <th>punctques</th>\n",
       "      <th>contrques</th>\n",
       "      <th>transf1</th>\n",
       "      <th>transf2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province as a nation in the 1960s?</td>\n",
       "      <td>0</td>\n",
       "      <td>How did Quebec nationalists see their province as a nation in the 1960s ?</td>\n",
       "      <td>How did Quebec nationalists see their province as a nation in the 1960s?</td>\n",
       "      <td>How did Quebec nationalists see their province as a nation in the 1960s ?</td>\n",
       "      <td>How did Quebec nationalists see their province as a nation in the 1960s ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you encourage people to adopt and not shop?</td>\n",
       "      <td>0</td>\n",
       "      <td>Do you have an adopted dog , how would you encourage people to adopt and not shop ?</td>\n",
       "      <td>Do you have an adopted dog, how would you encourage people to adopt and not shop?</td>\n",
       "      <td>Do you have an adopted dog , how would you encourage people to adopt and not shop ?</td>\n",
       "      <td>Do you have an adopted dog , how would you encourage people to adopt and not shop ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity affect space geometry?</td>\n",
       "      <td>0</td>\n",
       "      <td>Why does velocity affect time ? Does velocity affect space geometry ?</td>\n",
       "      <td>Why does velocity affect time? Does velocity affect space geometry?</td>\n",
       "      <td>Why does velocity affect time ? Does velocity affect space geometry ?</td>\n",
       "      <td>Why does velocity affect time ? Does velocity affect space geometry ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg hemispheres?</td>\n",
       "      <td>0</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg hemispheres ?</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg hemispheres?</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg hemispheres ?</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg hemispheres ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain bike by just changing the tyres?</td>\n",
       "      <td>0</td>\n",
       "      <td>Can I convert montra helicon D to a mountain bike by just changing the tyres ?</td>\n",
       "      <td>Can I convert montra helicon D to a mountain bike by just changing the tyres?</td>\n",
       "      <td>Can I convert montra helicon D to a mountain bike by just changing the tyres ?</td>\n",
       "      <td>Can I convert montra helicon D to a mountain bike by just changing the tyres ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306117</th>\n",
       "      <td>ffffcc4e2331aaf1e41e</td>\n",
       "      <td>What other technical skills do you need as a computer science undergrad other than c and c++?</td>\n",
       "      <td>0</td>\n",
       "      <td>What other technical skills do you need as a computer science undergrad other than c and c + + ?</td>\n",
       "      <td>What other technical skills do you need as a computer science undergrad other than c and c++?</td>\n",
       "      <td>What other technical skills do you need as a computer science undergrad other than c and c + + ?</td>\n",
       "      <td>What other technical skills do you need as a computer science undergrad other than c and c + + ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306118</th>\n",
       "      <td>ffffd431801e5a2f4861</td>\n",
       "      <td>Does MS in ECE have good job prospects in USA or like India there are more IT jobs present?</td>\n",
       "      <td>0</td>\n",
       "      <td>Does MS in ECE have good job prospects in USA or like India there are more IT jobs present ?</td>\n",
       "      <td>Does MS in ECE have good job prospects in USA or like India there are more IT jobs present?</td>\n",
       "      <td>Does MS in ECE have good job prospects in USA or like India there are more IT jobs present ?</td>\n",
       "      <td>Does MS in ECE have good job prospects in USA or like India there are more IT jobs present ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306119</th>\n",
       "      <td>ffffd48fb36b63db010c</td>\n",
       "      <td>Is foam insulation toxic?</td>\n",
       "      <td>0</td>\n",
       "      <td>Is foam insulation toxic ?</td>\n",
       "      <td>Is foam insulation toxic?</td>\n",
       "      <td>Is foam insulation toxic ?</td>\n",
       "      <td>Is foam insulation toxic ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306120</th>\n",
       "      <td>ffffec519fa37cf60c78</td>\n",
       "      <td>How can one start a research project based on biochemistry at UG level?</td>\n",
       "      <td>0</td>\n",
       "      <td>How can one start a research project based on biochemistry at UG level ?</td>\n",
       "      <td>How can one start a research project based on biochemistry at UG level?</td>\n",
       "      <td>How can one start a research project based on biochemistry at UG level ?</td>\n",
       "      <td>How can one start a research project based on biochemistry at UG level ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306121</th>\n",
       "      <td>ffffed09fedb5088744a</td>\n",
       "      <td>Who wins in a battle between a Wolverine and a Puma?</td>\n",
       "      <td>0</td>\n",
       "      <td>Who wins in a battle between a Wolverine and a Puma ?</td>\n",
       "      <td>Who wins in a battle between a Wolverine and a Puma?</td>\n",
       "      <td>Who wins in a battle between a Wolverine and a Puma ?</td>\n",
       "      <td>Who wins in a battle between a Wolverine and a Puma ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1306122 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          qid  \\\n",
       "0        00002165364db923c7e6   \n",
       "1        000032939017120e6e44   \n",
       "2        0000412ca6e4628ce2cf   \n",
       "3        000042bf85aa498cd78e   \n",
       "4        0000455dfa3e01eae3af   \n",
       "...                       ...   \n",
       "1306117  ffffcc4e2331aaf1e41e   \n",
       "1306118  ffffd431801e5a2f4861   \n",
       "1306119  ffffd48fb36b63db010c   \n",
       "1306120  ffffec519fa37cf60c78   \n",
       "1306121  ffffed09fedb5088744a   \n",
       "\n",
       "                                                                                         question_text  \\\n",
       "0                             How did Quebec nationalists see their province as a nation in the 1960s?   \n",
       "1                    Do you have an adopted dog, how would you encourage people to adopt and not shop?   \n",
       "2                                  Why does velocity affect time? Does velocity affect space geometry?   \n",
       "3                                            How did Otto von Guericke used the Magdeburg hemispheres?   \n",
       "4                        Can I convert montra helicon D to a mountain bike by just changing the tyres?   \n",
       "...                                                                                                ...   \n",
       "1306117  What other technical skills do you need as a computer science undergrad other than c and c++?   \n",
       "1306118    Does MS in ECE have good job prospects in USA or like India there are more IT jobs present?   \n",
       "1306119                                                                      Is foam insulation toxic?   \n",
       "1306120                        How can one start a research project based on biochemistry at UG level?   \n",
       "1306121                                           Who wins in a battle between a Wolverine and a Puma?   \n",
       "\n",
       "         target  \\\n",
       "0             0   \n",
       "1             0   \n",
       "2             0   \n",
       "3             0   \n",
       "4             0   \n",
       "...         ...   \n",
       "1306117       0   \n",
       "1306118       0   \n",
       "1306119       0   \n",
       "1306120       0   \n",
       "1306121       0   \n",
       "\n",
       "                                                                                                punctques  \\\n",
       "0                               How did Quebec nationalists see their province as a nation in the 1960s ?   \n",
       "1                     Do you have an adopted dog , how would you encourage people to adopt and not shop ?   \n",
       "2                                   Why does velocity affect time ? Does velocity affect space geometry ?   \n",
       "3                                              How did Otto von Guericke used the Magdeburg hemispheres ?   \n",
       "4                          Can I convert montra helicon D to a mountain bike by just changing the tyres ?   \n",
       "...                                                                                                   ...   \n",
       "1306117  What other technical skills do you need as a computer science undergrad other than c and c + + ?   \n",
       "1306118      Does MS in ECE have good job prospects in USA or like India there are more IT jobs present ?   \n",
       "1306119                                                                        Is foam insulation toxic ?   \n",
       "1306120                          How can one start a research project based on biochemistry at UG level ?   \n",
       "1306121                                             Who wins in a battle between a Wolverine and a Puma ?   \n",
       "\n",
       "                                                                                             contrques  \\\n",
       "0                             How did Quebec nationalists see their province as a nation in the 1960s?   \n",
       "1                    Do you have an adopted dog, how would you encourage people to adopt and not shop?   \n",
       "2                                  Why does velocity affect time? Does velocity affect space geometry?   \n",
       "3                                            How did Otto von Guericke used the Magdeburg hemispheres?   \n",
       "4                        Can I convert montra helicon D to a mountain bike by just changing the tyres?   \n",
       "...                                                                                                ...   \n",
       "1306117  What other technical skills do you need as a computer science undergrad other than c and c++?   \n",
       "1306118    Does MS in ECE have good job prospects in USA or like India there are more IT jobs present?   \n",
       "1306119                                                                      Is foam insulation toxic?   \n",
       "1306120                        How can one start a research project based on biochemistry at UG level?   \n",
       "1306121                                           Who wins in a battle between a Wolverine and a Puma?   \n",
       "\n",
       "                                                                                                  transf1  \\\n",
       "0                               How did Quebec nationalists see their province as a nation in the 1960s ?   \n",
       "1                     Do you have an adopted dog , how would you encourage people to adopt and not shop ?   \n",
       "2                                   Why does velocity affect time ? Does velocity affect space geometry ?   \n",
       "3                                              How did Otto von Guericke used the Magdeburg hemispheres ?   \n",
       "4                          Can I convert montra helicon D to a mountain bike by just changing the tyres ?   \n",
       "...                                                                                                   ...   \n",
       "1306117  What other technical skills do you need as a computer science undergrad other than c and c + + ?   \n",
       "1306118      Does MS in ECE have good job prospects in USA or like India there are more IT jobs present ?   \n",
       "1306119                                                                        Is foam insulation toxic ?   \n",
       "1306120                          How can one start a research project based on biochemistry at UG level ?   \n",
       "1306121                                             Who wins in a battle between a Wolverine and a Puma ?   \n",
       "\n",
       "                                                                                                  transf2  \n",
       "0                               How did Quebec nationalists see their province as a nation in the 1960s ?  \n",
       "1                     Do you have an adopted dog , how would you encourage people to adopt and not shop ?  \n",
       "2                                   Why does velocity affect time ? Does velocity affect space geometry ?  \n",
       "3                                              How did Otto von Guericke used the Magdeburg hemispheres ?  \n",
       "4                          Can I convert montra helicon D to a mountain bike by just changing the tyres ?  \n",
       "...                                                                                                   ...  \n",
       "1306117  What other technical skills do you need as a computer science undergrad other than c and c + + ?  \n",
       "1306118      Does MS in ECE have good job prospects in USA or like India there are more IT jobs present ?  \n",
       "1306119                                                                        Is foam insulation toxic ?  \n",
       "1306120                          How can one start a research project based on biochemistry at UG level ?  \n",
       "1306121                                             Who wins in a battle between a Wolverine and a Puma ?  \n",
       "\n",
       "[1306122 rows x 7 columns]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transforming sentence to correct bracket format\n",
    "insin['transf2'] = insin['transf1'].apply(lambda x: brackets(x))\n",
    "insin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T09:13:59.481035Z",
     "start_time": "2020-04-07T09:13:49.112725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For original training file:\n",
      "Found embeddings for 58.90% of vocab\n",
      "Found embeddings for  98.88% of all text\n"
     ]
    }
   ],
   "source": [
    "# Checking coverage\n",
    "vocab3=build_vocab(insin['transf2'])\n",
    "print('For original training file:')\n",
    "oov_glove3=check_coverage(vocab3, embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T09:13:59.489979Z",
     "start_time": "2020-04-07T09:13:59.482997Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('\"The', 2245),\n",
       " ('/math', 966),\n",
       " ('Quorans', 872),\n",
       " ('.g', 849),\n",
       " ('\"I', 704),\n",
       " ('.e', 655),\n",
       " ('cryptocurrencies', 479),\n",
       " ('Brexit', 461),\n",
       " ('\"the', 446),\n",
       " ('Redmi', 376),\n",
       " ('.S', 361),\n",
       " ('Quoras', 285),\n",
       " ('.A', 262),\n",
       " ('f(', 259),\n",
       " ('\"A', 244),\n",
       " ('$100', 200),\n",
       " ('\"a', 199),\n",
       " (\"'The\", 187),\n",
       " ('.I', 183),\n",
       " ('$1', 178)]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking top uncovered words\n",
    "oov_glove3[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T09:17:35.118388Z",
     "start_time": "2020-04-07T09:17:24.532728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For original training file:\n",
      "Found embeddings for 58.90% of vocab\n",
      "Found embeddings for  98.89% of all text\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('/math', 966),\n",
       " ('Quorans', 872),\n",
       " ('.g', 849),\n",
       " ('\"I', 704),\n",
       " ('.e', 655),\n",
       " ('cryptocurrencies', 479),\n",
       " ('Brexit', 461),\n",
       " ('\"the', 446),\n",
       " ('Redmi', 376),\n",
       " ('.S', 361),\n",
       " ('Quoras', 285),\n",
       " ('.A', 262),\n",
       " ('f(', 259),\n",
       " ('\"A', 244),\n",
       " ('$100', 200),\n",
       " ('\"a', 199),\n",
       " ('.I', 183),\n",
       " ('$1', 178),\n",
       " ('.K', 177),\n",
       " ('.E', 172)]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handling words in quotes or inverted commas, transforming and checking top uncovered words\n",
    "def the(x):\n",
    "    x=x.replace('\"The','\" The')\n",
    "    x=x.replace(\"'The\",\"' The\")\n",
    "    return(x)\n",
    "insin['transf3'] = insin['transf2'].apply(lambda x: the(x))\n",
    "vocab3=build_vocab(insin['transf3'])\n",
    "print('For original training file:')\n",
    "oov_glove3=check_coverage(vocab3, embeddings_index)\n",
    "oov_glove3[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T09:23:29.202988Z",
     "start_time": "2020-04-07T09:23:29.196007Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cleaning all puncutations formatting\n",
    "punct_mapping = {\"‘\": \"'\", \"₹\": \"Rupee\", \"´\": \"'\", \"°\": \"\", \"€\": \"e\", \"™\": \"tm\", \"√\": \" sqrt \", \"×\": \"x\", \"²\": \"2\", \n",
    "                 \"—\": \"-\", \"–\": \"-\", \"’\": \"'\", \"_\": \"-\", \"`\": \"'\", '“': '\"', '”': '\"', '“': '\"', \"£\": \"e\", \n",
    "                 '∞': 'infinity', 'θ': 'theta', '÷': '/', 'α': 'alpha', '•': '.', 'à': 'a', '−': '-', 'β': 'beta', \n",
    "                 '∅': '', '³': '3', 'π': 'pi', }\n",
    "punct = \"/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~\" + '\"\"“”’' + '∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—–&'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T09:23:58.274594Z",
     "start_time": "2020-04-07T09:23:29.405984Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For original training file:\n",
      "Found embeddings for 73.74% of vocab\n",
      "Found embeddings for  99.54% of all text\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Quorans', 878),\n",
       " ('Brexit', 492),\n",
       " ('cryptocurrencies', 481),\n",
       " ('Redmi', 378),\n",
       " ('Quoras', 289),\n",
       " ('OnePlus', 125),\n",
       " ('UCEED', 123),\n",
       " ('Blockchain', 111),\n",
       " ('GDPR', 107),\n",
       " ('demonetisation', 106),\n",
       " ('Coinbase', 104),\n",
       " ('SJWs', 103),\n",
       " ('BNBR', 99),\n",
       " ('Adityanath', 93),\n",
       " ('ethereum', 87),\n",
       " ('DCEU', 87),\n",
       " ('Boruto', 87),\n",
       " ('IIEST', 85),\n",
       " ('Qoura', 79),\n",
       " ('Machedo', 78)]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_special_chars(text,punct,mapping):\n",
    "    for p in mapping:\n",
    "        text=text.replace(p,mapping[p])\n",
    "    for p in punct:\n",
    "        text=text.replace(p,f' {p} ')\n",
    "    return text\n",
    "insin['transf4']=insin['transf3'].apply(lambda x:clean_special_chars(x,punct,punct_mapping))\n",
    "vocab3=build_vocab(insin['transf4'])\n",
    "print('For original training file:')\n",
    "oov_glove3=check_coverage(vocab3,embeddings_index)\n",
    "oov_glove3[:20]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T09:55:53.926209Z",
     "start_time": "2020-04-07T09:55:53.917261Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dictionary to correct mispellings\n",
    "mispell_dict = {'colour': 'color', 'centre': 'center', 'favourite': 'favorite', 'travelling': 'traveling', \n",
    "                'counselling': 'counseling', 'theatre': 'theater', 'cancelled': 'canceled', 'labour': 'labor', \n",
    "                'organisation': 'organization', 'wwii': 'world war 2', 'citicise': 'criticize', \n",
    "                'youtu ': 'youtube ', 'Qoura': 'Quora', 'sallary': 'salary', 'Whta': 'What', \n",
    "                'narcisist': 'narcissist', 'howdo': 'how do', 'whatare': 'what are', 'howcan': 'how can', \n",
    "                'howmuch': 'how much', 'howmany': 'how many', 'whydo': 'why do', 'doI': 'do I', \n",
    "                'theBest': 'the best', 'howdoes': 'how does', 'mastrubation': 'masturbation', \n",
    "                'mastrubate': 'masturbate', \"mastrubating\": 'masturbating', 'pennis': 'penis', \n",
    "                'Etherium': 'Ethereum', 'narcissit': 'narcissist', 'bigdata': 'big data', '2k17': '2017', \n",
    "                '2k18': '2018', 'qouta': 'quota', 'exboyfriend': 'ex boyfriend', 'airhostess': 'air hostess', \n",
    "                \"whst\": 'what', 'watsapp': 'whatsapp', 'demonitisation': 'demonetization', \n",
    "                'demonitization': 'demonetization', 'demonetisation': 'demonetization',\n",
    "                'Cryptocurrency':'Crypto currency','cryptocurrencies':'crypto currencies','Quorans':\"Quora people\",\n",
    "                'GDPR':\"General Data Protection Regulation\",\"SJWs\":\"Social Justice Warriors\",\n",
    "                \"TensorFlow\":\"Tensor Flow\",\"BNBR\":\"Be Nice Be Respectful\",\"Jesuss\":\"Jesus\",\n",
    "                \"microservices\":\"micro services\",\"hyperloop\":\"hyper loop\",\"Brexit\":\"British exit\",\"brexit\":\"british exit\",\n",
    "                \"Redmi\":\"Chinese mobile company\",\"OnePlus\":\"Chinese mobile company\",\"redmi\":\"chinese mobile company\",\n",
    "                'fortnite':'shooting game','pubg':'shooting game','PUBG':'shooting game','Fortnite':'shooting game',\n",
    "                \"Adhaar\":\"Aadhaar\",'adhaar':\"Aadhaar\",'Demonetization':'demonetization','Whst':\"What\",\n",
    "                'Blockchain':'blockchain','Quoras':'Quora','AAadhaar':'Aadhaar'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T09:56:20.030378Z",
     "start_time": "2020-04-07T09:55:54.082731Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For original training file:\n",
      "Found embeddings for 73.74% of vocab\n",
      "Found embeddings for  99.56% of all text\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('UCEED', 123),\n",
       " ('Coinbase', 104),\n",
       " ('Adityanath', 93),\n",
       " ('ethereum', 87),\n",
       " ('DCEU', 87),\n",
       " ('Boruto', 87),\n",
       " ('IIEST', 85),\n",
       " ('Machedo', 78),\n",
       " ('Upwork', 70),\n",
       " ('BJPs', 69),\n",
       " ('LNMIIT', 67),\n",
       " ('bhakts', 64),\n",
       " ('Zerodha', 63),\n",
       " ('Doklam', 62),\n",
       " ('NICMAR', 59),\n",
       " ('Unacademy', 58),\n",
       " ('Vajiram', 57),\n",
       " ('Kavalireddis', 57),\n",
       " ('MUOET', 56),\n",
       " ('chsl', 55)]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correcting spellings using above dictionary\n",
    "def correct_spelling(x,dic):\n",
    "    for word in dic.keys():\n",
    "        x=x.replace(word,dic[word])\n",
    "    return x\n",
    "insin['transf5']=insin['transf4'].apply(lambda x:correct_spelling(x,mispell_dict))\n",
    "vocab3=build_vocab(insin['transf5'])\n",
    "print('For original training file:')\n",
    "oov_glove3=check_coverage(vocab3,embeddings_index)\n",
    "oov_glove3[:20]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T10:19:35.344144Z",
     "start_time": "2020-04-07T10:18:58.590823Z"
    }
   },
   "outputs": [],
   "source": [
    "# Saving the processed text\n",
    "insin.to_csv(r'D:\\DS\\NLP\\quora-insincere-questions-classification\\embedprocessed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the processed file for future usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading processed file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T18:36:00.851952Z",
     "start_time": "2020-04-09T18:35:52.759039Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config=ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "session=InteractiveSession(config=config)\n",
    "import sklearn.metrics as metrics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T18:36:14.255089Z",
     "start_time": "2020-04-09T18:36:00.851952Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "      <th>punctques</th>\n",
       "      <th>contrques</th>\n",
       "      <th>transf1</th>\n",
       "      <th>transf2</th>\n",
       "      <th>transf3</th>\n",
       "      <th>transf4</th>\n",
       "      <th>transf5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "      <td>Do you have an adopted dog , how would you enc...</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>Do you have an adopted dog , how would you enc...</td>\n",
       "      <td>Do you have an adopted dog , how would you enc...</td>\n",
       "      <td>Do you have an adopted dog , how would you enc...</td>\n",
       "      <td>Do you have an adopted dog  ,  how would you e...</td>\n",
       "      <td>Do you have an adopted dog  ,  how would you e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "      <td>Why does velocity affect time ? Does velocity ...</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>Why does velocity affect time ? Does velocity ...</td>\n",
       "      <td>Why does velocity affect time ? Does velocity ...</td>\n",
       "      <td>Why does velocity affect time ? Does velocity ...</td>\n",
       "      <td>Why does velocity affect time  ?  Does velocit...</td>\n",
       "      <td>Why does velocity affect time  ?  Does velocit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                   qid  \\\n",
       "0           0  00002165364db923c7e6   \n",
       "1           1  000032939017120e6e44   \n",
       "2           2  0000412ca6e4628ce2cf   \n",
       "3           3  000042bf85aa498cd78e   \n",
       "4           4  0000455dfa3e01eae3af   \n",
       "\n",
       "                                       question_text  target  \\\n",
       "0  How did Quebec nationalists see their province...       0   \n",
       "1  Do you have an adopted dog, how would you enco...       0   \n",
       "2  Why does velocity affect time? Does velocity a...       0   \n",
       "3  How did Otto von Guericke used the Magdeburg h...       0   \n",
       "4  Can I convert montra helicon D to a mountain b...       0   \n",
       "\n",
       "                                           punctques  \\\n",
       "0  How did Quebec nationalists see their province...   \n",
       "1  Do you have an adopted dog , how would you enc...   \n",
       "2  Why does velocity affect time ? Does velocity ...   \n",
       "3  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "                                           contrques  \\\n",
       "0  How did Quebec nationalists see their province...   \n",
       "1  Do you have an adopted dog, how would you enco...   \n",
       "2  Why does velocity affect time? Does velocity a...   \n",
       "3  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "                                             transf1  \\\n",
       "0  How did Quebec nationalists see their province...   \n",
       "1  Do you have an adopted dog , how would you enc...   \n",
       "2  Why does velocity affect time ? Does velocity ...   \n",
       "3  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "                                             transf2  \\\n",
       "0  How did Quebec nationalists see their province...   \n",
       "1  Do you have an adopted dog , how would you enc...   \n",
       "2  Why does velocity affect time ? Does velocity ...   \n",
       "3  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "                                             transf3  \\\n",
       "0  How did Quebec nationalists see their province...   \n",
       "1  Do you have an adopted dog , how would you enc...   \n",
       "2  Why does velocity affect time ? Does velocity ...   \n",
       "3  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "                                             transf4  \\\n",
       "0  How did Quebec nationalists see their province...   \n",
       "1  Do you have an adopted dog  ,  how would you e...   \n",
       "2  Why does velocity affect time  ?  Does velocit...   \n",
       "3  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "                                             transf5  \n",
       "0  How did Quebec nationalists see their province...  \n",
       "1  Do you have an adopted dog  ,  how would you e...  \n",
       "2  Why does velocity affect time  ?  Does velocit...  \n",
       "3  How did Otto von Guericke used the Magdeburg h...  \n",
       "4  Can I convert montra helicon D to a mountain b...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insinemb=pd.read_csv(r'D:\\DS\\NLP\\quora-insincere-questions-classification\\embedprocessed.csv')\n",
    "insinemb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T18:36:16.395175Z",
     "start_time": "2020-04-09T18:36:14.255089Z"
    }
   },
   "outputs": [],
   "source": [
    "# Splitting loaded file\n",
    "train=insinemb.sample(frac=0.8,random_state=49) #random state is a seed value\n",
    "test=insinemb.drop(train.index)\n",
    "train=train[['transf5','target']]\n",
    "test=test[['transf5','target']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T18:36:36.397628Z",
     "start_time": "2020-04-09T18:36:16.395175Z"
    }
   },
   "outputs": [],
   "source": [
    "# Using keras tokenizer and fitting on our text\n",
    "tokenizer=tf.keras.preprocessing.text.Tokenizer(num_words=50000)\n",
    "tokenizer.fit_on_texts(list(train.transf5.values)+list(test.transf5.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T18:36:53.596979Z",
     "start_time": "2020-04-09T18:36:36.397628Z"
    }
   },
   "outputs": [],
   "source": [
    "# Converting our text to sequence of tokens\n",
    "train1=tokenizer.texts_to_sequences(train.transf5.values)\n",
    "test1=tokenizer.texts_to_sequences(test.transf5.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T18:36:58.689289Z",
     "start_time": "2020-04-09T18:36:53.596979Z"
    }
   },
   "outputs": [],
   "source": [
    "# Adjusting length of questions so that all are of same length\n",
    "train1=tf.keras.preprocessing.sequence.pad_sequences(train1, maxlen=100)\n",
    "test1=tf.keras.preprocessing.sequence.pad_sequences(test1, maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T18:40:11.833415Z",
     "start_time": "2020-04-09T18:36:58.689289Z"
    }
   },
   "outputs": [],
   "source": [
    "#Loading glove embeddings\n",
    "glove=r'D:\\DS\\NLP\\quora-insincere-questions-classification\\embeddings\\glove.840B.300d\\glove.840B.300d.txt'\n",
    "f=open(glove,encoding=\"utf8\")\n",
    "embeddings_index={line.split(\" \")[0]:np.array(line.split(\" \")[1:],dtype=np.float32) for line in f}\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T18:40:18.066288Z",
     "start_time": "2020-04-09T18:40:11.833415Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\Anaconda\\envs\\nlp\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3254: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "# Getting properties of embeddings -in case word not found in the embedding space it will generate a random vector\n",
    "# based on mean and std of the input Embedding space and this can be used to feed word2vec/glove to the \n",
    "# embedding layer of keras\n",
    "all_embs=np.stack(embeddings_index.values())\n",
    "emb_mean,emb_std=all_embs.mean(),all_embs.std()\n",
    "embed_size=all_embs.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T18:40:18.488313Z",
     "start_time": "2020-04-09T18:40:18.066288Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generating a random matrix to take missing words values\n",
    "word_index=tokenizer.word_index\n",
    "nb_words=min(50000, len(word_index))\n",
    "embedding_matrix=np.random.normal(emb_mean,emb_std,(nb_words, embed_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T18:40:18.597674Z",
     "start_time": "2020-04-09T18:40:18.488313Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filling matrix with corresponding embedding vector from glove\n",
    "for word,i in word_index.items():\n",
    "    if i>=50000: \n",
    "        continue\n",
    "    embedding_vector=embeddings_index.get(word)\n",
    "    if embedding_vector is not None: \n",
    "        embedding_matrix[i]=embedding_vector    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T18:40:19.847120Z",
     "start_time": "2020-04-09T18:40:18.597674Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Freeing memory\n",
    "del tokenizer,embeddings_index,all_embs,word_index,insinemb,f\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T18:40:22.320644Z",
     "start_time": "2020-04-09T18:40:19.847120Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 100, 300)          15000000  \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 100, 256)          440320    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                4112      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 15,444,449\n",
      "Trainable params: 15,444,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Model architecture- changing the number of hidden units and dropout didnt affect the output too much\n",
    "inp=tf.keras.layers.Input(shape=(100,))\n",
    "x=tf.keras.layers.Embedding(50000, embed_size, weights=[embedding_matrix])(inp)\n",
    "x=tf.keras.layers.Bidirectional(tf.compat.v1.keras.layers.CuDNNLSTM(128,return_sequences=True))(x)\n",
    "x=tf.keras.layers.GlobalMaxPool1D()(x)\n",
    "x=tf.keras.layers.Dense(16, activation=\"relu\")(x)\n",
    "x=tf.keras.layers.Dropout(0.1)(x)\n",
    "x=tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model=tf.keras.models.Model(inputs=inp, outputs=x)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T18:09:54.295982Z",
     "start_time": "2020-04-09T18:09:54.265239Z"
    }
   },
   "outputs": [],
   "source": [
    "# Class weights to take care of imbalance\n",
    "class_weight = {0: 1.,1: 10.}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T18:30:13.910510Z",
     "start_time": "2020-04-09T18:09:55.030129Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 1044898 samples, validate on 261224 samples\n",
      "Epoch 1/2\n",
      "1044898/1044898 [==============================] - 617s 591us/sample - loss: 0.4113 - accuracy: 0.9102 - val_loss: 0.3563 - val_accuracy: 0.9249\n",
      "Epoch 2/2\n",
      "1044898/1044898 [==============================] - 600s 574us/sample - loss: 0.3159 - accuracy: 0.9265 - val_loss: 0.3634 - val_accuracy: 0.9193\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2b7a0bca6c8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train1,train['target'],workers=6,class_weight=class_weight,max_queue_size=25,batch_size=512,verbose=1,epochs=2,validation_data=(test1,test['target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T09:54:22.815147Z",
     "start_time": "2020-04-09T09:54:18.956873Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save_weights(r'D:\\DS\\NLP\\quora-insincere-questions-classification\\modelwtv1.hdf5v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T18:33:23.213270Z",
     "start_time": "2020-04-09T18:31:32.813962Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum Test F1 score: 0.674\n"
     ]
    }
   ],
   "source": [
    "#Model v0- 100 max sentence length and total 50000 words\n",
    "search_result = threshold_search(test['target'], model.predict(test1))\n",
    "print('Optimum Test F1 score:',round(search_result['f1'],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T15:11:10.980417Z",
     "start_time": "2020-04-09T15:09:22.152854Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum Test F1 score: 0.671\n"
     ]
    }
   ],
   "source": [
    "#Model v1- 150 max sentence length and total 75000 words\n",
    "search_result = threshold_search(test['target'], model.predict(test1))\n",
    "print('Optimum Test F1 score:',round(search_result['f1'],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T09:56:45.689992Z",
     "start_time": "2020-04-09T09:54:56.544001Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum Test F1 score: 0.678\n"
     ]
    }
   ],
   "source": [
    "#Model v3- 200 max sentence length and total 100000 words\n",
    "search_result = threshold_search(test['target'], model.predict(test1))\n",
    "print('Optimum Test F1 score:',round(search_result['f1'],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T14:18:26.403963Z",
     "start_time": "2020-04-09T14:13:38.410006Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1.1.1</th>\n",
       "      <th>target</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>L1</th>\n",
       "      <th>GBM1</th>\n",
       "      <th>L2</th>\n",
       "      <th>GBM2</th>\n",
       "      <th>V0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172360</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.027577</td>\n",
       "      <td>0.007062</td>\n",
       "      <td>0.023413</td>\n",
       "      <td>0.013476</td>\n",
       "      <td>0.010037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>188522</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.022630</td>\n",
       "      <td>0.006376</td>\n",
       "      <td>0.015940</td>\n",
       "      <td>0.007689</td>\n",
       "      <td>0.000088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1235537</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.055480</td>\n",
       "      <td>0.073269</td>\n",
       "      <td>0.087146</td>\n",
       "      <td>0.089432</td>\n",
       "      <td>0.000321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>345543</td>\n",
       "      <td>0</td>\n",
       "      <td>0.101580</td>\n",
       "      <td>0.057472</td>\n",
       "      <td>0.688056</td>\n",
       "      <td>0.789218</td>\n",
       "      <td>0.618124</td>\n",
       "      <td>0.782704</td>\n",
       "      <td>0.712448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>566414</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.123943</td>\n",
       "      <td>0.066225</td>\n",
       "      <td>0.050635</td>\n",
       "      <td>0.096038</td>\n",
       "      <td>0.002988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044893</th>\n",
       "      <td>1044893</td>\n",
       "      <td>1044893</td>\n",
       "      <td>1044893</td>\n",
       "      <td>1044893</td>\n",
       "      <td>1044893</td>\n",
       "      <td>1180555</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010346</td>\n",
       "      <td>0.009663</td>\n",
       "      <td>0.090877</td>\n",
       "      <td>0.061587</td>\n",
       "      <td>0.102847</td>\n",
       "      <td>0.043326</td>\n",
       "      <td>0.157966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044894</th>\n",
       "      <td>1044894</td>\n",
       "      <td>1044894</td>\n",
       "      <td>1044894</td>\n",
       "      <td>1044894</td>\n",
       "      <td>1044894</td>\n",
       "      <td>155574</td>\n",
       "      <td>1</td>\n",
       "      <td>0.230059</td>\n",
       "      <td>0.198934</td>\n",
       "      <td>0.832992</td>\n",
       "      <td>0.862744</td>\n",
       "      <td>0.708256</td>\n",
       "      <td>0.929677</td>\n",
       "      <td>0.666673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044895</th>\n",
       "      <td>1044895</td>\n",
       "      <td>1044895</td>\n",
       "      <td>1044895</td>\n",
       "      <td>1044895</td>\n",
       "      <td>1044895</td>\n",
       "      <td>1130815</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.045584</td>\n",
       "      <td>0.058104</td>\n",
       "      <td>0.003764</td>\n",
       "      <td>0.021941</td>\n",
       "      <td>0.003667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044896</th>\n",
       "      <td>1044896</td>\n",
       "      <td>1044896</td>\n",
       "      <td>1044896</td>\n",
       "      <td>1044896</td>\n",
       "      <td>1044896</td>\n",
       "      <td>107187</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.076284</td>\n",
       "      <td>0.073334</td>\n",
       "      <td>0.098819</td>\n",
       "      <td>0.109336</td>\n",
       "      <td>0.002866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044897</th>\n",
       "      <td>1044897</td>\n",
       "      <td>1044897</td>\n",
       "      <td>1044897</td>\n",
       "      <td>1044897</td>\n",
       "      <td>1044897</td>\n",
       "      <td>856532</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.063408</td>\n",
       "      <td>0.025247</td>\n",
       "      <td>0.069858</td>\n",
       "      <td>0.037498</td>\n",
       "      <td>0.000967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1044898 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  Unnamed: 0.1.1.1  \\\n",
       "0                 0             0               0                 0   \n",
       "1                 1             1               1                 1   \n",
       "2                 2             2               2                 2   \n",
       "3                 3             3               3                 3   \n",
       "4                 4             4               4                 4   \n",
       "...             ...           ...             ...               ...   \n",
       "1044893     1044893       1044893         1044893           1044893   \n",
       "1044894     1044894       1044894         1044894           1044894   \n",
       "1044895     1044895       1044895         1044895           1044895   \n",
       "1044896     1044896       1044896         1044896           1044896   \n",
       "1044897     1044897       1044897         1044897           1044897   \n",
       "\n",
       "         Unnamed: 0.1.1.1.1  Unnamed: 0.1.1.1.1.1  target        V2        V3  \\\n",
       "0                         0                172360       0  0.000468  0.000433   \n",
       "1                         1                188522       0  0.000012  0.000023   \n",
       "2                         2               1235537       0  0.000025  0.000038   \n",
       "3                         3                345543       0  0.101580  0.057472   \n",
       "4                         4                566414       0  0.000258  0.000345   \n",
       "...                     ...                   ...     ...       ...       ...   \n",
       "1044893             1044893               1180555       0  0.010346  0.009663   \n",
       "1044894             1044894                155574       1  0.230059  0.198934   \n",
       "1044895             1044895               1130815       0  0.000239  0.000407   \n",
       "1044896             1044896                107187       0  0.000489  0.000237   \n",
       "1044897             1044897                856532       0  0.000066  0.000156   \n",
       "\n",
       "               L1      GBM1        L2      GBM2        V0  \n",
       "0        0.027577  0.007062  0.023413  0.013476  0.010037  \n",
       "1        0.022630  0.006376  0.015940  0.007689  0.000088  \n",
       "2        0.055480  0.073269  0.087146  0.089432  0.000321  \n",
       "3        0.688056  0.789218  0.618124  0.782704  0.712448  \n",
       "4        0.123943  0.066225  0.050635  0.096038  0.002988  \n",
       "...           ...       ...       ...       ...       ...  \n",
       "1044893  0.090877  0.061587  0.102847  0.043326  0.157966  \n",
       "1044894  0.832992  0.862744  0.708256  0.929677  0.666673  \n",
       "1044895  0.045584  0.058104  0.003764  0.021941  0.003667  \n",
       "1044896  0.076284  0.073334  0.098819  0.109336  0.002866  \n",
       "1044897  0.063408  0.025247  0.069858  0.037498  0.000967  \n",
       "\n",
       "[1044898 rows x 14 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving predictions for ensembling at end\n",
    "trainmodelsop=pd.read_csv(r'D:\\DS\\NLP\\quora-insincere-questions-classification\\trainmodeloutputs.csv')\n",
    "trainmodelsop['V0']=model.predict(train1)\n",
    "trainmodelsop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T14:18:38.791715Z",
     "start_time": "2020-04-09T14:18:26.403963Z"
    }
   },
   "outputs": [],
   "source": [
    "trainmodelsop.to_csv(r'D:\\DS\\NLP\\quora-insincere-questions-classification\\trainmodeloutputs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T14:19:49.680236Z",
     "start_time": "2020-04-09T14:18:38.791715Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1.1.1</th>\n",
       "      <th>target</th>\n",
       "      <th>V1</th>\n",
       "      <th>V3</th>\n",
       "      <th>L1</th>\n",
       "      <th>GBM1</th>\n",
       "      <th>L2</th>\n",
       "      <th>GBM2</th>\n",
       "      <th>V0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024300</td>\n",
       "      <td>0.022419</td>\n",
       "      <td>0.507896</td>\n",
       "      <td>0.302853</td>\n",
       "      <td>0.301129</td>\n",
       "      <td>0.327991</td>\n",
       "      <td>0.277927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.003438</td>\n",
       "      <td>0.120155</td>\n",
       "      <td>0.117613</td>\n",
       "      <td>0.111000</td>\n",
       "      <td>0.113504</td>\n",
       "      <td>0.063507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.068159</td>\n",
       "      <td>0.045665</td>\n",
       "      <td>0.042989</td>\n",
       "      <td>0.043656</td>\n",
       "      <td>0.003373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.034296</td>\n",
       "      <td>0.016712</td>\n",
       "      <td>0.023646</td>\n",
       "      <td>0.012958</td>\n",
       "      <td>0.003712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0.096897</td>\n",
       "      <td>0.107733</td>\n",
       "      <td>0.325269</td>\n",
       "      <td>0.217999</td>\n",
       "      <td>0.310578</td>\n",
       "      <td>0.259091</td>\n",
       "      <td>0.531536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261219</th>\n",
       "      <td>261219</td>\n",
       "      <td>261219</td>\n",
       "      <td>261219</td>\n",
       "      <td>261219</td>\n",
       "      <td>261219</td>\n",
       "      <td>1306100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.034349</td>\n",
       "      <td>0.062328</td>\n",
       "      <td>0.392208</td>\n",
       "      <td>0.501407</td>\n",
       "      <td>0.384330</td>\n",
       "      <td>0.524310</td>\n",
       "      <td>0.679393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261220</th>\n",
       "      <td>261220</td>\n",
       "      <td>261220</td>\n",
       "      <td>261220</td>\n",
       "      <td>261220</td>\n",
       "      <td>261220</td>\n",
       "      <td>1306101</td>\n",
       "      <td>0</td>\n",
       "      <td>0.371634</td>\n",
       "      <td>0.523747</td>\n",
       "      <td>0.762480</td>\n",
       "      <td>0.874843</td>\n",
       "      <td>0.703858</td>\n",
       "      <td>0.897279</td>\n",
       "      <td>0.898019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261221</th>\n",
       "      <td>261221</td>\n",
       "      <td>261221</td>\n",
       "      <td>261221</td>\n",
       "      <td>261221</td>\n",
       "      <td>261221</td>\n",
       "      <td>1306110</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004838</td>\n",
       "      <td>0.008398</td>\n",
       "      <td>0.139296</td>\n",
       "      <td>0.060111</td>\n",
       "      <td>0.064519</td>\n",
       "      <td>0.079674</td>\n",
       "      <td>0.024798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261222</th>\n",
       "      <td>261222</td>\n",
       "      <td>261222</td>\n",
       "      <td>261222</td>\n",
       "      <td>261222</td>\n",
       "      <td>261222</td>\n",
       "      <td>1306111</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009653</td>\n",
       "      <td>0.031900</td>\n",
       "      <td>0.207141</td>\n",
       "      <td>0.084060</td>\n",
       "      <td>0.030491</td>\n",
       "      <td>0.161251</td>\n",
       "      <td>0.026265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261223</th>\n",
       "      <td>261223</td>\n",
       "      <td>261223</td>\n",
       "      <td>261223</td>\n",
       "      <td>261223</td>\n",
       "      <td>261223</td>\n",
       "      <td>1306120</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.023978</td>\n",
       "      <td>0.013343</td>\n",
       "      <td>0.010014</td>\n",
       "      <td>0.010956</td>\n",
       "      <td>0.000096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>261224 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  Unnamed: 0.1.1.1  \\\n",
       "0                0             0               0                 0   \n",
       "1                1             1               1                 1   \n",
       "2                2             2               2                 2   \n",
       "3                3             3               3                 3   \n",
       "4                4             4               4                 4   \n",
       "...            ...           ...             ...               ...   \n",
       "261219      261219        261219          261219            261219   \n",
       "261220      261220        261220          261220            261220   \n",
       "261221      261221        261221          261221            261221   \n",
       "261222      261222        261222          261222            261222   \n",
       "261223      261223        261223          261223            261223   \n",
       "\n",
       "        Unnamed: 0.1.1.1.1  Unnamed: 0.1.1.1.1.1  target        V1        V3  \\\n",
       "0                        0                    10       0  0.024300  0.022419   \n",
       "1                        1                    15       0  0.000732  0.003438   \n",
       "2                        2                    16       0  0.000131  0.000277   \n",
       "3                        3                    21       0  0.000191  0.000143   \n",
       "4                        4                    22       1  0.096897  0.107733   \n",
       "...                    ...                   ...     ...       ...       ...   \n",
       "261219              261219               1306100       0  0.034349  0.062328   \n",
       "261220              261220               1306101       0  0.371634  0.523747   \n",
       "261221              261221               1306110       0  0.004838  0.008398   \n",
       "261222              261222               1306111       0  0.009653  0.031900   \n",
       "261223              261223               1306120       0  0.000023  0.000031   \n",
       "\n",
       "              L1      GBM1        L2      GBM2        V0  \n",
       "0       0.507896  0.302853  0.301129  0.327991  0.277927  \n",
       "1       0.120155  0.117613  0.111000  0.113504  0.063507  \n",
       "2       0.068159  0.045665  0.042989  0.043656  0.003373  \n",
       "3       0.034296  0.016712  0.023646  0.012958  0.003712  \n",
       "4       0.325269  0.217999  0.310578  0.259091  0.531536  \n",
       "...          ...       ...       ...       ...       ...  \n",
       "261219  0.392208  0.501407  0.384330  0.524310  0.679393  \n",
       "261220  0.762480  0.874843  0.703858  0.897279  0.898019  \n",
       "261221  0.139296  0.060111  0.064519  0.079674  0.024798  \n",
       "261222  0.207141  0.084060  0.030491  0.161251  0.026265  \n",
       "261223  0.023978  0.013343  0.010014  0.010956  0.000096  \n",
       "\n",
       "[261224 rows x 14 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving predictions for ensembling at end\n",
    "testmodelsop=pd.read_csv(r'D:\\DS\\NLP\\quora-insincere-questions-classification\\testmodeloutputs.csv')\n",
    "testmodelsop['V0']=model.predict(test1)\n",
    "testmodelsop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T14:19:52.788884Z",
     "start_time": "2020-04-09T14:19:49.680236Z"
    }
   },
   "outputs": [],
   "source": [
    "testmodelsop.to_csv(r'D:\\DS\\NLP\\quora-insincere-questions-classification\\testmodeloutputs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combined Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T02:28:50.106594Z",
     "start_time": "2020-04-10T02:28:48.432752Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>L1</th>\n",
       "      <th>L2</th>\n",
       "      <th>GBM1</th>\n",
       "      <th>GBM2</th>\n",
       "      <th>V0</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.027577</td>\n",
       "      <td>0.023413</td>\n",
       "      <td>0.007062</td>\n",
       "      <td>0.013476</td>\n",
       "      <td>0.010037</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.022630</td>\n",
       "      <td>0.015940</td>\n",
       "      <td>0.006376</td>\n",
       "      <td>0.007689</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.055480</td>\n",
       "      <td>0.087146</td>\n",
       "      <td>0.073269</td>\n",
       "      <td>0.089432</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.101580</td>\n",
       "      <td>0.057472</td>\n",
       "      <td>0.688056</td>\n",
       "      <td>0.618124</td>\n",
       "      <td>0.789218</td>\n",
       "      <td>0.782704</td>\n",
       "      <td>0.712448</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.123943</td>\n",
       "      <td>0.050635</td>\n",
       "      <td>0.066225</td>\n",
       "      <td>0.096038</td>\n",
       "      <td>0.002988</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044893</th>\n",
       "      <td>0.010346</td>\n",
       "      <td>0.009663</td>\n",
       "      <td>0.090877</td>\n",
       "      <td>0.102847</td>\n",
       "      <td>0.061587</td>\n",
       "      <td>0.043326</td>\n",
       "      <td>0.157966</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044894</th>\n",
       "      <td>0.230059</td>\n",
       "      <td>0.198934</td>\n",
       "      <td>0.832992</td>\n",
       "      <td>0.708256</td>\n",
       "      <td>0.862744</td>\n",
       "      <td>0.929677</td>\n",
       "      <td>0.666673</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044895</th>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.045584</td>\n",
       "      <td>0.003764</td>\n",
       "      <td>0.058104</td>\n",
       "      <td>0.021941</td>\n",
       "      <td>0.003667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044896</th>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.076284</td>\n",
       "      <td>0.098819</td>\n",
       "      <td>0.073334</td>\n",
       "      <td>0.109336</td>\n",
       "      <td>0.002866</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044897</th>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.063408</td>\n",
       "      <td>0.069858</td>\n",
       "      <td>0.025247</td>\n",
       "      <td>0.037498</td>\n",
       "      <td>0.000967</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1044898 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               V2        V3        L1        L2      GBM1      GBM2        V0  \\\n",
       "0        0.000468  0.000433  0.027577  0.023413  0.007062  0.013476  0.010037   \n",
       "1        0.000012  0.000023  0.022630  0.015940  0.006376  0.007689  0.000088   \n",
       "2        0.000025  0.000038  0.055480  0.087146  0.073269  0.089432  0.000321   \n",
       "3        0.101580  0.057472  0.688056  0.618124  0.789218  0.782704  0.712448   \n",
       "4        0.000258  0.000345  0.123943  0.050635  0.066225  0.096038  0.002988   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "1044893  0.010346  0.009663  0.090877  0.102847  0.061587  0.043326  0.157966   \n",
       "1044894  0.230059  0.198934  0.832992  0.708256  0.862744  0.929677  0.666673   \n",
       "1044895  0.000239  0.000407  0.045584  0.003764  0.058104  0.021941  0.003667   \n",
       "1044896  0.000489  0.000237  0.076284  0.098819  0.073334  0.109336  0.002866   \n",
       "1044897  0.000066  0.000156  0.063408  0.069858  0.025247  0.037498  0.000967   \n",
       "\n",
       "         target  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "...         ...  \n",
       "1044893       0  \n",
       "1044894       1  \n",
       "1044895       0  \n",
       "1044896       0  \n",
       "1044897       0  \n",
       "\n",
       "[1044898 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading training file with predictions from all above methods\n",
    "train=pd.read_csv(r'D:\\DS\\NLP\\quora-insincere-questions-classification\\trainmodeloutputs.csv')\n",
    "train=train[['V2','V3','L1','L2','GBM1','GBM2','V0','target']]\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T02:28:50.595325Z",
     "start_time": "2020-04-10T02:28:50.107591Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V3</th>\n",
       "      <th>L1</th>\n",
       "      <th>L2</th>\n",
       "      <th>GBM1</th>\n",
       "      <th>GBM2</th>\n",
       "      <th>V0</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.024300</td>\n",
       "      <td>0.022419</td>\n",
       "      <td>0.507896</td>\n",
       "      <td>0.301129</td>\n",
       "      <td>0.302853</td>\n",
       "      <td>0.327991</td>\n",
       "      <td>0.277927</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.003438</td>\n",
       "      <td>0.120155</td>\n",
       "      <td>0.111000</td>\n",
       "      <td>0.117613</td>\n",
       "      <td>0.113504</td>\n",
       "      <td>0.063507</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.068159</td>\n",
       "      <td>0.042989</td>\n",
       "      <td>0.045665</td>\n",
       "      <td>0.043656</td>\n",
       "      <td>0.003373</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.034296</td>\n",
       "      <td>0.023646</td>\n",
       "      <td>0.016712</td>\n",
       "      <td>0.012958</td>\n",
       "      <td>0.003712</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.096897</td>\n",
       "      <td>0.107733</td>\n",
       "      <td>0.325269</td>\n",
       "      <td>0.310578</td>\n",
       "      <td>0.217999</td>\n",
       "      <td>0.259091</td>\n",
       "      <td>0.531535</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261219</th>\n",
       "      <td>0.034349</td>\n",
       "      <td>0.062328</td>\n",
       "      <td>0.392208</td>\n",
       "      <td>0.384330</td>\n",
       "      <td>0.501407</td>\n",
       "      <td>0.524310</td>\n",
       "      <td>0.679393</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261220</th>\n",
       "      <td>0.371634</td>\n",
       "      <td>0.523747</td>\n",
       "      <td>0.762480</td>\n",
       "      <td>0.703858</td>\n",
       "      <td>0.874843</td>\n",
       "      <td>0.897279</td>\n",
       "      <td>0.898019</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261221</th>\n",
       "      <td>0.004838</td>\n",
       "      <td>0.008398</td>\n",
       "      <td>0.139296</td>\n",
       "      <td>0.064519</td>\n",
       "      <td>0.060111</td>\n",
       "      <td>0.079674</td>\n",
       "      <td>0.024798</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261222</th>\n",
       "      <td>0.009653</td>\n",
       "      <td>0.031900</td>\n",
       "      <td>0.207141</td>\n",
       "      <td>0.030491</td>\n",
       "      <td>0.084060</td>\n",
       "      <td>0.161251</td>\n",
       "      <td>0.026265</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261223</th>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.023978</td>\n",
       "      <td>0.010014</td>\n",
       "      <td>0.013343</td>\n",
       "      <td>0.010956</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>261224 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              V1        V3        L1        L2      GBM1      GBM2        V0  \\\n",
       "0       0.024300  0.022419  0.507896  0.301129  0.302853  0.327991  0.277927   \n",
       "1       0.000732  0.003438  0.120155  0.111000  0.117613  0.113504  0.063507   \n",
       "2       0.000131  0.000277  0.068159  0.042989  0.045665  0.043656  0.003373   \n",
       "3       0.000191  0.000143  0.034296  0.023646  0.016712  0.012958  0.003712   \n",
       "4       0.096897  0.107733  0.325269  0.310578  0.217999  0.259091  0.531535   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "261219  0.034349  0.062328  0.392208  0.384330  0.501407  0.524310  0.679393   \n",
       "261220  0.371634  0.523747  0.762480  0.703858  0.874843  0.897279  0.898019   \n",
       "261221  0.004838  0.008398  0.139296  0.064519  0.060111  0.079674  0.024798   \n",
       "261222  0.009653  0.031900  0.207141  0.030491  0.084060  0.161251  0.026265   \n",
       "261223  0.000023  0.000031  0.023978  0.010014  0.013343  0.010956  0.000096   \n",
       "\n",
       "        target  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            1  \n",
       "...        ...  \n",
       "261219       0  \n",
       "261220       0  \n",
       "261221       0  \n",
       "261222       0  \n",
       "261223       0  \n",
       "\n",
       "[261224 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading test file with predictions from all above methods\n",
    "test=pd.read_csv(r'D:\\DS\\NLP\\quora-insincere-questions-classification\\testmodeloutputs.csv')\n",
    "test=test[['V1','V3','L1','L2','GBM1','GBM2','V0','target']]\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T15:47:19.744875Z",
     "start_time": "2020-04-09T15:47:17.026410Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    2.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=150, multi_class='auto', n_jobs=-1, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=3,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only 3 feautures are being used after multiple attempts at finding the ideal combination\n",
    "logitf=LogisticRegression(n_jobs=-1,class_weight='balanced',penalty='l2',verbose=3,solver='lbfgs',max_iter=150,C=0.1)\n",
    "logitf.fit(train[['V0','V2','V3']],train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T15:47:28.758040Z",
     "start_time": "2020-04-09T15:47:21.822160Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training F1 score: 0.666626789054683\n",
      "Testing F1 score: 0.61123390976466\n",
      "Optimum F1 score: 0.681\n"
     ]
    }
   ],
   "source": [
    "pred=logitf.predict(train[['V0','V2','V3']])\n",
    "print('Training F1 score:',metrics.f1_score(train['target'],pred))\n",
    "pred=logitf.predict(test[['V0','V1','V3']])\n",
    "print('Testing F1 score:',metrics.f1_score(test['target'],pred))\n",
    "pred=logitf.predict_proba(test[['V0','V1','V3']])\n",
    "pred=pred[:,1]\n",
    "search_result = threshold_search(test['target'], pred)\n",
    "print('Optimum F1 score:',round(search_result['f1'],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using only the outputs from the 3 deep learning models give the best result so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic regression with non deep learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T02:31:18.442084Z",
     "start_time": "2020-04-10T02:31:15.726876Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    2.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=150, multi_class='auto', n_jobs=-1, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=3,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only 3 feautures are being used after multiple attempts at finding the ideal combination\n",
    "logitf=LogisticRegression(n_jobs=-1,class_weight='balanced',penalty='l2',verbose=3,solver='lbfgs',max_iter=150,C=0.1)\n",
    "logitf.fit(train[['GBM1','GBM2']],train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T02:31:30.929177Z",
     "start_time": "2020-04-10T02:31:23.313926Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training F1 score: 0.6086212931939791\n",
      "Testing F1 score: 0.5512047589480642\n",
      "Optimum F1 score: 0.623\n"
     ]
    }
   ],
   "source": [
    "pred=logitf.predict(train[['GBM1','GBM2']])\n",
    "print('Training F1 score:',metrics.f1_score(train['target'],pred))\n",
    "pred=logitf.predict(test[['GBM1','GBM2']])\n",
    "print('Testing F1 score:',metrics.f1_score(test['target'],pred))\n",
    "pred=logitf.predict_proba(test[['GBM1','GBM2']])\n",
    "pred=pred[:,1]\n",
    "search_result = threshold_search(test['target'], pred)\n",
    "print('Optimum F1 score:',round(search_result['f1'],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T15:28:00.238490Z",
     "start_time": "2020-04-09T15:28:00.191663Z"
    }
   },
   "outputs": [],
   "source": [
    "data=lgb.Dataset(train.drop('target',axis=1),label=train['target'])\n",
    "vdata=lgb.Dataset(test.drop('target',axis=1),label=test['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T15:42:27.855499Z",
     "start_time": "2020-04-09T15:42:27.839862Z"
    }
   },
   "outputs": [],
   "source": [
    "param = {\"objective\": \"binary\",'metric': {'auc'},\"num_threads\": -1,\"bagging_fraction\": 0.5,\n",
    "         \"feature_fraction\": 0.75,\"is_unbalance\":True,\"learning_rate\": 0.05,\"num_leaves\": 3,\"min_split_gain\":.05,\n",
    "         \"reg_alpha\": 1,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T15:42:39.415233Z",
     "start_time": "2020-04-09T15:42:28.042906Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's auc: 0.98597\tvalid_1's auc: 0.954138\n",
      "[40]\ttraining's auc: 0.986829\tvalid_1's auc: 0.957584\n",
      "[60]\ttraining's auc: 0.988019\tvalid_1's auc: 0.960065\n",
      "[80]\ttraining's auc: 0.988725\tvalid_1's auc: 0.96086\n",
      "[100]\ttraining's auc: 0.989084\tvalid_1's auc: 0.961191\n",
      "[120]\ttraining's auc: 0.98923\tvalid_1's auc: 0.961406\n",
      "[140]\ttraining's auc: 0.989385\tvalid_1's auc: 0.961554\n",
      "[160]\ttraining's auc: 0.989504\tvalid_1's auc: 0.961416\n",
      "[180]\ttraining's auc: 0.9896\tvalid_1's auc: 0.961376\n",
      "Early stopping, best iteration is:\n",
      "[139]\ttraining's auc: 0.989377\tvalid_1's auc: 0.961557\n"
     ]
    }
   ],
   "source": [
    "clf3 = lgb.train(param,data,8000,valid_sets = [data,vdata], verbose_eval=20, early_stopping_rounds = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T15:43:18.171751Z",
     "start_time": "2020-04-09T15:42:41.883438Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum Train F1 score: 0.793\n",
      "Optimum Test F1 score: 0.664\n"
     ]
    }
   ],
   "source": [
    "pred=clf3.predict(train.drop('target',axis=1),num_iteration=clf3.best_iteration)\n",
    "search_result = threshold_search(train['target'], pred)\n",
    "print('Optimum Train F1 score:',round(search_result['f1'],3))\n",
    "pred=clf3.predict(test.drop('target',axis=1),num_iteration=clf3.best_iteration)\n",
    "search_result = threshold_search(test['target'], pred)\n",
    "print('Optimum Test F1 score:',round(search_result['f1'],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Concatenating woe scores to training file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T02:35:05.031269Z",
     "start_time": "2020-04-10T02:35:01.209002Z"
    }
   },
   "outputs": [],
   "source": [
    "#Load if kernel restarted\n",
    "woetrain=pd.read_csv(r'D:\\DS\\NLP\\quora-insincere-questions-classification\\woe20bin.csv')\n",
    "woetest=pd.read_csv(r'D:\\DS\\NLP\\quora-insincere-questions-classification\\woetest20bin.csv')\n",
    "\n",
    "woetr=woetrain.drop(['target','Unnamed: 0'],axis=1)\n",
    "woete=woetest.drop(['target','Unnamed: 0'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T02:35:05.328491Z",
     "start_time": "2020-04-10T02:35:05.032251Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V3</th>\n",
       "      <th>L1</th>\n",
       "      <th>L2</th>\n",
       "      <th>GBM1</th>\n",
       "      <th>GBM2</th>\n",
       "      <th>V0</th>\n",
       "      <th>WOE_['Length']</th>\n",
       "      <th>WOE_['Words']</th>\n",
       "      <th>WOE_['Special Characters']</th>\n",
       "      <th>...</th>\n",
       "      <th>WOE_['Articles']</th>\n",
       "      <th>WOE_['Nouns']</th>\n",
       "      <th>WOE_['Verbs']</th>\n",
       "      <th>WOE_['Adjectives']</th>\n",
       "      <th>WOE_['Question Words']</th>\n",
       "      <th>WOE_['Adverbs']</th>\n",
       "      <th>WOE_['Positive score']</th>\n",
       "      <th>WOE_['Negative score']</th>\n",
       "      <th>WOE_['Neutral score']</th>\n",
       "      <th>WOE_['Final score']</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.024300</td>\n",
       "      <td>0.022419</td>\n",
       "      <td>0.507896</td>\n",
       "      <td>0.301129</td>\n",
       "      <td>0.302853</td>\n",
       "      <td>0.327991</td>\n",
       "      <td>0.277927</td>\n",
       "      <td>0.455097</td>\n",
       "      <td>0.448486</td>\n",
       "      <td>0.396929</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138917</td>\n",
       "      <td>0.645670</td>\n",
       "      <td>0.644238</td>\n",
       "      <td>0.281961</td>\n",
       "      <td>0.380696</td>\n",
       "      <td>0.131932</td>\n",
       "      <td>-0.017822</td>\n",
       "      <td>0.404594</td>\n",
       "      <td>0.522979</td>\n",
       "      <td>0.509005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.003438</td>\n",
       "      <td>0.120155</td>\n",
       "      <td>0.111000</td>\n",
       "      <td>0.117613</td>\n",
       "      <td>0.113504</td>\n",
       "      <td>0.063507</td>\n",
       "      <td>0.505908</td>\n",
       "      <td>0.421115</td>\n",
       "      <td>0.396929</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138917</td>\n",
       "      <td>0.135311</td>\n",
       "      <td>0.306160</td>\n",
       "      <td>0.281961</td>\n",
       "      <td>0.380696</td>\n",
       "      <td>0.131932</td>\n",
       "      <td>-0.017822</td>\n",
       "      <td>0.404594</td>\n",
       "      <td>0.522979</td>\n",
       "      <td>0.509005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.068159</td>\n",
       "      <td>0.042989</td>\n",
       "      <td>0.045665</td>\n",
       "      <td>0.043656</td>\n",
       "      <td>0.003373</td>\n",
       "      <td>0.240919</td>\n",
       "      <td>-0.075055</td>\n",
       "      <td>0.396929</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.089787</td>\n",
       "      <td>0.353022</td>\n",
       "      <td>-0.132154</td>\n",
       "      <td>-0.269975</td>\n",
       "      <td>-0.368412</td>\n",
       "      <td>0.131932</td>\n",
       "      <td>-0.310125</td>\n",
       "      <td>-0.888514</td>\n",
       "      <td>-0.387307</td>\n",
       "      <td>-0.111049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.034296</td>\n",
       "      <td>0.023646</td>\n",
       "      <td>0.016712</td>\n",
       "      <td>0.012958</td>\n",
       "      <td>0.003712</td>\n",
       "      <td>-0.205666</td>\n",
       "      <td>-0.248210</td>\n",
       "      <td>0.396929</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.089787</td>\n",
       "      <td>0.353022</td>\n",
       "      <td>0.306160</td>\n",
       "      <td>-0.757623</td>\n",
       "      <td>-0.368412</td>\n",
       "      <td>0.131932</td>\n",
       "      <td>-0.017822</td>\n",
       "      <td>0.404594</td>\n",
       "      <td>0.522979</td>\n",
       "      <td>0.509005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.096897</td>\n",
       "      <td>0.107733</td>\n",
       "      <td>0.325269</td>\n",
       "      <td>0.310578</td>\n",
       "      <td>0.217999</td>\n",
       "      <td>0.259091</td>\n",
       "      <td>0.531535</td>\n",
       "      <td>0.354693</td>\n",
       "      <td>0.421115</td>\n",
       "      <td>0.396929</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.572525</td>\n",
       "      <td>0.135311</td>\n",
       "      <td>0.306160</td>\n",
       "      <td>0.281961</td>\n",
       "      <td>0.380696</td>\n",
       "      <td>0.131932</td>\n",
       "      <td>-0.062996</td>\n",
       "      <td>0.404594</td>\n",
       "      <td>-0.315595</td>\n",
       "      <td>0.111252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261219</th>\n",
       "      <td>0.034349</td>\n",
       "      <td>0.062328</td>\n",
       "      <td>0.392208</td>\n",
       "      <td>0.384330</td>\n",
       "      <td>0.501407</td>\n",
       "      <td>0.524310</td>\n",
       "      <td>0.679393</td>\n",
       "      <td>0.156899</td>\n",
       "      <td>-0.248210</td>\n",
       "      <td>0.396929</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138917</td>\n",
       "      <td>0.353022</td>\n",
       "      <td>-0.553839</td>\n",
       "      <td>0.281961</td>\n",
       "      <td>0.380696</td>\n",
       "      <td>-1.017107</td>\n",
       "      <td>-0.618379</td>\n",
       "      <td>0.404594</td>\n",
       "      <td>-0.395241</td>\n",
       "      <td>0.596492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261220</th>\n",
       "      <td>0.371634</td>\n",
       "      <td>0.523747</td>\n",
       "      <td>0.762480</td>\n",
       "      <td>0.703858</td>\n",
       "      <td>0.874843</td>\n",
       "      <td>0.897279</td>\n",
       "      <td>0.898019</td>\n",
       "      <td>0.455097</td>\n",
       "      <td>0.288053</td>\n",
       "      <td>-0.231227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138917</td>\n",
       "      <td>0.353022</td>\n",
       "      <td>0.644238</td>\n",
       "      <td>0.281961</td>\n",
       "      <td>0.380696</td>\n",
       "      <td>0.131932</td>\n",
       "      <td>-0.017822</td>\n",
       "      <td>0.404594</td>\n",
       "      <td>0.522979</td>\n",
       "      <td>0.509005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261221</th>\n",
       "      <td>0.004838</td>\n",
       "      <td>0.008398</td>\n",
       "      <td>0.139296</td>\n",
       "      <td>0.064519</td>\n",
       "      <td>0.060111</td>\n",
       "      <td>0.079674</td>\n",
       "      <td>0.024798</td>\n",
       "      <td>0.458060</td>\n",
       "      <td>0.301318</td>\n",
       "      <td>0.396929</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138917</td>\n",
       "      <td>0.353022</td>\n",
       "      <td>-0.132154</td>\n",
       "      <td>0.281961</td>\n",
       "      <td>0.380696</td>\n",
       "      <td>0.131932</td>\n",
       "      <td>-0.017822</td>\n",
       "      <td>-0.895498</td>\n",
       "      <td>-0.387307</td>\n",
       "      <td>-0.997039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261222</th>\n",
       "      <td>0.009653</td>\n",
       "      <td>0.031900</td>\n",
       "      <td>0.207141</td>\n",
       "      <td>0.030491</td>\n",
       "      <td>0.084060</td>\n",
       "      <td>0.161251</td>\n",
       "      <td>0.026265</td>\n",
       "      <td>-0.855564</td>\n",
       "      <td>-1.317091</td>\n",
       "      <td>-0.429643</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.572525</td>\n",
       "      <td>-0.583569</td>\n",
       "      <td>-1.056555</td>\n",
       "      <td>0.281961</td>\n",
       "      <td>0.380696</td>\n",
       "      <td>0.131932</td>\n",
       "      <td>-0.017822</td>\n",
       "      <td>-0.888514</td>\n",
       "      <td>-0.258340</td>\n",
       "      <td>0.509005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261223</th>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.023978</td>\n",
       "      <td>0.010014</td>\n",
       "      <td>0.013343</td>\n",
       "      <td>0.010956</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.240919</td>\n",
       "      <td>0.201565</td>\n",
       "      <td>0.396929</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138917</td>\n",
       "      <td>-0.116554</td>\n",
       "      <td>0.306160</td>\n",
       "      <td>0.281961</td>\n",
       "      <td>-0.368412</td>\n",
       "      <td>0.131932</td>\n",
       "      <td>-0.017822</td>\n",
       "      <td>0.404594</td>\n",
       "      <td>0.522979</td>\n",
       "      <td>0.509005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>261224 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              V1        V3        L1        L2      GBM1      GBM2        V0  \\\n",
       "0       0.024300  0.022419  0.507896  0.301129  0.302853  0.327991  0.277927   \n",
       "1       0.000732  0.003438  0.120155  0.111000  0.117613  0.113504  0.063507   \n",
       "2       0.000131  0.000277  0.068159  0.042989  0.045665  0.043656  0.003373   \n",
       "3       0.000191  0.000143  0.034296  0.023646  0.016712  0.012958  0.003712   \n",
       "4       0.096897  0.107733  0.325269  0.310578  0.217999  0.259091  0.531535   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "261219  0.034349  0.062328  0.392208  0.384330  0.501407  0.524310  0.679393   \n",
       "261220  0.371634  0.523747  0.762480  0.703858  0.874843  0.897279  0.898019   \n",
       "261221  0.004838  0.008398  0.139296  0.064519  0.060111  0.079674  0.024798   \n",
       "261222  0.009653  0.031900  0.207141  0.030491  0.084060  0.161251  0.026265   \n",
       "261223  0.000023  0.000031  0.023978  0.010014  0.013343  0.010956  0.000096   \n",
       "\n",
       "        WOE_['Length']  WOE_['Words']  WOE_['Special Characters']  ...  \\\n",
       "0             0.455097       0.448486                    0.396929  ...   \n",
       "1             0.505908       0.421115                    0.396929  ...   \n",
       "2             0.240919      -0.075055                    0.396929  ...   \n",
       "3            -0.205666      -0.248210                    0.396929  ...   \n",
       "4             0.354693       0.421115                    0.396929  ...   \n",
       "...                ...            ...                         ...  ...   \n",
       "261219        0.156899      -0.248210                    0.396929  ...   \n",
       "261220        0.455097       0.288053                   -0.231227  ...   \n",
       "261221        0.458060       0.301318                    0.396929  ...   \n",
       "261222       -0.855564      -1.317091                   -0.429643  ...   \n",
       "261223        0.240919       0.201565                    0.396929  ...   \n",
       "\n",
       "        WOE_['Articles']  WOE_['Nouns']  WOE_['Verbs']  WOE_['Adjectives']  \\\n",
       "0               0.138917       0.645670       0.644238            0.281961   \n",
       "1               0.138917       0.135311       0.306160            0.281961   \n",
       "2              -0.089787       0.353022      -0.132154           -0.269975   \n",
       "3              -0.089787       0.353022       0.306160           -0.757623   \n",
       "4              -0.572525       0.135311       0.306160            0.281961   \n",
       "...                  ...            ...            ...                 ...   \n",
       "261219          0.138917       0.353022      -0.553839            0.281961   \n",
       "261220          0.138917       0.353022       0.644238            0.281961   \n",
       "261221          0.138917       0.353022      -0.132154            0.281961   \n",
       "261222         -0.572525      -0.583569      -1.056555            0.281961   \n",
       "261223          0.138917      -0.116554       0.306160            0.281961   \n",
       "\n",
       "        WOE_['Question Words']  WOE_['Adverbs']  WOE_['Positive score']  \\\n",
       "0                     0.380696         0.131932               -0.017822   \n",
       "1                     0.380696         0.131932               -0.017822   \n",
       "2                    -0.368412         0.131932               -0.310125   \n",
       "3                    -0.368412         0.131932               -0.017822   \n",
       "4                     0.380696         0.131932               -0.062996   \n",
       "...                        ...              ...                     ...   \n",
       "261219                0.380696        -1.017107               -0.618379   \n",
       "261220                0.380696         0.131932               -0.017822   \n",
       "261221                0.380696         0.131932               -0.017822   \n",
       "261222                0.380696         0.131932               -0.017822   \n",
       "261223               -0.368412         0.131932               -0.017822   \n",
       "\n",
       "        WOE_['Negative score']  WOE_['Neutral score']  WOE_['Final score']  \n",
       "0                     0.404594               0.522979             0.509005  \n",
       "1                     0.404594               0.522979             0.509005  \n",
       "2                    -0.888514              -0.387307            -0.111049  \n",
       "3                     0.404594               0.522979             0.509005  \n",
       "4                     0.404594              -0.315595             0.111252  \n",
       "...                        ...                    ...                  ...  \n",
       "261219                0.404594              -0.395241             0.596492  \n",
       "261220                0.404594               0.522979             0.509005  \n",
       "261221               -0.895498              -0.387307            -0.997039  \n",
       "261222               -0.888514              -0.258340             0.509005  \n",
       "261223                0.404594               0.522979             0.509005  \n",
       "\n",
       "[261224 rows x 24 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainl=[train.drop('target',axis=1),woetr]\n",
    "test1=[test.drop('target',axis=1),woete]\n",
    "newtrain=pd.concat(trainl,axis=1)\n",
    "newtest=pd.concat(test1,axis=1)\n",
    "newtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T02:35:17.871961Z",
     "start_time": "2020-04-10T02:35:07.965555Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 15 epochs took 9 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    9.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=150, multi_class='auto', n_jobs=-1, penalty='l2',\n",
       "                   random_state=None, solver='saga', tol=0.0001, verbose=3,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only deep model values are being used\n",
    "logitf=LogisticRegression(n_jobs=-1,class_weight='balanced',penalty='l2',verbose=3,solver='saga',max_iter=150,C=0.1)\n",
    "logitf.fit(newtrain.drop(['L1','L2','GBM1','GBM2'],axis=1),train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T02:35:25.534465Z",
     "start_time": "2020-04-10T02:35:17.872959Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training F1 score: 0.6687752208528737\n",
      "Testing F1 score: 0.6126196522758351\n",
      "Optimum F1 score: 0.68\n"
     ]
    }
   ],
   "source": [
    "pred=logitf.predict(newtrain.drop(['L1','L2','GBM1','GBM2'],axis=1))\n",
    "print('Training F1 score:',metrics.f1_score(train['target'],pred))\n",
    "pred=logitf.predict(newtest.drop(['L1','L2','GBM1','GBM2'],axis=1))\n",
    "print('Testing F1 score:',metrics.f1_score(test['target'],pred))\n",
    "pred=logitf.predict_proba(newtest.drop(['L1','L2','GBM1','GBM2'],axis=1))\n",
    "pred=pred[:,1]\n",
    "search_result = threshold_search(test['target'], pred)\n",
    "print('Optimum F1 score:',round(search_result['f1'],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score is similar to before that is adding woe values have not affected the f1 score much."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
